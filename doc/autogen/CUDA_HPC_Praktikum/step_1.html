<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                 "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
  <link href="stylesheet.css" rel="stylesheet" type="text/css">
  <link href="tabs.css" rel="stylesheet" type="text/css">
  <title>The step-1 tutorial program</title>
  <meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1">
  <meta name="author" content="the blanc and blanc++ authors <authors@dealii.org>">
  <meta name="copyright" content="Copyright (C) 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007 by the deal.II authors">
  <meta name="blanc++ version" content="1.0.0">
</head>
<body>
<div class="head">
  <h1 class="head">CUDA Lab Course Reference Manual 2013</h1>
</div>
<!-- Generated by Doxygen 1.7.6.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<div class="title">The step-1 tutorial program </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"> 
<table class="tutorial" width="100%">
<tr><th colspan="2"><b><small>Table of contents</small></b></th></tr>
<tr><td width="50%" valign="top">
<ol>
  <li> <a href="#Intro" class=bold>Introduction</a>
    <ul>
      </ul>
  <li> <a href="#CommProg" class=bold>The commented program</a>
    <ul>
        <li><a href="#ParallelizationofCholeskyFactorization">Parallelization of Cholesky Factorization</a>
        <li><a href="#ClassKernels">Class: Kernels</a>
      <ul>
        <li><a href="#ClassCholesky">Class: Cholesky</a>
        <li><a href="#ClassLU">Class: LU</a>
      </ul>
        <li><a href="#DeviceFunctions">Device Functions</a>
      <ul>
        <li><a href="#DeviceFunctionlex_index_2D">Device Function: lex_index_2D</a>
        <li><a href="#DeviceFunctionglobal_pos">Device Function: global_pos</a>
        <li><a href="#DeviceFunctioninv_sqrt">Device Function: inv_sqrt</a>
      </ul>
        <li><a href="#CholeskyKernels">Cholesky Kernels</a>
      <ul>
        <li><a href="#Kernel__single_thread">Kernel: __single_thread</a>
        <li><a href="#Kernelfactorize_diag_block">Kernel: factorize_diag_block</a>
        <li><a href="#Kernelstrip_update">Kernel: strip_update</a>
        <li><a href="#Kerneldiag_update">Kernel: diag_update</a>
        <li><a href="#Kernello_update">Kernel: lo_update</a>
      </ul>
        <li><a href="#Wrapperfunctions">Wrapper functions</a>
      <ul>
        <li><a href="#Functionblackbox">Function: blackbox</a>
        <li><a href="#Functionsingle_thread">Function: single_thread</a>
        <li><a href="#Functionfactorize_diag_block">Function: factorize_diag_block</a>
        <li><a href="#Functionstrip_update">Function: strip_update</a>
        <li><a href="#Functiondiag_update">Function: diag_update</a>
        <li><a href="#Functionlo_update">Function: lo_update</a>
      </ul>
        <li><a href="#ClassCUDADriver">Class: CUDADriver</a>
      <ul>
        <li><a href="#ConstructorCUDADriver">Constructor: CUDADriver</a>
        <li><a href="#Functionfactorize">Function: factorize</a>
        <li><a href="#Functionchol_fac">Function: chol_fac</a>
        <li><a href="#Functionsingle_thread_cholesky">Function: single_thread_cholesky</a>
      </ul>
        <li><a href="#ClassSimParams">Class: SimParams</a>
      <ul>
        <li><a href="#Functiondeclare">Function: declare</a>
        <li><a href="#Functionget">Function: get</a>
      </ul>
        <li><a href="#ClassCholeskyTest">Class: CholeskyTest</a>
        <li><a href="#ClassCholesky">Class: Cholesky</a>
      <ul>
        <li><a href="#ConstructorCholeskyTest">Constructor: CholeskyTest</a>
        <li><a href="#Functionsetup_and_assemble_test_matrix">Function: setup_and_assemble_test_matrix</a>
        <li><a href="#Functionrun">Function: run</a>
        <li><a href="#Functioncpu_tiled">Function: cpu_tiled</a>
        <li><a href="#FunctionLLtMult">Function: LLtMult</a>
      </ul>
        <li><a href="#ClassMyFancySimulation">Class: MyFancySimulation</a>
      <ul>
        <li><a href="#Constructor">Constructor</a>
        <li><a href="#Functionprecision_id">Function: precision_id</a>
        <li><a href="#Functionrun">Function: run</a>
        <li><a href="#Funktionmain">Funktion: main</a>
      </ul>
      </ul>
</ol></td><td width="50%" valign="top"><ol>
  <li value="3"> <a href="#Results" class=bold>Results</a>
    <ul>
      </ul>
  <li> <a href="#PlainProg" class=bold>The plain program</a>
    <ul>
        <li><a href="#plain-ParallelizationofCholeskyFactorization">Parallelization of Cholesky Factorization</a>
        <li><a href="#plain-ClassKernels">Class: Kernels</a>
      <ul>
        <li><a href="#plain-ClassCholesky">Class: Cholesky</a>
        <li><a href="#plain-ClassLU">Class: LU</a>
      </ul>
        <li><a href="#plain-DeviceFunctions">Device Functions</a>
      <ul>
        <li><a href="#plain-DeviceFunctionlex_index_2D">Device Function: lex_index_2D</a>
        <li><a href="#plain-DeviceFunctionglobal_pos">Device Function: global_pos</a>
        <li><a href="#plain-DeviceFunctioninv_sqrt">Device Function: inv_sqrt</a>
      </ul>
        <li><a href="#plain-CholeskyKernels">Cholesky Kernels</a>
      <ul>
        <li><a href="#plain-Kernel__single_thread">Kernel: __single_thread</a>
        <li><a href="#plain-Kernelfactorize_diag_block">Kernel: factorize_diag_block</a>
        <li><a href="#plain-Kernelstrip_update">Kernel: strip_update</a>
        <li><a href="#plain-Kerneldiag_update">Kernel: diag_update</a>
        <li><a href="#plain-Kernello_update">Kernel: lo_update</a>
      </ul>
        <li><a href="#plain-Wrapperfunctions">Wrapper functions</a>
      <ul>
        <li><a href="#plain-Functionblackbox">Function: blackbox</a>
        <li><a href="#plain-Functionsingle_thread">Function: single_thread</a>
        <li><a href="#plain-Functionfactorize_diag_block">Function: factorize_diag_block</a>
        <li><a href="#plain-Functionstrip_update">Function: strip_update</a>
        <li><a href="#plain-Functiondiag_update">Function: diag_update</a>
        <li><a href="#plain-Functionlo_update">Function: lo_update</a>
      </ul>
        <li><a href="#plain-ClassCUDADriver">Class: CUDADriver</a>
      <ul>
        <li><a href="#plain-ConstructorCUDADriver">Constructor: CUDADriver</a>
        <li><a href="#plain-Functionfactorize">Function: factorize</a>
        <li><a href="#plain-Functionchol_fac">Function: chol_fac</a>
        <li><a href="#plain-Functionsingle_thread_cholesky">Function: single_thread_cholesky</a>
      </ul>
        <li><a href="#plain-ClassSimParams">Class: SimParams</a>
      <ul>
        <li><a href="#plain-Functiondeclare">Function: declare</a>
        <li><a href="#plain-Functionget">Function: get</a>
      </ul>
        <li><a href="#plain-ClassCholeskyTest">Class: CholeskyTest</a>
        <li><a href="#plain-ClassCholesky">Class: Cholesky</a>
      <ul>
        <li><a href="#plain-ConstructorCholeskyTest">Constructor: CholeskyTest</a>
        <li><a href="#plain-Functionsetup_and_assemble_test_matrix">Function: setup_and_assemble_test_matrix</a>
        <li><a href="#plain-Functionrun">Function: run</a>
        <li><a href="#plain-Functioncpu_tiled">Function: cpu_tiled</a>
        <li><a href="#plain-FunctionLLtMult">Function: LLtMult</a>
      </ul>
        <li><a href="#plain-ClassMyFancySimulation">Class: MyFancySimulation</a>
      <ul>
        <li><a href="#plain-Constructor">Constructor</a>
        <li><a href="#plain-Functionprecision_id">Function: precision_id</a>
        <li><a href="#plain-Functionrun">Function: run</a>
        <li><a href="#plain-Funktionmain">Funktion: main</a>
      </ul>
      </ul>
</ol> </td> </tr> </table>
 <a class="anchor" id="Introduction"></a></p>
<h1>Introduction</h1>
<p>In this example program we discuss how to implement the Cholesky factorization of dense matrices. Once a matrix is factorized the corresponding linear algebraic system can be solved by solving two auxiliary triangular linear systems.  </p>
<p>The starting point is a set of linear equations </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{eqnarray} \label{LSYS} \begin{array}{rcccr} a_{0,0}x_0 &amp; + &amp; \ldots &amp; + &amp; a_{0,n-1}x_{n-1} \\ &amp; &amp; \ldots &amp; &amp; \\ &amp; &amp; \ldots &amp; &amp; \\ &amp; &amp; \ldots &amp; &amp; \\ a_{n-1,0}x_0 &amp; + &amp; \ldots &amp; + &amp; a_{n-1,n-1}x_{n-1} \end{array} &amp; = &amp; \begin{array}{c} f_0 \\ \cdot\\ \cdot\\ \cdot\\ f_{n-1} \end{array} \end{eqnarray}" src="form_0.png"/>
</p>
<p> with symmetric coefficient matrix <img class="formulaInl" alt="$A = (a_{ij})_{i,j=0}^{i,j=n-1}$" src="form_1.png"/>, <img class="formulaInl" alt="$a_{ij}=a_{ji}\,\forall i,j$" src="form_2.png"/>. The solution vector is denoted by <img class="formulaInl" alt="$x=(x_j)_{j=0}^{j=n-1}$" src="form_3.png"/> and the right-hand side by <img class="formulaInl" alt="$f=(f_i)_{i=0}^{i=n-1}$" src="form_4.png"/>. The factorization process yields a lower triangular matrix <img class="formulaInl" alt="$L$" src="form_5.png"/>, such that </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{eqnarray} LL^T &amp; = &amp; A \,. \end{eqnarray}" src="form_6.png"/>
</p>
<p> Solving the linear system given is then achieved by solving two triangular systems of equations by forward and backward substitution. The first step yields the auxiliary solution <img class="formulaInl" alt="$y = L^Tx$" src="form_7.png"/>. </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{eqnarray} Ax ~ = ~ f \Rightarrow LL^Tx &amp; = &amp; f \\ y ~ = ~ L^Tx \Rightarrow Ly &amp; = &amp; f \\ \Rightarrow y &amp; = &amp; L^{-1} f \\ \Rightarrow x &amp; = &amp; (L^T)^{-1} y \,. \end{eqnarray}" src="form_8.png"/>
</p>
  <p><a class="anchor" id="CholeskyFactorizationAlgorithm"></a></p>
<h2>Cholesky Factorization - Algorithm</h2>
<p>The entries of <img class="formulaInl" alt="$L$" src="form_5.png"/> follow from the condition <img class="formulaInl" alt="$LL^T = A$" src="form_9.png"/>, that is </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{eqnarray} (LL^T)_{ij} ~ = ~ \sum_{k=0}^{\min\{i,j\}} L_{ik}L^T_{kj} &amp; = &amp; \sum_{k=0}^{\min\{i,j\}} L_{ik}L_{jk} ~ = ~ A_{ij} \,. \end{eqnarray}" src="form_10.png"/>
</p>
<p> The upper limit of the summation is due to the triangular shape of matrix <img class="formulaInl" alt="$L$" src="form_5.png"/>. It implies that one has to start computing its elements at the uppermost diagonal element and then has to proceed down the column. Only then one can go over to the next column. Therefore the computation of the diagonal elements is inherently serial. Each diagonal element needs the entries of <img class="formulaInl" alt="$L$" src="form_5.png"/> which are in the block above and to the left of it. </p>
<ol>
<li>
For the top row we have <ol>
<li>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{eqnarray} L_{00} &amp; = &amp; \sqrt{A_{00}} \end{eqnarray}" src="form_11.png"/>
</p>
  </li>
<li>
do in parallel : <img class="formulaInl" alt="$j = 1,\ldots, n-1$" src="form_12.png"/> : <p class="formulaDsp">
<img class="formulaDsp" alt="\begin{eqnarray} L_{j0} &amp; = &amp; \frac{1}{\sqrt{L_{00}}} A_{0j} \end{eqnarray}" src="form_13.png"/>
</p>
  </li>
</ol>
</li>
<li>
and for the following rows <img class="formulaInl" alt="$i = 1,\ldots, n-1$" src="form_14.png"/> <ol>
<li>
<br/>
 <p class="formulaDsp">
<img class="formulaDsp" alt="\begin{eqnarray} \textrm{sum} &amp; = &amp; \sum_{k=0}^{i-1} L_{ik}^2 \\ L_{ii} &amp; = &amp; \sqrt{A_{ii} - \textrm{sum} } \end{eqnarray}" src="form_15.png"/>
</p>
  </li>
<li>
do in parallel : <img class="formulaInl" alt="$j = i+1,\ldots, n-1$" src="form_16.png"/> : <p class="formulaDsp">
<img class="formulaDsp" alt="\begin{eqnarray} \textrm{sum} &amp; = &amp; \sum_{k=0}^{i-1} L_{ik}L_{jk} \\ L_{ji} &amp; = &amp; \frac{1}{\sqrt{L_{ii}}} \left( A_{ij} - \textrm{sum} \right) \,. \end{eqnarray}" src="form_17.png"/>
</p>
  </li>
</ol>
</li>
</ol>
<p>This shows, that at least the computation of the off-diagonal elements can be parallelized. Fortunately that's the part containing most of the the computational costs in Cholesky factorization.  <a class="anchor" id="SpecialrequirementsduetoCUDA"></a></p>
<h2>Special requirements due to CUDA</h2>
<ul>
<li>
Hide latency of memory accesses, especially those to global memory </li>
<li>
memory accesses require a certain order to be efficient (bank conflicts) </li>
<li>
Kernels should load as little data from memory as possible and should do as much computations with it as possible </li>
<li>
synchronisation - always an issue in parallel programming </li>
<li>
Minimize the dependencies on nvcc  </li>
</ul>
<p><a class="anchor" id="ProgramStructure"></a></p>
<h2>Program Structure</h2>
<p>The diagram in the figure roughly sketches the overall class layout and the distribution of the classes over the source files. On the host side you have a toplevel class which manages the interaction with the user (data input and output; file step-1.cpp). The actual Cholesky factorization is distributed over a stack of classes and files. This stack reflects the hierarchical structure of the compute environment formed by CPU and GPU. The front end is a driver class which offers a black-box function for the factorization. The factorization routine internally delegates the work to the CUDA kernels. To do this, the access is not direct but via wrapper functions which encapsulate the kernel calls and the set up of thread grids and blocks. The purpose of this large amount of indirection is to facilitate porting the program to different parallelization architectures if new, promising ones appear. The dependence of the host side code on the device-specific one is kept at a minimum. The bridge between the two is formed by the file cuda_kernel_wrapper_step-1.cu.h. </p>
<div class="image">
<img src="step-1-class-design.png" alt="step-1-class-design.png"/>
<div class="caption">
Distribution of classes over source files.</div></div>
<p> <a class="anchor" id="Literature"></a></p>
<h2>Literature</h2>
<p>Cambridge CUDA-Course <a href="http://www.many-core.group.cam.ac.uk/archive/CUDAcourse09/">Lectures 3 and 4</a></p>
<p><a class="anchor" id="CommProg"></a> </p>
<h1>The commented program</h1>
<div class="fragment"><pre class="fragment">     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
 / *
    Copyright 2010,2011,2012,2013 Stephan Kramer, as of 2013: Dr. Stephan Kramer
 
    Licensed under the Apache License, Version 2.0 (the <span class="stringliteral">&quot;License&quot;</span>);
    you may not use <span class="keyword">this</span> file except in compliance with the License.
    You may obtain a copy of the License at
 
        http:<span class="comment">//www.apache.org/licenses/LICENSE-2.0</span>
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an <span class="stringliteral">&quot;AS IS&quot;</span> BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License <span class="keywordflow">for</span> the specific language governing permissions and
    limitations under the License.
 
    This file includes
 
    - the CUDA kernels <span class="keywordflow">for</span> computing a Cholesky factorization
      of a real, symmetric (and hopefully positive definite) matrix.
 
    - device functions needed by the kernels <span class="keywordflow">for</span> mapping thread and block indices
      to row and column indices of the matrix which is to be factorized or
      to the positions in the linear array holding the matrix entries.
 
    - the definitions of the wrapper functions <span class="keywordflow">for</span> the kernels. These wrapper functions
      are declared in a separate header file and either allow to call
      the kernels individually or to execute the complete factorization
      via the <span class="stringliteral">&#39;blackbox&#39;</span> <span class="keyword">function</span>.
 
    All kernels and wrapper functions are enclosed in a <span class="keyword">namespace </span>&#39;step1&#39;
 * /
<span class="preprocessor"> #ifndef CUDA_KERNEL_STEP_1_CU_H</span>
<span class="preprocessor"> #define CUDA_KERNEL_STEP_1_CU_H</span>
</pre></div><p>The most interesting part of this program is the way parallelization is implemented with CUDA. Therefore, we walk through the source code in a bottom-up fashion. It begins with the kernels and ends with the main function. A general feature of matrix operations is that large matrices get tiled into smaller submatrices on which the work is done at the end. Typically, the choice of the tile size depends on the hardware.</p>
<p><a class="anchor" id="ParallelizationofCholeskyFactorization"></a> </p>
<h3>Parallelization of Cholesky Factorization</h3>
<p>Looking at the algorithm given in the introduction, we see that the main computational effort is caused by computing the auxiliary variable <code>sum</code> in the update of the off-diagonal elements.</p>
<p>For an efficient parallelization we subdivide the matrix into blocks and start with factorizing the upper leftmost diagonal block. Afterwards we compute the blocks in the columns below the diagonal block. Finally, we update the lower right part of the matrix which is still to be factorized by subtracting the auxiliary variable <code>sum</code>. This happens in diag_update() and lo_update().</p>
<p>For CUDA, since the size of a warp is 32, the most efficient choice for the blocksize is 16 in most cases where double precision is the type of choice for floating point numbers and 32 should be the optimum for single precision. #define DEFAULT_TILE_SIZE 16</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">namespace </span>step1 {
</pre></div><p>As of CUDA 5.0 it is possible to pass the size of shared memory arrays via template parameters into the kernels. Therefore we use a static constant rather than some macro to set the value for the size of matrix tiles. For CUDA 2.x and 3.x it did not seem to work. For 4.x we did not try.</p>
<p>The square of this number gives the number of threads in a thread block. 16 has turned out to be a fairly good compromise.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">int</span> DEFAULT_TILE_SIZE = 16;
</pre></div><p><a class="anchor" id="ClassKernels"></a> </p>
<h3>Class: Kernels</h3>
<p>The CUDA-based kernels for the parallel computation are encapsulated into wrapper functions which are all collected into one structure. From a performance point of view one of the more interesting things is the dependence on the precision. Therefore, the kernels are templatized with respect to the number type <code>T</code>. This minimizes the amount of work for creating all the implementations for the different number types and precisions. To do this, we provide explicit template-specializations of this class. The number of specializations is kept at a minimum by grouping the wrapper functions for the different factorization methods into different private internal classes. Access to the kernels is via the <code>lu</code> and <code>cholesky</code> attributes.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">class </span>Kernels {
</pre></div><p><a class="anchor" id="ClassCholesky"></a> </p>
<h4>Class: Cholesky</h4>
<p>This internal class provides the interface to the actual kernels of the Cholesky factorization.</p>
<div class="fragment"><pre class="fragment">     <span class="keyword">struct </span>Cholesky {
 
         <span class="keywordtype">void</span> single_thread(T * A, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim);
 
         cudaError_t factorize_diag_block(T *A,
                                          <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim );
 
         <span class="keywordtype">void</span> strip_update(T *A,
                           <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_remaining_blocks, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim);
 
         <span class="keywordtype">void</span> diag_update(T *A,
                          <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_remaining_blocks, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim);
 
         <span class="keywordtype">void</span> lo_update(T *A,
                        <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_blocks, <span class="keywordtype">int</span> n_remaining_blocks, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim);
 
         <span class="keywordtype">void</span> blackbox(T *A, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim);
 
     };
</pre></div><p><a class="anchor" id="ClassLU"></a> </p>
<h4>Class: LU</h4>
<p>A possible extension of this program would be to add an internal class which provides the interface to LU-specific kernels. This is the reason why the wrapper functions for the Cholesky kernels have been encapsulated in a private, internal class.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">public</span>:
     Cholesky cholesky;
 
 };
 
 } <span class="comment">// namespace step1 END</span>
 
<span class="preprocessor"> #endif // CUDA_KERNEL_STEP_1_CU_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
 / *
      This file includes
 
    - the CUDA kernels <span class="keywordflow">for</span> computing a Cholesky factorization
      of a real, symmetric (and hopefully positive definite) matrix.
 
    - device functions needed by the kernels <span class="keywordflow">for</span> mapping thread and block indices
      to row and column indices of the matrix which is to be factorized or
      to the positions in the linear array holding the matrix entries.
 
    - the definitions of the wrapper functions <span class="keywordflow">for</span> the kernels. These wrapper functions
      are declared in a separate header file and either allow to call
      the kernels individually or to execute the complete factorization
      via the <span class="stringliteral">&#39;blackbox&#39;</span> <span class="keyword">function</span>.
 
    All kernels and wrapper functions are enclosed in a <span class="keyword">namespace </span>&#39;step1&#39;
 * /
<span class="preprocessor"> #ifdef USE_CU_C</span>
</pre></div><p>In order to use printf() from within a kernel the good old C-header has to be included.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;stdio.h&gt;</span>
 
<span class="preprocessor"> #include &lt;step-1/cuda_kernel_wrapper_step-1.cu.h&gt;</span>
 
 <span class="keyword">namespace </span>step1 {
</pre></div><p><a class="anchor" id="DeviceFunctions"></a> </p>
<h3>Device Functions</h3>
<p>Before discussing the kernels we take a look at so-called device functions. They execute only on the GPU and up to CUDA 3.2 are automatically inline. Nowadays they may be not inline. To enforce inlining the keyword <code>__forceinline__</code> get introduced.</p>
<p><a class="anchor" id="DeviceFunctionlex_index_2D"></a> </p>
<h4>Device Function: lex_index_2D</h4>
<p>Compute a position <img class="formulaInl" alt="$r\cdot row\_length + c$" src="form_18.png"/> in a linear array from a row index <img class="formulaInl" alt="$r$" src="form_19.png"/> and column index <img class="formulaInl" alt="$c$" src="form_20.png"/> of a matrix entry. It is assumed that the matrix is stored row-wise. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">r</td><td>: row index </td></tr>
    <tr><td class="paramname">c</td><td>: column index </td></tr>
    <tr><td class="paramname">leading_dim</td><td>: number of matrix entries per row</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> __forceinline__
 __device__ <span class="keywordtype">int</span> lex_index_2D(<span class="keywordtype">int</span> r, <span class="keywordtype">int</span> c, <span class="keywordtype">int</span> leading_dim)
 {
     <span class="keywordflow">return</span> c +  r*leading_dim;
 }
</pre></div><p><a class="anchor" id="DeviceFunctionglobal_pos"></a> </p>
<h4>Device Function: global_pos</h4>
<p>Compute a global row or column index given the Block index and thread index. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">t_pos</td><td>: local row or comlumn index within block </td></tr>
    <tr><td class="paramname">n_blocks_done</td><td>: Index of the block in C-counting</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keywordtype">int</span> TILE_SIZE&gt;
 __forceinline__
 __device__ <span class="keywordtype">int</span> global_pos(<span class="keywordtype">int</span> t_pos, <span class="keywordtype">int</span> n_blocks_done)
 {
     <span class="keywordflow">return</span> t_pos + TILE_SIZE*n_blocks_done;
 }
</pre></div><p><a class="anchor" id="DeviceFunctioninv_sqrt"></a> </p>
<h4>Device Function: inv_sqrt</h4>
<p>CUDA provides single and double-precision versions for the computation of the reciprocal of a square root. In order to use it in a template context we have to provide our own little wrapper function for unifying the name by employing C++'s polymorphism. As for the other device functions we would like to enforce inlining. However, this leads to compiler errors (at least when using the nvcc which ships with CUDA 5). Therefore, we do not inline. The function <code>rsqrtf</code> is documented in the CUDA Programming Guide. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>: real to take the square root of.</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> __device__ <span class="keywordtype">float</span> inv_sqrt(<span class="keywordtype">float</span> x)
 {
     <span class="keywordflow">return</span> rsqrtf(x);
 }
 
 
 __device__ <span class="keywordtype">double</span> inv_sqrt(<span class="keywordtype">double</span> x)
 {
     <span class="keywordflow">return</span> rsqrt(x);
 }
</pre></div><p><a class="anchor" id="CholeskyKernels"></a> </p>
<h3>Cholesky Kernels</h3>
<p>Kernels run on the GPU and are global functions. They cannot be members of a class but of a namespace. Therefore, in order to group them according to the factorization method they are used for we put them into different naemspaces.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">namespace </span>Chol {
</pre></div><p><a class="anchor" id="Kernel__single_thread"></a> </p>
<h4>Kernel: __single_thread</h4>
<p>This kernel is only started once to compute the factorization of the whole matrix. This shows that the source of the CPU-based Cholesky factorization would also run unchanged on the GPU. In memory the matrix is stored as a linear array whose length is a multiple of <code>leading_dim</code>. This is for improved memory troughput. For instance, this allows to make rows to have a length which is a multiple of the cache line length which avoids misaligned accesses. Since for Cholesky factorizations a matrix must be square it does not matter whether it is stored in row- or column-major format. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>: linear array containing the matrix entries in row-major order. </td></tr>
    <tr><td class="paramname">n_rows</td><td>: length of a column </td></tr>
    <tr><td class="paramname">leading_dim</td><td>:</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 __global__
 <span class="keywordtype">void</span>
 __single_thread(T *A, <span class="keyword">const</span> <span class="keywordtype">int</span> n_rows, <span class="keyword">const</span> <span class="keywordtype">int</span> leading_dim)
 {
</pre></div><p>The outer loop runs over the rows <em>L</em>.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> r = 0; r &lt; n_rows; ++r)
     {
</pre></div><p>Compute diagonal entry of Cholesky factor.</p>
<div class="fragment"><pre class="fragment">         T sum = 0.;
         <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> idx;
         <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> idx_c;
</pre></div><p>Sum squares of entries computed so far in this row.</p>
<div class="fragment"><pre class="fragment">         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> u = 0; u &lt; r; ++u)
         {
             idx = lex_index_2D(r, u, leading_dim);
             sum += A[idx] * A[idx];
         }
         idx = lex_index_2D(r, r, leading_dim);
         A[idx] = sqrt(A[idx] - sum);
</pre></div><p>Off-diagonal entries. Here, we exploit the symmetry of <em>A</em>. The auxiliary variable <code>sum</code> corresponds to step 2.1 of the algorithm given in the introduction.</p>
<div class="fragment"><pre class="fragment">         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> c = r+1; c &lt; n_rows; ++c)
         {
             sum = 0.;
 
             <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> u = 0; u &lt; r; ++u)
             {
                 idx_c = lex_index_2D(c, u, leading_dim);
                 idx   = lex_index_2D(r, u, leading_dim);
                 sum += A[idx_c]*A[idx];
             }
 
             idx_c = lex_index_2D(c, r, leading_dim);
             idx   = lex_index_2D(r, c, leading_dim);
             A[idx_c]  = A[idx] - sum;
 
             idx   = lex_index_2D(r, r, leading_dim);
             A[idx_c] /= A[idx];
         }
     }
 }
</pre></div><p><a class="anchor" id="Kernelfactorize_diag_block"></a> </p>
<h4>Kernel: factorize_diag_block</h4>
<p>This kernel factorizes a diagonal block assuming that all previous diagonal blocks have already been factored.</p>
<p>In contrast to a serial implementation we hide the summation of the off-diagonal elements from the factorized part in the usage of the <em>thread</em> index and in the choice of synchronization points.</p>
<p>Each instance of this kernel computes one matrix entry of the Cholesky factor <img class="formulaInl" alt="$L$" src="form_5.png"/>. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>: Linear array containing the elements of matrix to factorize </td></tr>
    <tr><td class="paramname">n_blocks_done</td><td>: distance of the block which is to be factorized from the left uppermost diagonal block. </td></tr>
    <tr><td class="paramname">n_cols</td><td>: length of a row of <img class="formulaInl" alt="$A$" src="form_21.png"/>.</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keywordtype">int</span> TILE_SIZE&gt;
 __global__
 <span class="keywordtype">void</span>
 __factorize_diag_block(T *A, <span class="keywordtype">int</span> n_blocks_done,
                        <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim)
 {
</pre></div><p>In C, arrays are stored row-wise; thus the <img class="formulaInl" alt="$x$" src="form_22.png"/> coordinate of <code>threadIdx</code> indicates the column index.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> col = threadIdx.x;
</pre></div><p>The <img class="formulaInl" alt="$y$" src="form_23.png"/> coordinate of <code>threadIdx</code> indicates the row.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> row = threadIdx.y;
</pre></div><p>From the thread and block index we have to compute the index of the matrix element this thread has to work on. This is delegated to device functions.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> global_row = global_pos&lt;TILE_SIZE&gt;(row, n_blocks_done);
     <span class="keywordtype">int</span> global_col = global_pos&lt;TILE_SIZE&gt;(col, n_blocks_done);
</pre></div><p>For matrices whose number of rows is not a multiple of <code>TILE_SIZE</code> we have to take care that thread do not work on non-existing matrix entries.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span> ((global_row &gt;= n_cols) || (global_col &gt;= n_cols))
         <span class="keywordflow">return</span>;
 
     <span class="keywordtype">int</span> idx = lex_index_2D(global_row, global_col, leading_dim);
</pre></div><p>Simplify debugging especially of index problems we provide possibility for some output.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #ifdef INDEX_BOUND_DEBUG</span>
<span class="preprocessor"></span>     <span class="keywordflow">if</span> (row == 0 &amp;&amp; col == 0)
     printf(<span class="stringliteral">&quot;%s:\n------------------------\n&quot;</span>, __FUNCTION__);
     __syncthreads();
 
     printf(<span class="stringliteral">&quot;row, col : (%d, %d), g_row,g_col : (%d, %d), idx : %d\n &quot;</span>,
            row, col, global_row, global_col, idx);
<span class="preprocessor"> #endif</span>
</pre></div><p>Copy the diagonal block to <em>shared memory</em> so that threads can exchange their results. To avoid memory bank conflicts when consecutively accessing the elements of a column we add one column. This trick is discussed in the <em>CUDA Best Practices Guide</em> in the chapter about multiplying a matrix with its transpose.</p>
<div class="fragment"><pre class="fragment">     __shared__ T L[TILE_SIZE][TILE_SIZE+1];
</pre></div><p>To minimize the number of accesses to global memory we copy the matrix entries of the block to shared memory and synchronize all threads within the block before we go on.</p>
<div class="fragment"><pre class="fragment">     L[row][col]= A[idx];
     __syncthreads();
 
     T fac;
</pre></div><p>Now, we can compute the entries of the Cholesky factors. We have to distinguish between diagonal elements i.e. <img class="formulaInl" alt="$ r = c = k$" src="form_24.png"/>, elements of the uppermost row, and the rest. For matrices whose number of rows is not a multiple of <code>TILE_SIZE</code> we have to modify the upper bound of the loop over the diagonal of matrix block.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> k_max = TILE_SIZE;
</pre></div><p>Next, figure out whether we are in the rightmost block column of the matrix. Note that <code>global_pos(0, bo)</code> cannot exceed <code>n_cols</code> due to the way threads get started.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span> (n_cols - global_pos&lt;TILE_SIZE&gt;(0, n_blocks_done) &lt; TILE_SIZE)
         k_max = n_cols%TILE_SIZE;
 
<span class="preprocessor"> #ifdef INDEX_BOUND_DEBUG</span>
<span class="preprocessor"></span>       printf(<span class="stringliteral">&quot;k_max : %d\n&quot;</span>, k_max);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
     <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k=0; k &lt; k_max; k++)
     {
         __syncthreads();
</pre></div><p>Compute the inverse square root of diagonal element <img class="formulaInl" alt="$1/\sqrt{A_{kk}}$" src="form_25.png"/> using the device function defined above, and store the result in a register. The device function is necessary to encapsulate the precision-dependent function names of the reciprocal square root. Precomputing <img class="formulaInl" alt="$1/\sqrt{A_{kk}}$" src="form_25.png"/> allows to map the division by <img class="formulaInl" alt="$\sqrt{A_{kk}}$" src="form_26.png"/> of the off-diagonal elements of <img class="formulaInl" alt="$L$" src="form_5.png"/> to a multiplication which is computationally cheaper.</p>
<div class="fragment"><pre class="fragment">         fac = inv_sqrt(L[k][k]);
         __syncthreads();
</pre></div><p>We compute the diagonal element and the row to its right-hand side </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{eqnarray} L_{ck} = fac \cdot A_{ck} &amp; = &amp; \left\lbrace \begin{array}{ll} \sqrt{A_{kk}} &amp; c = k \\ \frac{A_{ck}}{\sqrt{A_{kk}}} &amp; c > k \end{array} \right. \end{eqnarray}" src="form_27.png"/>
</p>
<div class="fragment"><pre class="fragment">         <span class="keywordflow">if</span> ((row==k)&amp;&amp;(col&gt;=k)) L[col][row]=(L[col][row])*fac;
</pre></div><p>Again we have to synchronize.</p>
<div class="fragment"><pre class="fragment">         __syncthreads();
</pre></div><p>Next, compute the lower left triangle.</p>
<p>The off-diagonal entries follow from </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{eqnarray} s_k &amp; = &amp; L_{ck}L_{rk} \\ s_c &amp; = &amp; \sum_{k=c+1}^{TILE\_SIZE}(-s_k) \\ L_{rc} &amp; = &amp; \frac{1}{\sqrt{A_{kk}}} \left(A_{rc} + s_c \right)\,. \end{eqnarray}" src="form_28.png"/>
</p>
<p> We only have to perform the first of these steps, i.e. computing <img class="formulaInl" alt="$s_k$" src="form_29.png"/>, and one addition in the sum. Hence, <img class="formulaInl" alt="$s_c$" src="form_30.png"/> is computed incrementally by the <code>k</code> loop. Instead of storing <img class="formulaInl" alt="$s_c$" src="form_30.png"/>, we subtract the individual terms <img class="formulaInl" alt="$s_k$" src="form_29.png"/> from <img class="formulaInl" alt="$A_{rc}$" src="form_31.png"/> and store the modified <img class="formulaInl" alt="$A_{rc}$" src="form_31.png"/> in the Cholesky factor.</p>
<p>When the condition <code>row</code> == <code>k</code> is true, <code>L</code>[row][col] contains the final value <img class="formulaInl" alt="$A_{rc} + s_c$" src="form_32.png"/>. The multiplication with <code>fac</code>, that is <img class="formulaInl" alt="$1/\sqrt{A_{kk}}$" src="form_25.png"/>, is performed implicitly during this process.</p>
<div class="fragment"><pre class="fragment">         <span class="keywordflow">if</span> ((row&gt;=col)&amp;&amp;(col&gt;k)) L[row][col] -= L[col][k]*L[row][k];
     }
 
     __syncthreads();
</pre></div><p>At the end, we copy the result back to global memory.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span> (row&gt;=col) A[idx] = L[row][col];
 
 
<span class="preprocessor"> #ifdef INDEX_BOUND_DEBUG</span>
<span class="preprocessor"></span>     printf(<span class="stringliteral">&quot;A_%d : %f\n&quot;</span>, idx,  L[row][col]);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"> }</span>
</pre></div><p><a class="anchor" id="Kernelstrip_update"></a> </p>
<h4>Kernel: strip_update</h4>
<p>This kernel updates <img class="formulaInl" alt="$L_{ij}$" src="form_33.png"/> in the columns below diagonal block <em>j</em>.</p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>: global Matrix </td></tr>
    <tr><td class="paramname">n_blocks_done</td><td>: distance from the diagonal block just factorized. </td></tr>
    <tr><td class="paramname">n_cols</td><td>: length of a row of <img class="formulaInl" alt="$A$" src="form_21.png"/>.</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keywordtype">int</span> TILE_SIZE&gt;
 __global__
 <span class="keywordtype">void</span>
 __strip_update(T *A, <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim)
 {
</pre></div><p><code>boffy</code> und <code>boffx</code> are the coordinates of the matrix block this thread works on.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> boffy=n_blocks_done;
</pre></div><p>The "+1" is needed since <code>n_blocks_done</code> denotes the position of the left uppermost block.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> boffx = blockIdx.x + boffy + 1;
</pre></div><p>As in the last kernel.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> col = threadIdx.x;
     <span class="keywordtype">int</span> row = threadIdx.y;
</pre></div><p>Again avoid bank conficts by adding a column</p>
<div class="fragment"><pre class="fragment">     __shared__ T topleft[TILE_SIZE][TILE_SIZE+1];
     __shared__ T workingmat[TILE_SIZE][TILE_SIZE+1];
</pre></div><p>Grab the data of the diagonal block just factorized ...</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> global_row = global_pos&lt;TILE_SIZE&gt;(row,n_blocks_done);
     <span class="keywordtype">int</span> global_col = global_pos&lt;TILE_SIZE&gt;(col,n_blocks_done);
</pre></div><p>For matrices whose number of rows is not a multiple of <code>TILE_SIZE</code> we have to take care that thread do not work on non-existing matrix entries.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span> ((global_row &gt;= n_cols) || (global_col &gt;= n_cols))
         <span class="keywordflow">return</span>;
 
     <span class="keywordtype">int</span> idx = lex_index_2D(global_row, global_col, leading_dim);
 
     topleft[row][col]=A[idx];
</pre></div><p>and the transposed block which is to be processed</p>
<div class="fragment"><pre class="fragment">     global_row = global_pos&lt;TILE_SIZE&gt;(row,boffx);
     <span class="keywordtype">int</span> idx_w = lex_index_2D(global_row, global_col, leading_dim);
 
     workingmat[col][row] = A[idx_w];
 
     __syncthreads();
 
 
     <span class="keywordtype">int</span> k_max = TILE_SIZE;
</pre></div><p>Do step 2.2 of the algorithm given in the introduction. Each thread works on one column.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span>(row==0)
         <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k=0; k &lt; k_max; k++)
         {
             T sum=0.;
             <span class="keywordflow">for</span> (<span class="keywordtype">int</span> m = 0; m &lt; k; m++)
                 sum += topleft[k][m]*workingmat[m][col];
 
             workingmat[k][col] = (workingmat[k][col] - sum)/topleft[k][k];
         }
 
     __syncthreads();
 
     A[idx_w] = workingmat[col][row];
 }
</pre></div><p><a class="anchor" id="Kerneldiag_update"></a> </p>
<h4>Kernel: diag_update</h4>
<p>This Kernel computes the contribution of the last factorized diagonal block to the auxiliary variable <code>sum</code> in step 2.1. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>: global matrix </td></tr>
    <tr><td class="paramname">n_blocks_done</td><td>: block offset from upper left corner of the matrix. </td></tr>
    <tr><td class="paramname">n_cols</td><td>: length of a row of <img class="formulaInl" alt="$A$" src="form_21.png"/>.</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keywordtype">int</span> TILE_SIZE&gt;
 __global__
 <span class="keywordtype">void</span>
 __diag_update(T *A, <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim)
 {
</pre></div><p>Finding the global indices and setup of the shared memory is as above.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> boffx = blockIdx.x + n_blocks_done + 1;
 
     <span class="keywordtype">int</span> col = threadIdx.x;
     <span class="keywordtype">int</span> row = threadIdx.y;
 
     <span class="keywordtype">int</span> global_row = global_pos&lt;TILE_SIZE&gt;(row, boffx);
     <span class="keywordtype">int</span> global_col = global_pos&lt;TILE_SIZE&gt;(col, n_blocks_done);
</pre></div><p>For matrices whose number of rows is not a multiple of <code>TILE_SIZE</code> we have to take care that threads do not work on non-existing matrix entries.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span> ((global_row &gt;= n_cols) || (global_col &gt;= n_cols))
         <span class="keywordflow">return</span>;
 
     <span class="keywordtype">int</span> idx = lex_index_2D(global_row, global_col, leading_dim);
 
     __shared__ T left[TILE_SIZE][TILE_SIZE+1];
</pre></div><p>Copy and synchronize.</p>
<div class="fragment"><pre class="fragment">     left[row][col]= A[idx];
 
     __syncthreads();
</pre></div><p>The thread with index (row, col) computes the corresponding term from step 2.1.</p>
<div class="fragment"><pre class="fragment">     T sum = 0.f;
 
 
     <span class="keywordtype">int</span> k_max = TILE_SIZE;
 
     <span class="keywordflow">if</span>(row&gt;=col)
     {
         <span class="keywordflow">for</span>(<span class="keywordtype">int</span> kk=0; kk&lt;k_max; kk++) sum += left[row][kk]*left[col][kk];
</pre></div><p>Subtract the result from the global Matrix entry.</p>
<div class="fragment"><pre class="fragment">         global_col = global_pos&lt;TILE_SIZE&gt;(col, boffx);
         idx = lex_index_2D(global_row, global_col, leading_dim);
 
         A[idx] -= sum;
     }
 }
</pre></div><p><a class="anchor" id="Kernello_update"></a> </p>
<h4>Kernel: lo_update</h4>
<p>This kernel applies the intermediate results produced by strip_update() and diag_update() to the rest of the matrix. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>: global matrix </td></tr>
    <tr><td class="paramname">n_blocks_done</td><td>: Block-offset </td></tr>
    <tr><td class="paramname">n_blocks</td><td>: Number of blocks, in which a row of <code>A</code> is subdivided. </td></tr>
    <tr><td class="paramname">n_cols</td><td>: length of a row of <code>A</code>.</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keywordtype">int</span> TILE_SIZE&gt;
 __global__
 <span class="keywordtype">void</span>
 __lo_update(T *A, <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_blocks, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim)
 {
</pre></div><p>Start with local and global Indices of the entry this thread works on ...</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> col = threadIdx.x;
     <span class="keywordtype">int</span> row = threadIdx.y;
 
     <span class="keywordtype">int</span> boffy=blockIdx.y+n_blocks_done+1;
     <span class="keywordtype">int</span> boffx=boffy+1;
 
     __shared__ T left[TILE_SIZE][TILE_SIZE];
</pre></div><p>The extra column is needed only for <code>upt</code>.</p>
<div class="fragment"><pre class="fragment">     __shared__ T upt[TILE_SIZE][TILE_SIZE+1];
</pre></div><p>Start reading data at the lower left.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> global_row_src = global_pos&lt;TILE_SIZE&gt;(row, boffy);
     <span class="keywordtype">int</span> global_col_src = global_pos&lt;TILE_SIZE&gt;(col, n_blocks_done);
</pre></div><p>For matrices whose number of rows is not a multiple of <code>TILE_SIZE</code> we have to take care that thread do not work on non-existing matrix entries.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span> ((global_row_src &gt;= n_cols) || (global_col_src &gt;= n_cols))
         <span class="keywordflow">return</span>;
 
     <span class="keywordtype">int</span> idx = lex_index_2D(global_row_src, global_col_src, leading_dim);
 
     upt[row][col]=A[idx];
     __syncthreads();
 
 
<span class="preprocessor"> #ifdef nSCHUR_DEBUG</span>
<span class="preprocessor"></span>     <span class="keywordflow">if</span> (row == 0 &amp;&amp; col == 0)
     printf(<span class="stringliteral">&quot;%s block (%d,%d):\n------------------------\n&quot;</span>,
            __FUNCTION__, blockIdx.x, blockIdx.y);
     __syncthreads();
 
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
     <span class="keywordflow">for</span> (;boffx&lt;n_blocks;boffx++)
     {
         <span class="keywordtype">int</span> global_row = global_pos&lt;TILE_SIZE&gt;(row, boffx);
         idx = lex_index_2D(global_row, global_col_src, leading_dim);
</pre></div><p>Reset shared memory.</p>
<div class="fragment"><pre class="fragment">         left[row][col]= 0.;
         left[row][col]=A[idx];
 
<span class="preprocessor"> #ifdef SCHUR_DEBUG</span>
<span class="preprocessor"></span>         printf(<span class="stringliteral">&quot;loading  left[%d][%d]=A[%d] == %f\n&quot;</span>, row, col, idx, A[idx]);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>         __syncthreads();
 
         <span class="keywordflow">if</span> (global_row &lt; n_cols)
         {
             T matrixprod=0.f;
</pre></div><p>The thread with index (row, col) computes the corresponding term from step 2.2.</p>
<div class="fragment"><pre class="fragment">             <span class="keywordtype">int</span> k_max = TILE_SIZE;
 
             <span class="keywordflow">for</span> (<span class="keywordtype">int</span> kk=0;kk&lt;k_max;kk++)
             {
                 matrixprod+=left[row][kk]*upt[col][kk];
 
<span class="preprocessor"> #ifdef SCHUR_DEBUG</span>
<span class="preprocessor"></span>                 printf(<span class="stringliteral">&quot;row, col : (%d, %d), g_row,g_col : (%d, %d), idx : %d, mprod : %f, L_r%d : %f, U_1c : %f \n &quot;</span>,
                        row, col, global_row, global_col_src, idx, matrixprod, kk, left[row][kk], upt[col][kk]);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>             }
 
             <span class="keywordtype">int</span> global_col = global_pos&lt;TILE_SIZE&gt;(col, boffy);
 
             <span class="keywordflow">if</span> (global_col &lt; n_cols)
             {
                 idx = lex_index_2D(global_row, global_col, leading_dim);
                 A[idx] -= matrixprod;
 
<span class="preprocessor"> #ifdef SCHUR_DEBUG</span>
<span class="preprocessor"></span>                 <span class="keywordflow">if</span> (row == 0 &amp;&amp; col == 0)
                     printf(<span class="stringliteral">&quot;%s:\n------------------------\n&quot;</span>, __FUNCTION__);
                 __syncthreads();
 
                 printf(<span class="stringliteral">&quot;row, col : (%d, %d), g_row,g_col : (%d, %d), idx : %d, mprod : %f\n &quot;</span>,
                        row, col, global_row, global_col, idx, matrixprod);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>             }
         }
     }
 
 }
 
 } <span class="comment">// namespace Chol END</span>
 
 } <span class="comment">// namespace step1 END</span>
</pre></div><p><a class="anchor" id="Wrapperfunctions"></a> </p>
<h3>Wrapper functions</h3>
<p>The wrapper functions mainly repeat the arguments of the kernels. Besides that they manage the set up of the thread blocks and grids. Due to the tiling of matrix all kernels will be executed by grids of 2-dimensional thread blocks. The block size reflects the tiling. The grids are always 1-dimensional since the off-diagonal update operations are effectively independent updates of several rows or columns at once.</p>
<p><a class="anchor" id="Functionblackbox"></a> </p>
<h4>Function: blackbox</h4>
<p>This function provides a complete GPU-based implementation of the Cholesky factorization and is an example of how to call several kernels from one wrapper function.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> step1::Kernels&lt;T&gt;::Cholesky::blackbox(T * a_d, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim)
 {
     cudaError_t error;
</pre></div><p>Compute the number of blocks needed to cover the matrix.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> n_blocks = (n_cols+int(DEFAULT_TILE_SIZE)-1)/<span class="keywordtype">int</span>(DEFAULT_TILE_SIZE);
</pre></div><p>A thread-block should be as large as a matrix block.</p>
<div class="fragment"><pre class="fragment">     dim3 threads(DEFAULT_TILE_SIZE, DEFAULT_TILE_SIZE);
 
     dim3 logrid;
 
     <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=n_blocks; i&gt;2; --i)
     {
         logrid.x=1;
         logrid.y=i-2;
 
         dim3 stripgrid(i-1);
</pre></div><p>For the diagonal block we need only one block, thus the grid size is 1.</p>
<div class="fragment"><pre class="fragment">         Chol::__factorize_diag_block&lt;T, DEFAULT_TILE_SIZE&gt;
                 &lt;&lt;&lt;1, threads&gt;&gt;&gt;(a_d, n_blocks-i, n_cols, leading_dim);
         cudaThreadSynchronize();
 
         Chol::__strip_update&lt;T, DEFAULT_TILE_SIZE&gt;
                 &lt;&lt;&lt;stripgrid, threads&gt;&gt;&gt;(a_d, n_blocks-i, n_cols, leading_dim);
         cudaThreadSynchronize();
 
         Chol::__diag_update&lt;T, DEFAULT_TILE_SIZE&gt;
                 &lt;&lt;&lt;stripgrid, threads&gt;&gt;&gt;(a_d, n_blocks-i, n_cols, leading_dim);
         cudaThreadSynchronize();
         Chol::__lo_update&lt;T, DEFAULT_TILE_SIZE&gt;
                 &lt;&lt;&lt; logrid, threads &gt;&gt;&gt;(a_d, n_blocks-i, n_blocks, n_cols, leading_dim);
         cudaThreadSynchronize();
     }
</pre></div><p>For the last 2x2-Block submatrix <code>lo_update()</code> is not needed anymore.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span>(n_blocks&gt;1)
     {
         Chol::__factorize_diag_block&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;1, threads&gt;&gt;&gt;(a_d, n_blocks-2, n_cols,
                                                    leading_dim);
         cudaThreadSynchronize();
 
         Chol::__strip_update&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;1, threads&gt;&gt;&gt;(a_d, n_blocks-2, n_cols, leading_dim);
         cudaThreadSynchronize();
 
         Chol::__diag_update&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;1, threads&gt;&gt;&gt;(a_d, n_blocks-2, n_cols, leading_dim);
         cudaThreadSynchronize();
 
     }
</pre></div><p>Factorize the last diagonal block.</p>
<div class="fragment"><pre class="fragment">     Chol::__factorize_diag_block&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;1, threads&gt;&gt;&gt;(a_d, n_blocks-1, n_cols, leading_dim);
</pre></div><p>Make all threads finish before the host is allowed to go on. Remember, kernel starts are asynchronous.</p>
<div class="fragment"><pre class="fragment">     cudaThreadSynchronize();
</pre></div><p>... check error state of GPU.</p>
<div class="fragment"><pre class="fragment">     error=cudaGetLastError();
     <span class="keywordflow">if</span> (error != cudaSuccess)
     {
         printf(<span class="stringliteral">&quot;     Error code %d: %s.\n&quot;</span>,error,cudaGetErrorString(error));
         exit(-1);
     }
 }
</pre></div><p><a class="anchor" id="Functionsingle_thread"></a> </p>
<h4>Function: single_thread</h4>
<p>This function wraps the kernel call.</p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">a_d</td><td>: Pointer to device memory containing the matrix entries. </td></tr>
    <tr><td class="paramname">n_rows</td><td>: the number of rows of the matrix. This implies the number of columns and total number of elements as the matrix behind <code>a_d</code> is supposed to be square.</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> step1::Kernels&lt;T&gt;::Cholesky::single_thread(T * a_d, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim)
 {
</pre></div><p>Start the kernel which is supposed to work only in one thread.</p>
<div class="fragment"><pre class="fragment">     Chol::__single_thread&lt;&lt;&lt;1,1&gt;&gt;&gt;(a_d, n_cols, leading_dim);
 }
</pre></div><p><a class="anchor" id="Functionfactorize_diag_block"></a> </p>
<h4>Function: factorize_diag_block</h4>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 cudaError_t step1::Kernels&lt;T&gt;::Cholesky::factorize_diag_block(T * a_d,
                                                               <span class="keywordtype">int</span> n_blocks_done,
                                                               <span class="keywordtype">int</span> n_cols,
                                                               <span class="keywordtype">int</span> leading_dim)
 {
     dim3 threads(DEFAULT_TILE_SIZE, DEFAULT_TILE_SIZE);
     Chol::__factorize_diag_block&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;1, threads&gt;&gt;&gt;(a_d, n_blocks_done,  n_cols, leading_dim);
     cudaThreadSynchronize();
 
     <span class="keywordflow">return</span> cudaGetLastError();
 }
</pre></div><p><a class="anchor" id="Functionstrip_update"></a> </p>
<h4>Function: strip_update</h4>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span>
 step1::Kernels&lt;T&gt;::Cholesky::strip_update(T *a_d,
                                           <span class="keywordtype">int</span> n_blocks_done,
                                           <span class="keywordtype">int</span> n_remaining_blocks, <span class="keywordtype">int</span> n_cols,
                                           <span class="keywordtype">int</span> leading_dim)
 {
     cudaError_t error;
     dim3 stripgrid(n_remaining_blocks-1);
     dim3 threads(DEFAULT_TILE_SIZE, DEFAULT_TILE_SIZE);
 
     Chol::__strip_update&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;stripgrid, threads&gt;&gt;&gt;(a_d,
                                                  n_blocks_done, n_cols,
                                                  leading_dim);
</pre></div><p>Every update must be synchronized, because we can't continue the factorization before having updated the submatrix of A.</p>
<div class="fragment"><pre class="fragment">     cudaThreadSynchronize();
</pre></div><p>The last task is to query the error state of the CUDA context.</p>
<div class="fragment"><pre class="fragment">     error=cudaGetLastError();
     <span class="keywordflow">if</span> (error != cudaSuccess)
     {
         printf(<span class="stringliteral">&quot;     Error code %d: %s.\n&quot;</span>,error,cudaGetErrorString(error));
</pre></div><p>In case of an error</p>
<div class="fragment"><pre class="fragment">         exit(-1);
     }
 }
</pre></div><p><a class="anchor" id="Functiondiag_update"></a> </p>
<h4>Function: diag_update</h4>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> step1::Kernels&lt;T&gt;::Cholesky::diag_update(T *a_d,
                                               <span class="keywordtype">int</span> n_blocks_done,
                                               <span class="keywordtype">int</span> n_remaining_blocks,
                                               <span class="keywordtype">int</span> n_cols,
                                               <span class="keywordtype">int</span> leading_dim)
 {
     cudaError_t error;
     dim3 stripgrid(n_remaining_blocks-1);
     dim3 threads(DEFAULT_TILE_SIZE, DEFAULT_TILE_SIZE);
 
     Chol::__diag_update&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;stripgrid, threads&gt;&gt;&gt;(a_d,
                                                 n_blocks_done, n_cols,
                                                 leading_dim);
 
     cudaThreadSynchronize();
     error=cudaGetLastError();
     <span class="keywordflow">if</span> (error != cudaSuccess)
     {
         printf(<span class="stringliteral">&quot;     Error code %d: %s.\n&quot;</span>,error,cudaGetErrorString(error));
         exit(-1);
     }
 }
</pre></div><p><a class="anchor" id="Functionlo_update"></a> </p>
<h4>Function: lo_update</h4>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> step1::Kernels&lt;T&gt;::Cholesky::lo_update(T *a_d,
                                             <span class="keywordtype">int</span> n_blocks_done,
                                             <span class="keywordtype">int</span> n_blocks,
                                             <span class="keywordtype">int</span> n_remaining_blocks ,
                                             <span class="keywordtype">int</span> n_cols,
                                             <span class="keywordtype">int</span> leading_dim)
 {
     cudaError_t error;
     dim3 logrid;
     logrid.x=1;
     logrid.y=n_remaining_blocks-2;
     dim3 threads(DEFAULT_TILE_SIZE, DEFAULT_TILE_SIZE);
 
     Chol::__lo_update&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt; logrid, threads &gt;&gt;&gt;(a_d,
                                              n_blocks_done, n_blocks,  n_cols, leading_dim);
     cudaThreadSynchronize();
     error=cudaGetLastError();
     <span class="keywordflow">if</span> (error != cudaSuccess)
     {
         printf(<span class="stringliteral">&quot;     Error code %d: %s.\n&quot;</span>,error,cudaGetErrorString(error));
         exit(-1);
     }
 }
</pre></div><p>This 2-liner provides all possible template sepcializations for real-valued matrices.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> <span class="keyword">class </span>step1::Kernels&lt;float&gt;;
 <span class="keyword">template</span> <span class="keyword">class </span>step1::Kernels&lt;double&gt;;
 
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CUDADriver_STEP_1_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define CUDADriver_STEP_1_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;step-1/SimParams.h&gt;</span>
 
<span class="preprocessor"> #include &lt;lac/FullMatrixAccessor.h&gt;</span>
<span class="preprocessor"> #include &lt;lac/blas++.h&gt;</span>
 
<span class="preprocessor"> #include &lt;step-1/cuda_kernel_wrapper_step-1.cu.h&gt;</span>
</pre></div><p>Each example program is put into a separate namespace so that it is easier to combine classes from different examples.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">namespace </span>step1 {
</pre></div><p><a class="anchor" id="ClassCUDADriver"></a> </p>
<h3>Class: CUDADriver</h3>
<p>This class is responsible for managing host-device communication, mainly data transfer and invoking kernels. To simplify host-device data transfer, we use our SciPal-library which encapsulates all the details. The implementation of the kernels is inherited privately in order to express that this class is <em>implemented with</em> the Kernels class.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">class </span>CUDADriver : <span class="keyword">private</span> Kernels&lt;T&gt; {
 
 <span class="keyword">public</span>:
</pre></div><p>Some typedefs to make life easier.</p>
<div class="fragment"><pre class="fragment">     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::blas_wrapper_type BW;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::FullMatrixAccessor FullMatrixAccessor;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::Matrix Matrix;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::SubMatrix SubMatrix;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::MatrixSubCol MatrixSubCol;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::Vector Vector;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::SubColVector SubColVector;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::SubVectorBase SubVectorBase;
 
     <span class="keyword">typedef</span> std::map&lt;std::string,double&gt; TimerName2Value;
 
 
 
     CUDADriver(<span class="keyword">const</span> SimParams &amp;p);
 
 
 
     <span class="keywordtype">double</span> factorize(FullMatrixAccessor&amp; A);
 
     <span class="keywordtype">double</span> factorize(dealii::FullMatrix&lt;T&gt; &amp;A);
 
     <span class="keywordtype">void</span> chol_fac(FullMatrixAccessor&amp; A, TimerName2Value&amp; times);
 
     <span class="keywordtype">void</span> lu_fac(FullMatrixAccessor&amp; A, TimerName2Value&amp; times);
 
     <span class="keywordtype">void</span> single_thread_cholesky(FullMatrixAccessor&amp; A);
 
 
 <span class="keyword">private</span>:
     Matrix A_d;
 
     <span class="keyword">const</span> SimParams * params;
 };
 
 } <span class="comment">// namespace step1 END</span>
 
<span class="preprocessor"> #endif // CUDADriver_STEP_1_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CUDA_DRIVER_STEP_1_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define CUDA_DRIVER_STEP_1_HH</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;base/CUDATimer.h&gt;</span>
 
<span class="preprocessor"> #include &lt;step-1/cuda_driver_step-1.h&gt;</span>
 
<span class="preprocessor"> #include &lt;step-1/cuda_kernel_wrapper_step-1.cu.h&gt;</span>
 
 
 
<span class="preprocessor"> #include &lt;QTime&gt;</span>
</pre></div><p><a class="anchor" id="ConstructorCUDADriver"></a> </p>
<h4>Constructor: CUDADriver</h4>
<p>In this case the constructor of the driver class does not do much.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 step1::CUDADriver&lt;T&gt;::CUDADriver(<span class="keyword">const</span> SimParams &amp;p)
     :
       params(&amp;p)
 {}
</pre></div><p><a class="anchor" id="Functionfactorize"></a> </p>
<h4>Function: factorize</h4>
<p>This function copies the data from the host to the device, starts the CUDA-based factorization and copies the result back to the host. There are two version of this function. The first one executes the Cholesky decomposition as a whole. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>: Matrix to factorize </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd>Number of seconds spent in GPU version of Cholesky factorization. NOT milliseconds.</dd></dl>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">double</span>
 step1::CUDADriver&lt;T&gt;::factorize(FullMatrixAccessor&amp; A)
 {
</pre></div><p>Copy from host to device</p>
<div class="fragment"><pre class="fragment">     this-&gt;A_d = A;
 
     QTime t;
     t.start();
</pre></div><p>Call the multi-threaded factorization. To do this, we have to dereference the Matrix object and retrieve the bare pointer to the array containing the matrix entries.</p>
<div class="fragment"><pre class="fragment">     this-&gt;cholesky.blackbox(this-&gt;A_d.array().val(), this-&gt;A_d.n_cols(), this-&gt;A_d.leading_dim );
</pre></div><p>Convert milliseconds into seconds. Cf. QT-doc.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">double</span> kernel_time = t.elapsed()/1000.;
</pre></div><p>Finally, copy the result from device back to host.</p>
<div class="fragment"><pre class="fragment">     A = this-&gt;A_d;
 
     <span class="keywordflow">return</span> kernel_time;
 }
</pre></div><p><a class="anchor" id="Functionchol_fac"></a> </p>
<h4>Function: chol_fac</h4>
<p>The second version allows to measure the performance of the different parts of the algorithm</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span>
 step1::CUDADriver&lt;T&gt;::chol_fac(FullMatrixAccessor&amp; A, TimerName2Value&amp; times)
 {
</pre></div><p>Copy from host to device</p>
<div class="fragment"><pre class="fragment">     this-&gt;A_d = A;
</pre></div><p>For timing measurements we use</p>
<div class="fragment"><pre class="fragment">     QTime t;
</pre></div><p>We dereference the Matrix object and retrieve the bare pointer to the linear array containing the matrix entries.</p>
<div class="fragment"><pre class="fragment">     T* a_d = this-&gt;A_d.array().val();
 
     <span class="keywordtype">int</span> n_rows = this-&gt;A_d.n_rows();
 
     <span class="keywordtype">int</span> leading_dim = this-&gt;A_d.leading_dim;
</pre></div><p>Compute the number of blocks needed to cover the matrix.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> n_blocks = (A.n_rows()+int(DEFAULT_TILE_SIZE)-1)/<span class="keywordtype">int</span>(DEFAULT_TILE_SIZE);
 
     times[<span class="stringliteral">&quot;factorize_diagonal_block&quot;</span>] = 0.;
     times[<span class="stringliteral">&quot;strip_update&quot;</span>] = 0.;
     times[<span class="stringliteral">&quot;diag_update&quot;</span>] = 0.;
     times[<span class="stringliteral">&quot;lo_update&quot;</span>] = 0.;
</pre></div><p>Loop over the virtual diagonal blocks of the matrix.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = n_blocks; i &gt; 2; --i)
     {
         t.restart();
 
 
         cudaError_t error = this-&gt;cholesky.factorize_diag_block(a_d, n_blocks-i, n_rows, leading_dim);
 
         times[<span class="stringliteral">&quot;factorize_diagonal_block&quot;</span>]+=t.elapsed();
 
         AssertThrow(error == cudaSuccess, dealii::ExcMessage( cudaGetErrorString(error) ) );
 
 
         t.restart();
         this-&gt;cholesky.strip_update(a_d, n_blocks-i, i, n_rows, leading_dim);
 
         times[<span class="stringliteral">&quot;strip_update&quot;</span>]+=t.elapsed();
 
 
         t.restart();
         this-&gt;cholesky.diag_update(a_d, n_blocks-i, i, n_rows, leading_dim);
 
         times[<span class="stringliteral">&quot;diag_update&quot;</span>]+=t.elapsed();
 
 
         t.restart();
         this-&gt;cholesky.lo_update(a_d, n_blocks-i, n_blocks, i, n_rows, leading_dim);
 
         times[<span class="stringliteral">&quot;lo_update&quot;</span>]+=t.elapsed();
     }
</pre></div><p>For the last 2x2-Block submatrix <code>lo_update()</code> is not needed anymore.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span>(n_blocks&gt;1)
     {
         this-&gt;cholesky.factorize_diag_block(a_d, n_blocks-2, n_rows, leading_dim);
 
         this-&gt;cholesky.strip_update(a_d, n_blocks-2, 2, n_rows, leading_dim);
 
         this-&gt;cholesky.diag_update(a_d, n_blocks-2, 2,  n_rows, leading_dim);
     }
</pre></div><p>Factorize the last diagonal block.</p>
<div class="fragment"><pre class="fragment">     std::cout &lt;&lt; <span class="stringliteral">&quot;Cholesky decomposition...&quot;</span> &lt;&lt; std::endl;
     this-&gt;cholesky.factorize_diag_block(a_d, n_blocks-1, n_rows, leading_dim);
</pre></div><p>Finally, copy the result from device back to host.</p>
<div class="fragment"><pre class="fragment">     A = this-&gt;A_d;
 }
</pre></div><p><a class="anchor" id="Functionsingle_thread_cholesky"></a> </p>
<h4>Function: single_thread_cholesky</h4>
<p>This factorization method uses only one thread on the GPU. This demonstrates that CUDA can be basically used like C. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>: Matrix to factorize</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span>
 step1::CUDADriver&lt;T&gt;::single_thread_cholesky(FullMatrixAccessor&amp; A)
 {
</pre></div><p>Copy from host to device</p>
<div class="fragment"><pre class="fragment">     this-&gt;A_d = A;
</pre></div><p>Call the single-threaded factorization. To this end, we have to dereference the Matrix object and retrieve the bare pointer to the array containing the matrix entries.</p>
<div class="fragment"><pre class="fragment">     this-&gt;cholesky.single_thread(this-&gt;A_d.array().val(),
                                  this-&gt;A_d.n_rows(), this-&gt;A_d.leading_dim );
</pre></div><p>Finally, copy the result from device back to host.</p>
<div class="fragment"><pre class="fragment">     A = this-&gt;A_d;
 }
 
<span class="preprocessor"> #endif // CUDA_DRIVER_STEP_1_HH</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef SIM_PARAMETER_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define SIM_PARAMETER_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;deal.II/base/parameter_handler.h&gt;</span>
 
<span class="preprocessor"> #include &lt;QDir&gt;</span>
 
 <span class="keyword">namespace </span>step1 {
</pre></div><p><a class="anchor" id="ClassSimParams"></a> </p>
<h3>Class: SimParams</h3>
<p>This structure contains all parameters necessary for controling the global test properties, i.e. precision and what BLAS to use. The documentation strings given in the declare function provide a detailed documentation of the individual attributes of this class and are available at run-time as well.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">struct </span>SimParams {
 
     SimParams() {}
 
     <span class="keyword">static</span> <span class="keywordtype">void</span> declare(dealii::ParameterHandler &amp; prm);
 
     <span class="keywordtype">void</span> <span class="keyword">get</span>(dealii::ParameterHandler &amp; prm);
 
     <span class="keywordtype">int</span>
     device,
     matrix_low,
     matrix_high,
     step_size,
     average_runs;
 
     <span class="keywordtype">bool</span> use_double;
 
     QDir run_dir;
 
 <span class="keyword">private</span>:
</pre></div><p>As usual, inhibit automatic generation of copy ctor and assignment operator.</p>
<div class="fragment"><pre class="fragment">     SimParams(<span class="keyword">const</span> SimParams&amp; / *other* /) {}
 
     SimParams&amp; operator= (<span class="keyword">const</span> SimParams&amp; / *other* /)
     {
         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
     }
 
 };
 }
 
 
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef SIM_PARAMETER_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define SIM_PARAMETER_HH</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;deal.II/base/parameter_handler.h&gt;</span>
<span class="preprocessor"> #include &lt;step-1/SimParams.h&gt;</span>
</pre></div><p><a class="anchor" id="Functiondeclare"></a> </p>
<h4>Function: declare</h4>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">void</span>
 step1::SimParams::declare(dealii::ParameterHandler &amp; prm)
 {
     prm.enter_subsection(<span class="stringliteral">&quot;Simulation basics&quot;</span>);
 
     prm.declare_entry(<span class="stringliteral">&quot;Run directory&quot;</span>, <span class="stringliteral">&quot;./test_me&quot;</span>,
                       dealii::Patterns::Anything(),
                       <span class="stringliteral">&quot;Specify a directory where results of &quot;</span>
                       <span class="stringliteral">&quot;the test are to be stored. This can be either &quot;</span>
                       <span class="stringliteral">&quot;an absolute path or path relative to the directory &quot;</span>
                       <span class="stringliteral">&quot;where the program has been started. The default is &quot;</span>
                       <span class="stringliteral">&quot;subdir called test_me-&lt;date&gt; where &lt;date&gt; will be replaced &quot;</span>
                       <span class="stringliteral">&quot;by the date at which the program has been started. &quot;</span>
                       <span class="stringliteral">&quot;this simplifies keeping the projects directory clean &quot;</span>
                       <span class="stringliteral">&quot;&quot;</span>);
 
     prm.leave_subsection();
 
 
     prm.enter_subsection(<span class="stringliteral">&quot;CUDA parameters&quot;</span>);
 
 
     prm.declare_entry(<span class="stringliteral">&quot;Device&quot;</span>, <span class="stringliteral">&quot;0&quot;</span>,
                       dealii::Patterns::Integer(),
                       <span class="stringliteral">&quot;which CUDA-enabled GPU should be used&quot;</span>);
 
     prm.declare_entry(<span class="stringliteral">&quot;Shared Memory&quot;</span>, <span class="stringliteral">&quot;true&quot;</span>,
                       dealii::Patterns::Bool(),
                       <span class="stringliteral">&quot;Whether shared (true) or L1 (false) memory should be used.&quot;</span>);
 
 
     prm.leave_subsection();
 
     prm.enter_subsection(<span class="stringliteral">&quot;Testcase parameters&quot;</span>);
 
     prm.declare_entry(<span class="stringliteral">&quot;Double-Precision&quot;</span>,<span class="stringliteral">&quot;true&quot;</span>,
                       dealii::Patterns::Bool(),
                       <span class="stringliteral">&quot;Decide between double (true) or float (false) precision&quot;</span>);
 
     prm.declare_entry(<span class="stringliteral">&quot;Matrix size - lower limit&quot;</span>, <span class="stringliteral">&quot;256&quot;</span>,
                       dealii::Patterns::Integer(),
                       <span class="stringliteral">&quot;Start value of the range of matrix sizes tested by the simulation&quot;</span>);
 
 
     prm.declare_entry(<span class="stringliteral">&quot;Matrix size - upper limit&quot;</span>, <span class="stringliteral">&quot;513&quot;</span>,
                       dealii::Patterns::Integer(),
                       <span class="stringliteral">&quot;End value of the range of matrix sizes tested by the simulation&quot;</span>);
 
     prm.declare_entry(<span class="stringliteral">&quot;Matrix size - step size&quot;</span>, <span class="stringliteral">&quot;1024&quot;</span>,
                       dealii::Patterns::Integer(),
                       <span class="stringliteral">&quot;Increment for the size of the test matrices&quot;</span>);
 
     prm.declare_entry(<span class="stringliteral">&quot;Average - runs&quot;</span>, <span class="stringliteral">&quot;10&quot;</span>,
                       dealii::Patterns::Integer(),
                       <span class="stringliteral">&quot;Number of runs being used for averaging&quot;</span>);
 
     prm.leave_subsection();
 
 }
</pre></div><p><a class="anchor" id="Functionget"></a> </p>
<h4>Function: get</h4>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">void</span>
 step1::SimParams::get(dealii::ParameterHandler &amp; prm)
 {
     prm.enter_subsection(<span class="stringliteral">&quot;Simulation basics&quot;</span>);
 
     run_dir.setPath(prm.get(<span class="stringliteral">&quot;Run directory&quot;</span>).c_str());
     run_dir.makeAbsolute();
 
     <span class="keywordflow">if</span> (!run_dir.exists())
         run_dir.mkpath(<span class="stringliteral">&quot;.&quot;</span>);
 
     prm.leave_subsection();
 
     prm.enter_subsection(<span class="stringliteral">&quot;CUDA parameters&quot;</span>);
 
     device        = prm.get_integer(<span class="stringliteral">&quot;Device&quot;</span>);
 
     prm.leave_subsection();
 
     prm.enter_subsection(<span class="stringliteral">&quot;Testcase parameters&quot;</span>);
 
 
     use_double   = prm.get_bool(<span class="stringliteral">&quot;Double-Precision&quot;</span>);
 
     matrix_low   = prm.get_integer(<span class="stringliteral">&quot;Matrix size - lower limit&quot;</span>);
 
     matrix_high  = prm.get_integer(<span class="stringliteral">&quot;Matrix size - upper limit&quot;</span>);
 
     step_size    = prm.get_integer(<span class="stringliteral">&quot;Matrix size - step size&quot;</span>);
 
     average_runs = prm.get_integer(<span class="stringliteral">&quot;Average - runs&quot;</span>);
 
 
     prm.leave_subsection();
 
 
 }
 
 
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
</pre></div><p>STL header</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;iostream&gt;</span>
<span class="preprocessor"> #include &lt;vector&gt;</span>
</pre></div><p>QT</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;QThread&gt;</span>
<span class="preprocessor"> #include &lt;QTime&gt;</span>
</pre></div><p>deal.II-components</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;deal.II/base/convergence_table.h&gt;</span>
<span class="preprocessor"> #include &lt;deal.II/base/parameter_handler.h&gt;</span>
<span class="preprocessor"> #include &lt;deal.II/lac/full_matrix.h&gt;</span>
 
<span class="preprocessor"> #include &lt;QDir&gt;</span>
</pre></div><p>Drivers for the GPU part. Include all other header files needed.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;step-1/SimParams.h&gt;</span>
 
<span class="preprocessor"> #include &lt;step-1/cuda_driver_step-1.h&gt;</span>
<span class="preprocessor"> #include &lt;step-1/cuda_driver_step-1.hh&gt;</span>
</pre></div><p>Headers from SciPal.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;lac/FullMatrixAccessor.h&gt;</span>
<span class="preprocessor"> #include &lt;lac/MatrixCreator.h&gt;</span>
 
 
 <span class="keyword">namespace </span>step1 {
</pre></div><p><a class="anchor" id="ClassCholeskyTest"></a> </p>
<h3>Class: CholeskyTest</h3>
<p>This class is responsible for executing the Cholesky factorization in a separate thread. To this end we have to inherit from QThread and overwrite the run()-Function. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">Number</td><td>: type of matrix entries.</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 <span class="keyword">class </span>CholeskyTest : <span class="keyword">public</span> QThread
 {
</pre></div><p>We only want to print small matrices to the console.</p>
<div class="fragment"><pre class="fragment">     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> max_display_size = 20;
 
 <span class="keyword">public</span>:
 
     CholeskyTest(<span class="keywordtype">int</span> n_r,
                  dealii::ConvergenceTable&amp; s_table,
                  <span class="keyword">const</span> SimParams &amp;_params);
 
 <span class="keyword">protected</span>:
 
     <span class="keywordtype">void</span> setup_and_assemble_test_matrix();
 
     <span class="keywordtype">void</span> factorize();
 
     <span class="keywordtype">void</span> check_results();
 
     <span class="keywordtype">void</span> run();
 
 
 
     <span class="keywordtype">int</span> n_rows;
 
     dealii::ConvergenceTable &amp; speedup_table;
 
     dealii::FullMatrix&lt;Number&gt; A, L, L_T;
 
 <span class="keyword">private</span>:
 
     <span class="keyword">const</span> SimParams * params;
 };
</pre></div><p><a class="anchor" id="ClassCholesky"></a> </p>
<h3>Class: Cholesky</h3>
<p>For performance comparisons we also need a CPU-based Cholesky and LU factorization.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">class </span>Cholesky {
 
 <span class="keyword">public</span>:
     <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt; <span class="keyword">static</span> <span class="keywordtype">void</span> cpu(std::vector&lt;std::vector&lt;T&gt; &gt; &amp; A);
 
     <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt; <span class="keyword">static</span> <span class="keywordtype">void</span> cpu_tiled(T* A, <span class="keywordtype">int</span> tile_size);
 
     <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt; <span class="keyword">static</span> <span class="keywordtype">void</span> LLtMult(T * A, <span class="keyword">const</span> T * L, <span class="keywordtype">int</span> n_rows);
 };
</pre></div><p><a class="anchor" id="ConstructorCholeskyTest"></a> </p>
<h4>Constructor: CholeskyTest</h4>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 CholeskyTest&lt;Number&gt;::CholeskyTest(<span class="keywordtype">int</span> n_r,
                                    dealii::ConvergenceTable&amp; s_table,
                                    <span class="keyword">const</span> SimParams &amp;_params)
     :
       n_rows(n_r),
       speedup_table(s_table),
       params(&amp;_params)
 {}
</pre></div><p><a class="anchor" id="Functionsetup_and_assemble_test_matrix"></a> </p>
<h4>Function: setup_and_assemble_test_matrix</h4>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 <span class="keywordtype">void</span> CholeskyTest&lt;Number&gt;::setup_and_assemble_test_matrix()
 {
     this-&gt;A.reinit(n_rows, n_rows);
     this-&gt;L.reinit(n_rows, n_rows);
     this-&gt;L_T.reinit(n_rows, n_rows);
 
     QTime t;
 
     this-&gt;speedup_table.add_value(<span class="stringliteral">&quot;n rows&quot;</span>, n_rows);
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;Initial Cholesky factor deal.II :&quot;</span> &lt;&lt; std::endl;
     std::cout &lt;&lt; <span class="stringliteral">&quot;----------------------------------------------------&quot;</span>
               &lt;&lt; std::endl;
</pre></div><p>For debugging purposes it is useful to have the possibility of factorizing a symmetric and orthogonal matrix like Hadamard matrices.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #ifdef USE_HADAMARD</span>
<span class="preprocessor"></span>     MatrixCreator::extended_hadamard(n_rows, A);
<span class="preprocessor"> #else</span>
<span class="preprocessor">     t.start();</span>
</pre></div><p>Because of the design of the Tmmult-function of the class FullMatrix provided by deal.II we have to compute the transpose of the reference Cholesky factor <img class="formulaInl" alt="$L^T_{rc} = (r+2)(c+2), \quad r = 0,\ldots , n_{rows}-1\,, c = r,\ldots , n_{rows}-1$" src="form_34.png"/></p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> r = 0; r &lt; n_rows; ++r)
         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> c = r; c &lt;n_rows; ++c)
             L(r,c) = 1e-0*(r+2)*(c+2);
 
 
     <span class="keywordflow">if</span>(<span class="keyword">false</span>)
     qDebug(<span class="stringliteral">&quot;Time for CPU-based setup of Cholesky factor : %f s&quot;</span>,
            t.elapsed()/1000.);
 
     <span class="keywordflow">if</span> ( L.n_rows() &lt; max_display_size)
         L.print(std::cout, 10, 5);
     <span class="keywordflow">if</span> ( L.n_rows() &lt; max_display_size)
         std::cout &lt;&lt; std::endl;std::cout &lt;&lt; std::endl;
 
     {
</pre></div><p>At this place it is instrcutive to measure the time needed for copying matrices. To do this, we reinitialize the timer for measuring the copy time.</p>
<div class="fragment"><pre class="fragment">         t.restart();
         L_T.copy_from(L);
         <span class="keywordflow">if</span>(<span class="keyword">false</span>)
         qDebug(<span class="stringliteral">&quot;Time for CPU-based copying of Cholesky factor : %f s&quot;</span>,
                t.elapsed()/1000.);
</pre></div><p>Then we construct the matrix which is to be factorized by computing <img class="formulaInl" alt="$A = L\cdot L^T$" src="form_35.png"/>.</p>
<div class="fragment"><pre class="fragment">         t.restart();
         L_T.Tmmult(A, L, <span class="keyword">false</span>);
         <span class="keywordflow">if</span>(<span class="keyword">false</span>)
         qDebug(<span class="stringliteral">&quot;Time for CPU-based multiplication of Cholesky factor&quot;</span>
                <span class="stringliteral">&quot; : %f s&quot;</span>,
                t.elapsed()/1000.);
</pre></div><p>The Matrix <code>A</code> is backed up, as its recomputation is pretty expensive.</p>
<div class="fragment"><pre class="fragment">         L_T.copy_from(A);
     }
 
     <span class="keywordflow">if</span> ( A.n_rows() &lt; max_display_size)
     {
         std::cout &lt;&lt; <span class="stringliteral">&quot;Matrix to factorize :&quot;</span> &lt;&lt; std::endl;
         std::cout &lt;&lt; <span class="stringliteral">&quot;----------------------------------------------------&quot;</span>
                   &lt;&lt; std::endl;
 
         A.print(std::cout, 10, 5);
 
         std::cout &lt;&lt; std::endl;std::cout &lt;&lt; std::endl;
     }
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
 }
</pre></div><p><a class="anchor" id="Functionrun"></a> </p>
<h4>Function: run</h4>
<p>Initialization and factorization.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 <span class="keywordtype">void</span> CholeskyTest&lt;Number&gt;::run()
 {
</pre></div><p>Prepare the test data.</p>
<div class="fragment"><pre class="fragment">     this-&gt;setup_and_assemble_test_matrix();
</pre></div><p>Timer</p>
<div class="fragment"><pre class="fragment">     QTime t;
     <span class="keywordtype">double</span> cpu_time, gpu_time;
</pre></div><p>Execute CPU-based Cholesky factorization.</p>
<div class="fragment"><pre class="fragment">     FullMatrixAccessor&lt;Number&gt; A_h_cpu(A, <span class="keyword">true</span>);
     {
         t.restart();
</pre></div><p>We need the temporary object <code>A_h</code> to get access to the value array of <code>A</code>.</p>
<div class="fragment"><pre class="fragment">         Cholesky::cpu_tiled&lt;Number&gt;(A_h_cpu.val(), A_h_cpu.n_rows() );
 
 
         cpu_time =  t.elapsed()/1000.;
         <span class="keywordflow">if</span> (<span class="keyword">false</span>)
         qDebug(<span class="stringliteral">&quot;Time for CPU-based Cholesky factorization : %f s&quot;</span>,
                cpu_time);
</pre></div><p>Save timing results in a deal.II convergence table.</p>
<div class="fragment"><pre class="fragment">         this-&gt;speedup_table.add_value(<span class="stringliteral">&quot;CPU factorization&quot;</span>, cpu_time);
         this-&gt;speedup_table.set_precision(<span class="stringliteral">&quot;CPU factorization&quot;</span>, 10);
 
 
         std::cout &lt;&lt; <span class="stringliteral">&quot;CPU-factorized Matrix (lower triangle contains &quot;</span>
                   &lt;&lt; <span class="stringliteral">&quot;transposed Cholesky factor) :&quot;</span> &lt;&lt; std::endl;
         std::cout &lt;&lt; <span class="stringliteral">&quot;----------------------------------------------------&quot;</span>
                   &lt;&lt; std::endl;
 
         <span class="keywordflow">if</span> ( A.n_rows() &lt; max_display_size)
             A_h_cpu.print(); <span class="comment">//std::cout, 10, 5);</span>
 
     }
 
     std::cout &lt;&lt; std::endl;std::cout &lt;&lt; std::endl;
 
 
     Assert( A.n_rows() == A.n_cols(),
             dealii::ExcMessage(<span class="stringliteral">&quot;Matrix not square! Cholesky impossible&quot;</span>));
 
 
     <span class="keywordtype">double</span> kernel_time = 0;
</pre></div><p>Compute the Cholesky factorization on the GPU.</p>
<div class="fragment"><pre class="fragment">     CUDADriver&lt;Number&gt; run(*params);
     t.restart();
     {
         FullMatrixAccessor&lt;Number&gt; A_h(A, <span class="keyword">true</span>);
         kernel_time = run.factorize(A_h);
 
         gpu_time =  t.elapsed()/1000.;
</pre></div><p>For the impatient user dump the results to screen.</p>
<div class="fragment"><pre class="fragment">         <span class="keywordflow">if</span> (<span class="keyword">false</span>)
         qDebug(<span class="stringliteral">&quot;Time for GPU-based Cholesky factorization %f&quot;</span>
                <span class="stringliteral">&quot; including data transfer : %f s\n&quot;</span>
                <span class="stringliteral">&quot;speed up factor factorization : %f netto : %f n_rows : %d\n&quot;</span>,
                kernel_time,
                gpu_time,
                cpu_time/kernel_time,
                cpu_time/gpu_time,
                n_rows);
 
 
         std::cout &lt;&lt; <span class="stringliteral">&quot;GPU-factorized Matrix (lower triangle contains &quot;</span>
                   &lt;&lt; <span class="stringliteral">&quot;transposed Cholesky factor) :&quot;</span> &lt;&lt; std::endl;
         std::cout &lt;&lt; <span class="stringliteral">&quot;----------------------------------------------------&quot;</span>
                   &lt;&lt; std::endl;
 
         <span class="keywordflow">if</span> ( A_h.n_rows() &lt; max_display_size)
             A_h.print(); <span class="comment">//std::cout, 10, 5);</span>
</pre></div><p>Both factorizations should lead to the same result: the original matrix still remains in the upper and the Cholesky factor has appeared in the lower triangle. Thus, taking the norm of their difference should yield a numerical zero.</p>
<div class="fragment"><pre class="fragment">         A_h_cpu -= A_h;
 
         std::cout &lt;&lt; <span class="stringliteral">&quot;difference of factorized matrices &quot;</span>
                         &lt;&lt; <span class="stringliteral">&quot; :&quot;</span> &lt;&lt; std::endl;
               std::cout &lt;&lt; <span class="stringliteral">&quot;----------------------------------------------------&quot;</span>
                         &lt;&lt; std::endl;
 
               <span class="keywordflow">if</span> ( A_h_cpu.n_rows() &lt; max_display_size)
                   A_h_cpu.print(); <span class="comment">//std::cout, 10, 5);</span>
 
               <span class="keywordtype">double</span> F_norm =  A_h_cpu.frobenius_norm();
 
         std::cout &lt;&lt; <span class="stringliteral">&quot;||A_cpu - A_d ||_F = &quot;</span> &lt;&lt; F_norm &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>
                   &lt;&lt; <span class="stringliteral">&quot;||A_cpu - A_d ||_F/n_el = &quot;</span> &lt;&lt; F_norm/A_h_cpu.n_elements() &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>
                   &lt;&lt; <span class="stringliteral">&quot;||A_cpu - A_d ||_F/||A_d||_F = &quot;</span> &lt;&lt; F_norm/A_h.frobenius_norm() &lt;&lt; std::endl;
 
     }
 
     this-&gt;speedup_table.add_value(<span class="stringliteral">&quot;pure GPU fac&quot;</span>, kernel_time);
     this-&gt;speedup_table.set_precision(<span class="stringliteral">&quot;pure GPU fac&quot;</span>, 10);
 
     this-&gt;speedup_table.add_value(<span class="stringliteral">&quot;GPU fac incl data transfer&quot;</span>, gpu_time);
     this-&gt;speedup_table.set_precision(<span class="stringliteral">&quot;GPU fac incl data transfer&quot;</span>, 10);
</pre></div><p>Timing of individual components of the factorization in order to compare manual version against CUBLAS-based variant</p>
<div class="fragment"><pre class="fragment">     FullMatrixAccessor&lt;Number&gt; A_h(A, <span class="keyword">true</span>);
     FullMatrixAccessor&lt;Number&gt; A_original = A_h;
 
     {
         <span class="keyword">typename</span> CUDADriver&lt;Number&gt;::TimerName2Value times;
 
         run.chol_fac(A_h, times);
 
 
         <span class="keyword">typename</span> CUDADriver&lt;Number&gt;::TimerName2Value::const_iterator
                 e=times.begin(),
                 end_t=times.end();
 
         <span class="keywordflow">for</span>( ; e != end_t ; ++e)
         {
             this-&gt;speedup_table.add_value(e-&gt;first, e-&gt;second);
             this-&gt;speedup_table.set_precision(e-&gt;first,10);
         }
     }
     <span class="keywordflow">return</span>;
 }
</pre></div><p><a class="anchor" id="Functioncpu_tiled"></a> </p>
<h4>Function: cpu_tiled</h4>
<p><code>T</code> must be float or double.</p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>: Matrix to factorize. factorization is in-place. Entries must be in the upper triangle including the diagonal.</td></tr>
  </table>
  </dd>
</dl>
<p>The Cholesky factor will be stored in the lower triangle and overwrites the diagonal. This function is identical to the Chol::__singe_thread() kernel.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> Cholesky::cpu_tiled(T* A,
                          <span class="keywordtype">int</span> tile_size)
 {
 
     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> r = 0; r &lt; tile_size; ++r)
     {
</pre></div><p>Compute diagonal entry.</p>
<div class="fragment"><pre class="fragment">         T sum = 0.;
         <span class="keywordtype">int</span> idx;
         <span class="keywordtype">int</span> idx_c;
 
         <span class="keywordflow">for</span> (<span class="keywordtype">int</span> u = 0; u &lt; r; ++u)
         {
             idx = r*tile_size + u;
             sum += A[idx] * A[idx];
         }
         idx = r*tile_size + r;
         A[idx] = sqrt(A[idx] - sum);
 
         <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = r+1; c &lt; tile_size; ++c)
         {
             T tmp = 0.;
 
             <span class="keywordflow">for</span> (<span class="keywordtype">int</span> u = 0; u &lt; r; ++u)
             {
                 idx_c = c*tile_size + u;
                 idx   = r*tile_size + u;
                 tmp += A[idx_c]*A[idx];
             }
 
             idx_c = c*tile_size + r;
             idx   = r*tile_size + c;
             A[idx_c]  = A[idx] - tmp;
             A[idx_c] /= A[r*tile_size + r];
         }
     }
 }
</pre></div><p><a class="anchor" id="FunctionLLtMult"></a> </p>
<h4>Function: LLtMult</h4>
<p>Computes the original matrix. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">A</td><td>: Pointer to value array of matrix </td></tr>
    <tr><td class="paramname">L</td><td>: Pointer to value array of Cholesky factor </td></tr>
    <tr><td class="paramname">n_rows</td><td>: Number of rows</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> Cholesky::LLtMult(T * A, <span class="keyword">const</span> T * L, <span class="keywordtype">int</span> n_rows)
 {
     <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> r = 0; r &lt; n_rows; ++r)
         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> c = 0; c &lt;=r; ++c)
         {
             <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> idx = c + (r*(r+1))/2;
             <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k_max = std::min(r,c);
 
             A[idx] = 0.;
 
             <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k = 0; k &lt; k_max; ++k)
             {
                 <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> idx_k   = k + (r*(r+1))/2;
                 <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> idx_k_T = k + (c*(c+1))/2;
 
                 A[idx] += L[idx_k]*L[idx_k_T];
             }
         }
 }
</pre></div><p><a class="anchor" id="ClassMyFancySimulation"></a> </p>
<h3>Class: MyFancySimulation</h3>
<p>The final class which drives the simulation. This class is primarily intended to manage the user's input.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 <span class="keyword">class </span>MyFancySimulation {
 
 <span class="keyword">public</span>:
 
     MyFancySimulation(SimParams &amp;p);
 
     <span class="keywordtype">void</span> run();
 
     <span class="keyword">static</span> std::string precision_id();
 
 <span class="keyword">private</span>:
     <span class="keyword">const</span> SimParams * params;
 
 };
</pre></div><p><a class="anchor" id="Constructor"></a> </p>
<h4>Constructor</h4>
<p>The constructor of the simulation class sets the pointer to the runtime parameters and which GPU ("device") to use.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Number&gt;
 step1::MyFancySimulation&lt;Number&gt;::MyFancySimulation(SimParams &amp;p)
     :
       params(&amp;p)
 {
     cudaSetDevice(params-&gt;device); 
 }
</pre></div><p><a class="anchor" id="Functionprecision_id"></a> </p>
<h4>Function: precision_id</h4>
<p>Returns a string for identifying the precision.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;&gt;
 std::string MyFancySimulation&lt;float&gt;::precision_id()
 {
     <span class="keywordflow">return</span> <span class="stringliteral">&quot;float&quot;</span>;
 }
 
 <span class="keyword">template</span>&lt;&gt;
 std::string MyFancySimulation&lt;double&gt;::precision_id()
 {
     <span class="keywordflow">return</span> <span class="stringliteral">&quot;double&quot;</span>;
 }
 
 }
</pre></div><p><a class="anchor" id="Functionrun"></a> </p>
<h4>Function: run</h4>
<p>Compute the factorization for different matrix sizes.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 <span class="keywordtype">void</span> step1::MyFancySimulation&lt;Number&gt;::run()
 {   
</pre></div><p>Before we start the test we setup the naem of the file which at the end contains the runtimes.</p>
<div class="fragment"><pre class="fragment">     std::ostringstream filename;
 
     filename &lt;&lt; <span class="stringliteral">&quot;chol_fac_times_&quot;</span> &lt;&lt; params-&gt;matrix_low &lt;&lt; <span class="stringliteral">&quot;_&quot;</span> &lt;&lt; precision_id().c_str() &lt;&lt; <span class="stringliteral">&quot;.dat&quot;</span>;
</pre></div><p>The results of the factorization are stored in a convergence table.</p>
<div class="fragment"><pre class="fragment">     dealii::ConvergenceTable factorization_times;
</pre></div><p>Loop over all matrix sizes in the specified range.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> n = params-&gt;matrix_low; n &lt; params-&gt;matrix_high; n+=params-&gt;step_size)
     {
         CholeskyTest&lt;Number&gt; driver(n, factorization_times, *params);
 
         driver.start();
</pre></div><p>For debugging purposes it is sometimes useful to disable the inheritance from QThread and to call the run()-function directly.</p>
<div class="fragment"><pre class="fragment">         / * driver.run();* /
         driver.wait();
</pre></div><p>To avoid data loss we save the results after each factorizatrion.</p>
<div class="fragment"><pre class="fragment">         std::ofstream out(filename.str().c_str());
         factorization_times.write_text(out);
     }
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;Done.&quot;</span> &lt;&lt; std::endl;
 }
</pre></div><p><a class="anchor" id="Funktionmain"></a> </p>
<h4>Funktion: main</h4>
<p>Instantiate and execute the simulation.</p>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> *argv[])
 {
     <span class="keyword">using namespace </span>step1;
 
     SimParams params;
</pre></div><p>First we declare the parameters to expect ...</p>
<div class="fragment"><pre class="fragment">     dealii::ParameterHandler prm_handler;
</pre></div><p>Get the current working directory</p>
<div class="fragment"><pre class="fragment">     QDir cwd = QDir::current();
</pre></div><p>and backup the location where the program has been started. Here, we assume the we use QTCreators shadow-biuld mechanism whoch puts the build directory at the same level as the directory <em><a class="el" href="step_1.html">step-1</a></em> containing the source code.</p>
<div class="fragment"><pre class="fragment">     <span class="keyword">const</span> QDir launch_dir = cwd;
     cwd.setPath(<span class="stringliteral">&quot;../step-1&quot;</span>);
</pre></div><p>By default, the parameter file has the same name as the binary and is supposed to be in a subdirectory prm of the directory, where the program has been started.</p>
<div class="fragment"><pre class="fragment">     std::string prm_filename;
     <span class="keywordflow">if</span> (argc == 1)
     {
         std::string tmp = argv[0];
         <span class="keywordtype">int</span> found=tmp.find_last_of(<span class="charliteral">&#39;/&#39;</span>);
         prm_filename = tmp.substr(found+1);
         prm_filename += <span class="stringliteral">&quot;-Decomp.prm&quot;</span>;
 
         cwd.setPath(<span class="stringliteral">&quot;./prm&quot;</span>);
     }
     <span class="keywordflow">else</span>
     {
         QFileInfo tmp(argv[1]);
</pre></div><p>Subdivide the given filename into its path and filename so that the corresponding subdirectories can be created.</p>
<div class="fragment"><pre class="fragment">         QString prm_path = tmp.absolutePath();
         cwd.setPath(prm_path);
         cwd.makeAbsolute();
         prm_filename = tmp.fileName().toStdString();
 
         std::cout &lt;&lt; <span class="stringliteral">&quot;chosen prm file : &quot;</span> &lt;&lt; tmp.absoluteFilePath().toStdString().c_str() &lt;&lt; std::endl;
     }
</pre></div><p>Before the parameter file can be read, we have to make sure that its directory exists</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span> (!cwd.exists() )
         launch_dir.mkpath( cwd.absolutePath() );
 
     QDir::setCurrent(cwd.absolutePath());
     SimParams::declare(prm_handler);
     prm_handler.read_input (prm_filename);
 
     QDir::setCurrent(launch_dir.absolutePath());
 
     params.get(prm_handler);
</pre></div><p>Create the toplevel run directory.</p>
<div class="fragment"><pre class="fragment">     cwd.setPath(params.run_dir.absolutePath());
</pre></div><p>The following lets a directory make its own path.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span> (!cwd.exists())
         cwd.mkpath( <span class="stringliteral">&quot;.&quot;</span> );
</pre></div><p>Now, change to the run dir</p>
<div class="fragment"><pre class="fragment">     QDir::setCurrent(cwd.absolutePath());
 
     cwd.setPath(<span class="stringliteral">&quot;./log&quot;</span>);
     cwd.makeAbsolute();
     <span class="keywordflow">if</span> (!cwd.exists())
         cwd.mkpath(<span class="stringliteral">&quot;.&quot;</span>);
</pre></div><p>Create the log directory and write what has been actually read into log file. Basically, this is just another parameter file and can thus be used again as input to another run.</p>
<div class="fragment"><pre class="fragment">     QDir::setCurrent(cwd.absolutePath());
 
     prm_filename += <span class="stringliteral">&quot;.log&quot;</span>;
     std::ofstream log_out_text(prm_filename.c_str());
     prm_handler.print_parameters (log_out_text,
                                   dealii::ParameterHandler::Text);
</pre></div><p>At this point the toplevel run dir must exist. Thus, we can change to it without any further sanity test.</p>
<div class="fragment"><pre class="fragment">     QDir::setCurrent(params.run_dir.absolutePath());
</pre></div><p>Now, run the comparison of GPU vs. CPU for the selected precision.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span> (!params.use_double) {
 
         MyFancySimulation&lt;float&gt; machma_float(params);
 
         machma_float.run();
     }
     <span class="keywordflow">else</span> {
 
         MyFancySimulation&lt;double&gt; machma_double(params);
 
         machma_double.run();
     }
 }
</pre></div><p> <a class="anchor" id="Results"></a></p>
<h1>Results</h1>
<p>To generate figures comparable to the ones shown below start step-1 with the parameter file <em>step-1-Cholesky.prm</em> from the <em>prm</em> subdirectory. A gnuplot script <em>chol_fac_plot_results.gp</em> for generating the graphical output is in the <em>scripts</em> subdirectory. The plots are generated by switching to the directory where the results file is stored and starting gnuplot from that directory with the plot script as argument. Depending on the particular parameters you will have to modify the name of the data file read by that script.  </p>
<p>The initial comparisons for the Cholesky factorization were done on a Macbook Pro with Core2Duo processor running at 2.53 GHz and NVidia's Gforce 8600m GT chip. Neglecting the time needed for host-to-device memory transfer the break even is at roughly 170 rows. Including transfer times this rise to 700 rows. The Cholesky factorization does not take into account any information about the size of the matrix entries. Therefore the choice of the testmatrix does not really matter as long as only timing tests are performed. Due to the fact that GPUs have a different rounding behavior, one should also test whether for a given matrix and right-hand side the solution obtained from both variants is the same up to numerical accuracy.</p>
<div class="image"><div class="image">
<img src="cholesky_macbookpro_c2d_2.53GHz_8600m_GT.png"  alt="cholesky_macbookpro_c2d_2.53GHz_8600m_GT.png" width=" 1024"/>
</div>
<div class="caption"> Comparison of GPU vs. CPU performance for various matrix sizes.</div></div><div style="display: none;"><div class="image">
<img src="cholesky_macbookpro_c2d_2.53GHz_8600m_GT.png" alt="cholesky_macbookpro_c2d_2.53GHz_8600m_GT.png"/>
</div>
<p> "" </div> <p>The next more serious comparison is run on a system consisting of a quad-core Xeon with 2.26 GHz and a GeForce GTX 460.</p>
<div class="image"><div class="image">
<img src="chol_fac_times_256_float.png"  alt="chol_fac_times_256_float.png" width=" 1024"/>
</div>
<div class="caption"> Execution times on quad-core Xeon 2.26 GHz and gtx 460.</div></div><div style="display: none;"><div class="image">
<img src="chol_fac_times_256_float.png" alt="chol_fac_times_256_float.png"/>
</div>
<p> "" </div> <div class="image"><div class="image">
<img src=" chol_fac_speedup.png"  alt=" chol_fac_speedup.png" width=" 1024"/>
</div>
<div class="caption"> Speedup of GPU over CPU on quad-core Xeon 2.26 GHz and gtx 460.</div></div><div style="display: none;"><div class="image">
<img src=" chol_fac_speedup.png" alt=" chol_fac_speedup.png"/>
</div>
<p> "" </div> <div class="image"><div class="image">
<img src="chol_fac_gpu_individual_components.png"  alt="chol_fac_gpu_individual_components.png" width=" 1024"/>
</div>
<div class="caption"> Individual timing of the different kernels of the Cholesky factorization on gtx 460.</div></div><div style="display: none;"><div class="image">
<img src="chol_fac_gpu_individual_components.png" alt="chol_fac_gpu_individual_components.png"/>
</div>
<p> "" </div><p><a class="anchor" id="PlainProg"></a> </p>
<h1>The plain program</h1>
<p>(If you are looking at a locally installed CUDA HPC Praktikum version, then the program can be found at <em> .. /.. /testsite / /step-1 /step-cu.cc </em>. Otherwise, this is only the path on some remote server.) </p>
<div class="fragment"><pre class="fragment"> / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
 / *
    Copyright 2010,2011,2012,2013 Stephan Kramer, as of 2013: Dr. Stephan Kramer
 
    Licensed under the Apache License, Version 2.0 (the <span class="stringliteral">&quot;License&quot;</span>);
    you may not use <span class="keyword">this</span> file except in compliance with the License.
    You may obtain a copy of the License at
 
        http:<span class="comment">//www.apache.org/licenses/LICENSE-2.0</span>
 
    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an <span class="stringliteral">&quot;AS IS&quot;</span> BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License <span class="keywordflow">for</span> the specific language governing permissions and
    limitations under the License.
 
    This file includes
 
    - the CUDA kernels <span class="keywordflow">for</span> computing a Cholesky factorization
      of a real, symmetric (and hopefully positive definite) matrix.
 
    - device functions needed by the kernels <span class="keywordflow">for</span> mapping thread and block indices
      to row and column indices of the matrix which is to be factorized or
      to the positions in the linear array holding the matrix entries.
 
    - the definitions of the wrapper functions <span class="keywordflow">for</span> the kernels. These wrapper functions
      are declared in a separate header file and either allow to call
      the kernels individually or to execute the complete factorization
      via the <span class="stringliteral">&#39;blackbox&#39;</span> <span class="keyword">function</span>.
 
    All kernels and wrapper functions are enclosed in a <span class="keyword">namespace </span>&#39;step1&#39;
 * /
<span class="preprocessor"> #ifndef CUDA_KERNEL_STEP_1_CU_H</span>
<span class="preprocessor"> #define CUDA_KERNEL_STEP_1_CU_H</span>
</pre></div><p> <a class="anchor" id="plain-ParallelizationofCholeskyFactorization"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">namespace </span>step1 {
 
 <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">int</span> DEFAULT_TILE_SIZE = 16;
</pre></div><p> <a class="anchor" id="plain-ClassKernels"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">class </span>Kernels {
</pre></div><p> <a class="anchor" id="plain-ClassCholesky"></a> </p>
<div class="fragment"><pre class="fragment">     <span class="keyword">struct </span>Cholesky {
 
         <span class="keywordtype">void</span> single_thread(T * A, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim);
 
         cudaError_t factorize_diag_block(T *A,
                                          <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim );
 
         <span class="keywordtype">void</span> strip_update(T *A,
                           <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_remaining_blocks, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim);
 
         <span class="keywordtype">void</span> diag_update(T *A,
                          <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_remaining_blocks, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim);
 
         <span class="keywordtype">void</span> lo_update(T *A,
                        <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_blocks, <span class="keywordtype">int</span> n_remaining_blocks, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim);
 
         <span class="keywordtype">void</span> blackbox(T *A, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim);
 
     };
</pre></div><p> <a class="anchor" id="plain-ClassLU"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">public</span>:
     Cholesky cholesky;
 
 };
 
 } <span class="comment">// namespace step1 END</span>
 
<span class="preprocessor"> #endif // CUDA_KERNEL_STEP_1_CU_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
 / *
      This file includes
 
    - the CUDA kernels <span class="keywordflow">for</span> computing a Cholesky factorization
      of a real, symmetric (and hopefully positive definite) matrix.
 
    - device functions needed by the kernels <span class="keywordflow">for</span> mapping thread and block indices
      to row and column indices of the matrix which is to be factorized or
      to the positions in the linear array holding the matrix entries.
 
    - the definitions of the wrapper functions <span class="keywordflow">for</span> the kernels. These wrapper functions
      are declared in a separate header file and either allow to call
      the kernels individually or to execute the complete factorization
      via the <span class="stringliteral">&#39;blackbox&#39;</span> <span class="keyword">function</span>.
 
    All kernels and wrapper functions are enclosed in a <span class="keyword">namespace </span>&#39;step1&#39;
 * /
<span class="preprocessor"> #ifdef USE_CU_C</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;stdio.h&gt;</span>
 
<span class="preprocessor"> #include &lt;step-1/cuda_kernel_wrapper_step-1.cu.h&gt;</span>
 
 <span class="keyword">namespace </span>step1 {
</pre></div><p> <a class="anchor" id="plain-DeviceFunctions"></a> </p>
<div class="fragment"><pre class="fragment"></pre></div><p> <a class="anchor" id="plain-DeviceFunctionlex_index_2D"></a> </p>
<div class="fragment"><pre class="fragment"> __forceinline__
 __device__ <span class="keywordtype">int</span> lex_index_2D(<span class="keywordtype">int</span> r, <span class="keywordtype">int</span> c, <span class="keywordtype">int</span> leading_dim)
 {
     <span class="keywordflow">return</span> c +  r*leading_dim;
 }
</pre></div><p> <a class="anchor" id="plain-DeviceFunctionglobal_pos"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keywordtype">int</span> TILE_SIZE&gt;
 __forceinline__
 __device__ <span class="keywordtype">int</span> global_pos(<span class="keywordtype">int</span> t_pos, <span class="keywordtype">int</span> n_blocks_done)
 {
     <span class="keywordflow">return</span> t_pos + TILE_SIZE*n_blocks_done;
 }
</pre></div><p> <a class="anchor" id="plain-DeviceFunctioninv_sqrt"></a> </p>
<div class="fragment"><pre class="fragment"> __device__ <span class="keywordtype">float</span> inv_sqrt(<span class="keywordtype">float</span> x)
 {
     <span class="keywordflow">return</span> rsqrtf(x);
 }
 
 
 __device__ <span class="keywordtype">double</span> inv_sqrt(<span class="keywordtype">double</span> x)
 {
     <span class="keywordflow">return</span> rsqrt(x);
 }
</pre></div><p> <a class="anchor" id="plain-CholeskyKernels"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">namespace </span>Chol {
</pre></div><p> <a class="anchor" id="plain-Kernel__single_thread"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 __global__
 <span class="keywordtype">void</span>
 __single_thread(T *A, <span class="keyword">const</span> <span class="keywordtype">int</span> n_rows, <span class="keyword">const</span> <span class="keywordtype">int</span> leading_dim)
 {
     <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> r = 0; r &lt; n_rows; ++r)
     {
         T sum = 0.;
         <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> idx;
         <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> idx_c;
         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> u = 0; u &lt; r; ++u)
         {
             idx = lex_index_2D(r, u, leading_dim);
             sum += A[idx] * A[idx];
         }
         idx = lex_index_2D(r, r, leading_dim);
         A[idx] = sqrt(A[idx] - sum);
 
         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> c = r+1; c &lt; n_rows; ++c)
         {
             sum = 0.;
 
             <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> u = 0; u &lt; r; ++u)
             {
                 idx_c = lex_index_2D(c, u, leading_dim);
                 idx   = lex_index_2D(r, u, leading_dim);
                 sum += A[idx_c]*A[idx];
             }
 
             idx_c = lex_index_2D(c, r, leading_dim);
             idx   = lex_index_2D(r, c, leading_dim);
             A[idx_c]  = A[idx] - sum;
 
             idx   = lex_index_2D(r, r, leading_dim);
             A[idx_c] /= A[idx];
         }
     }
 }
</pre></div><p> <a class="anchor" id="plain-Kernelfactorize_diag_block"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keywordtype">int</span> TILE_SIZE&gt;
 __global__
 <span class="keywordtype">void</span>
 __factorize_diag_block(T *A, <span class="keywordtype">int</span> n_blocks_done,
                        <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim)
 {
     <span class="keywordtype">int</span> col = threadIdx.x;
 
     <span class="keywordtype">int</span> row = threadIdx.y;
 
     <span class="keywordtype">int</span> global_row = global_pos&lt;TILE_SIZE&gt;(row, n_blocks_done);
     <span class="keywordtype">int</span> global_col = global_pos&lt;TILE_SIZE&gt;(col, n_blocks_done);
 
     <span class="keywordflow">if</span> ((global_row &gt;= n_cols) || (global_col &gt;= n_cols))
         <span class="keywordflow">return</span>;
 
     <span class="keywordtype">int</span> idx = lex_index_2D(global_row, global_col, leading_dim);
 
<span class="preprocessor"> #ifdef INDEX_BOUND_DEBUG</span>
<span class="preprocessor"></span>     <span class="keywordflow">if</span> (row == 0 &amp;&amp; col == 0)
     printf(<span class="stringliteral">&quot;%s:\n------------------------\n&quot;</span>, __FUNCTION__);
     __syncthreads();
 
     printf(<span class="stringliteral">&quot;row, col : (%d, %d), g_row,g_col : (%d, %d), idx : %d\n &quot;</span>,
            row, col, global_row, global_col, idx);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
     __shared__ T L[TILE_SIZE][TILE_SIZE+1];
 
     L[row][col]= A[idx];
     __syncthreads();
 
     T fac;
 
     <span class="keywordtype">int</span> k_max = TILE_SIZE;
     <span class="keywordflow">if</span> (n_cols - global_pos&lt;TILE_SIZE&gt;(0, n_blocks_done) &lt; TILE_SIZE)
         k_max = n_cols%TILE_SIZE;
 
<span class="preprocessor"> #ifdef INDEX_BOUND_DEBUG</span>
<span class="preprocessor"></span>       printf(<span class="stringliteral">&quot;k_max : %d\n&quot;</span>, k_max);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
     <span class="keywordflow">for</span>(<span class="keywordtype">int</span> k=0; k &lt; k_max; k++)
     {
         __syncthreads();
         fac = inv_sqrt(L[k][k]);
         __syncthreads();
 
         <span class="keywordflow">if</span> ((row==k)&amp;&amp;(col&gt;=k)) L[col][row]=(L[col][row])*fac;
 
         __syncthreads();
 
 
         <span class="keywordflow">if</span> ((row&gt;=col)&amp;&amp;(col&gt;k)) L[row][col] -= L[col][k]*L[row][k];
     }
 
     __syncthreads();
 
     <span class="keywordflow">if</span> (row&gt;=col) A[idx] = L[row][col];
 
 
<span class="preprocessor"> #ifdef INDEX_BOUND_DEBUG</span>
<span class="preprocessor"></span>     printf(<span class="stringliteral">&quot;A_%d : %f\n&quot;</span>, idx,  L[row][col]);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"> }</span>
</pre></div><p> <a class="anchor" id="plain-Kernelstrip_update"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keywordtype">int</span> TILE_SIZE&gt;
 __global__
 <span class="keywordtype">void</span>
 __strip_update(T *A, <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim)
 {
     <span class="keywordtype">int</span> boffy=n_blocks_done;
 
     <span class="keywordtype">int</span> boffx = blockIdx.x + boffy + 1;
 
     <span class="keywordtype">int</span> col = threadIdx.x;
     <span class="keywordtype">int</span> row = threadIdx.y;
 
     __shared__ T topleft[TILE_SIZE][TILE_SIZE+1];
     __shared__ T workingmat[TILE_SIZE][TILE_SIZE+1];
 
     <span class="keywordtype">int</span> global_row = global_pos&lt;TILE_SIZE&gt;(row,n_blocks_done);
     <span class="keywordtype">int</span> global_col = global_pos&lt;TILE_SIZE&gt;(col,n_blocks_done);
 
     <span class="keywordflow">if</span> ((global_row &gt;= n_cols) || (global_col &gt;= n_cols))
         <span class="keywordflow">return</span>;
 
     <span class="keywordtype">int</span> idx = lex_index_2D(global_row, global_col, leading_dim);
 
     topleft[row][col]=A[idx];
 
     global_row = global_pos&lt;TILE_SIZE&gt;(row,boffx);
     <span class="keywordtype">int</span> idx_w = lex_index_2D(global_row, global_col, leading_dim);
 
     workingmat[col][row] = A[idx_w];
 
     __syncthreads();
 
 
     <span class="keywordtype">int</span> k_max = TILE_SIZE;
 
     <span class="keywordflow">if</span>(row==0)
         <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k=0; k &lt; k_max; k++)
         {
             T sum=0.;
             <span class="keywordflow">for</span> (<span class="keywordtype">int</span> m = 0; m &lt; k; m++)
                 sum += topleft[k][m]*workingmat[m][col];
 
             workingmat[k][col] = (workingmat[k][col] - sum)/topleft[k][k];
         }
 
     __syncthreads();
 
     A[idx_w] = workingmat[col][row];
 }
</pre></div><p> <a class="anchor" id="plain-Kerneldiag_update"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keywordtype">int</span> TILE_SIZE&gt;
 __global__
 <span class="keywordtype">void</span>
 __diag_update(T *A, <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim)
 {
     <span class="keywordtype">int</span> boffx = blockIdx.x + n_blocks_done + 1;
 
     <span class="keywordtype">int</span> col = threadIdx.x;
     <span class="keywordtype">int</span> row = threadIdx.y;
 
     <span class="keywordtype">int</span> global_row = global_pos&lt;TILE_SIZE&gt;(row, boffx);
     <span class="keywordtype">int</span> global_col = global_pos&lt;TILE_SIZE&gt;(col, n_blocks_done);
 
     <span class="keywordflow">if</span> ((global_row &gt;= n_cols) || (global_col &gt;= n_cols))
         <span class="keywordflow">return</span>;
 
     <span class="keywordtype">int</span> idx = lex_index_2D(global_row, global_col, leading_dim);
 
     __shared__ T left[TILE_SIZE][TILE_SIZE+1];
 
     left[row][col]= A[idx];
 
     __syncthreads();
 
     T sum = 0.f;
 
 
     <span class="keywordtype">int</span> k_max = TILE_SIZE;
 
     <span class="keywordflow">if</span>(row&gt;=col)
     {
         <span class="keywordflow">for</span>(<span class="keywordtype">int</span> kk=0; kk&lt;k_max; kk++) sum += left[row][kk]*left[col][kk];
 
         global_col = global_pos&lt;TILE_SIZE&gt;(col, boffx);
         idx = lex_index_2D(global_row, global_col, leading_dim);
 
         A[idx] -= sum;
     }
 }
</pre></div><p> <a class="anchor" id="plain-Kernello_update"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keywordtype">int</span> TILE_SIZE&gt;
 __global__
 <span class="keywordtype">void</span>
 __lo_update(T *A, <span class="keywordtype">int</span> n_blocks_done, <span class="keywordtype">int</span> n_blocks, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim)
 {
 
     <span class="keywordtype">int</span> col = threadIdx.x;
     <span class="keywordtype">int</span> row = threadIdx.y;
 
     <span class="keywordtype">int</span> boffy=blockIdx.y+n_blocks_done+1;
     <span class="keywordtype">int</span> boffx=boffy+1;
 
     __shared__ T left[TILE_SIZE][TILE_SIZE];
 
     __shared__ T upt[TILE_SIZE][TILE_SIZE+1];
 
 
     <span class="keywordtype">int</span> global_row_src = global_pos&lt;TILE_SIZE&gt;(row, boffy);
     <span class="keywordtype">int</span> global_col_src = global_pos&lt;TILE_SIZE&gt;(col, n_blocks_done);
 
     <span class="keywordflow">if</span> ((global_row_src &gt;= n_cols) || (global_col_src &gt;= n_cols))
         <span class="keywordflow">return</span>;
 
     <span class="keywordtype">int</span> idx = lex_index_2D(global_row_src, global_col_src, leading_dim);
 
     upt[row][col]=A[idx];
     __syncthreads();
 
 
<span class="preprocessor"> #ifdef nSCHUR_DEBUG</span>
<span class="preprocessor"></span>     <span class="keywordflow">if</span> (row == 0 &amp;&amp; col == 0)
     printf(<span class="stringliteral">&quot;%s block (%d,%d):\n------------------------\n&quot;</span>,
            __FUNCTION__, blockIdx.x, blockIdx.y);
     __syncthreads();
 
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
     <span class="keywordflow">for</span> (;boffx&lt;n_blocks;boffx++)
     {
         <span class="keywordtype">int</span> global_row = global_pos&lt;TILE_SIZE&gt;(row, boffx);
         idx = lex_index_2D(global_row, global_col_src, leading_dim);
 
         left[row][col]= 0.;
         left[row][col]=A[idx];
 
<span class="preprocessor"> #ifdef SCHUR_DEBUG</span>
<span class="preprocessor"></span>         printf(<span class="stringliteral">&quot;loading  left[%d][%d]=A[%d] == %f\n&quot;</span>, row, col, idx, A[idx]);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>         __syncthreads();
 
         <span class="keywordflow">if</span> (global_row &lt; n_cols)
         {
             T matrixprod=0.f;
 
             <span class="keywordtype">int</span> k_max = TILE_SIZE;
 
             <span class="keywordflow">for</span> (<span class="keywordtype">int</span> kk=0;kk&lt;k_max;kk++)
             {
                 matrixprod+=left[row][kk]*upt[col][kk];
 
<span class="preprocessor"> #ifdef SCHUR_DEBUG</span>
<span class="preprocessor"></span>                 printf(<span class="stringliteral">&quot;row, col : (%d, %d), g_row,g_col : (%d, %d), idx : %d, mprod : %f, L_r%d : %f, U_1c : %f \n &quot;</span>,
                        row, col, global_row, global_col_src, idx, matrixprod, kk, left[row][kk], upt[col][kk]);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>             }
 
             <span class="keywordtype">int</span> global_col = global_pos&lt;TILE_SIZE&gt;(col, boffy);
 
             <span class="keywordflow">if</span> (global_col &lt; n_cols)
             {
                 idx = lex_index_2D(global_row, global_col, leading_dim);
                 A[idx] -= matrixprod;
 
<span class="preprocessor"> #ifdef SCHUR_DEBUG</span>
<span class="preprocessor"></span>                 <span class="keywordflow">if</span> (row == 0 &amp;&amp; col == 0)
                     printf(<span class="stringliteral">&quot;%s:\n------------------------\n&quot;</span>, __FUNCTION__);
                 __syncthreads();
 
                 printf(<span class="stringliteral">&quot;row, col : (%d, %d), g_row,g_col : (%d, %d), idx : %d, mprod : %f\n &quot;</span>,
                        row, col, global_row, global_col, idx, matrixprod);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>             }
         }
     }
 
 }
 
 } <span class="comment">// namespace Chol END</span>
 
 } <span class="comment">// namespace step1 END</span>
</pre></div><p> <a class="anchor" id="plain-Wrapperfunctions"></a> </p>
<div class="fragment"><pre class="fragment"></pre></div><p> <a class="anchor" id="plain-Functionblackbox"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> step1::Kernels&lt;T&gt;::Cholesky::blackbox(T * a_d, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim)
 {
     cudaError_t error;
 
     <span class="keywordtype">int</span> n_blocks = (n_cols+int(DEFAULT_TILE_SIZE)-1)/<span class="keywordtype">int</span>(DEFAULT_TILE_SIZE);
 
     dim3 threads(DEFAULT_TILE_SIZE, DEFAULT_TILE_SIZE);
 
     dim3 logrid;
 
     <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i=n_blocks; i&gt;2; --i)
     {
         logrid.x=1;
         logrid.y=i-2;
 
         dim3 stripgrid(i-1);
 
         Chol::__factorize_diag_block&lt;T, DEFAULT_TILE_SIZE&gt;
                 &lt;&lt;&lt;1, threads&gt;&gt;&gt;(a_d, n_blocks-i, n_cols, leading_dim);
         cudaThreadSynchronize();
 
         Chol::__strip_update&lt;T, DEFAULT_TILE_SIZE&gt;
                 &lt;&lt;&lt;stripgrid, threads&gt;&gt;&gt;(a_d, n_blocks-i, n_cols, leading_dim);
         cudaThreadSynchronize();
 
         Chol::__diag_update&lt;T, DEFAULT_TILE_SIZE&gt;
                 &lt;&lt;&lt;stripgrid, threads&gt;&gt;&gt;(a_d, n_blocks-i, n_cols, leading_dim);
         cudaThreadSynchronize();
         Chol::__lo_update&lt;T, DEFAULT_TILE_SIZE&gt;
                 &lt;&lt;&lt; logrid, threads &gt;&gt;&gt;(a_d, n_blocks-i, n_blocks, n_cols, leading_dim);
         cudaThreadSynchronize();
     }
 
     <span class="keywordflow">if</span>(n_blocks&gt;1)
     {
         Chol::__factorize_diag_block&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;1, threads&gt;&gt;&gt;(a_d, n_blocks-2, n_cols,
                                                    leading_dim);
         cudaThreadSynchronize();
 
         Chol::__strip_update&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;1, threads&gt;&gt;&gt;(a_d, n_blocks-2, n_cols, leading_dim);
         cudaThreadSynchronize();
 
         Chol::__diag_update&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;1, threads&gt;&gt;&gt;(a_d, n_blocks-2, n_cols, leading_dim);
         cudaThreadSynchronize();
 
     }
 
     Chol::__factorize_diag_block&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;1, threads&gt;&gt;&gt;(a_d, n_blocks-1, n_cols, leading_dim);
 
     cudaThreadSynchronize();
 
     error=cudaGetLastError();
     <span class="keywordflow">if</span> (error != cudaSuccess)
     {
         printf(<span class="stringliteral">&quot;     Error code %d: %s.\n&quot;</span>,error,cudaGetErrorString(error));
         exit(-1);
     }
 }
</pre></div><p> <a class="anchor" id="plain-Functionsingle_thread"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> step1::Kernels&lt;T&gt;::Cholesky::single_thread(T * a_d, <span class="keywordtype">int</span> n_cols, <span class="keywordtype">int</span> leading_dim)
 {
     Chol::__single_thread&lt;&lt;&lt;1,1&gt;&gt;&gt;(a_d, n_cols, leading_dim);
 }
</pre></div><p> <a class="anchor" id="plain-Functionfactorize_diag_block"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 cudaError_t step1::Kernels&lt;T&gt;::Cholesky::factorize_diag_block(T * a_d,
                                                               <span class="keywordtype">int</span> n_blocks_done,
                                                               <span class="keywordtype">int</span> n_cols,
                                                               <span class="keywordtype">int</span> leading_dim)
 {
     dim3 threads(DEFAULT_TILE_SIZE, DEFAULT_TILE_SIZE);
     Chol::__factorize_diag_block&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;1, threads&gt;&gt;&gt;(a_d, n_blocks_done,  n_cols, leading_dim);
     cudaThreadSynchronize();
 
     <span class="keywordflow">return</span> cudaGetLastError();
 }
</pre></div><p> <a class="anchor" id="plain-Functionstrip_update"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span>
 step1::Kernels&lt;T&gt;::Cholesky::strip_update(T *a_d,
                                           <span class="keywordtype">int</span> n_blocks_done,
                                           <span class="keywordtype">int</span> n_remaining_blocks, <span class="keywordtype">int</span> n_cols,
                                           <span class="keywordtype">int</span> leading_dim)
 {
     cudaError_t error;
     dim3 stripgrid(n_remaining_blocks-1);
     dim3 threads(DEFAULT_TILE_SIZE, DEFAULT_TILE_SIZE);
 
     Chol::__strip_update&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;stripgrid, threads&gt;&gt;&gt;(a_d,
                                                  n_blocks_done, n_cols,
                                                  leading_dim);
 
     cudaThreadSynchronize();
 
     error=cudaGetLastError();
     <span class="keywordflow">if</span> (error != cudaSuccess)
     {
         printf(<span class="stringliteral">&quot;     Error code %d: %s.\n&quot;</span>,error,cudaGetErrorString(error));
 
         exit(-1);
     }
 }
</pre></div><p> <a class="anchor" id="plain-Functiondiag_update"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> step1::Kernels&lt;T&gt;::Cholesky::diag_update(T *a_d,
                                               <span class="keywordtype">int</span> n_blocks_done,
                                               <span class="keywordtype">int</span> n_remaining_blocks,
                                               <span class="keywordtype">int</span> n_cols,
                                               <span class="keywordtype">int</span> leading_dim)
 {
     cudaError_t error;
     dim3 stripgrid(n_remaining_blocks-1);
     dim3 threads(DEFAULT_TILE_SIZE, DEFAULT_TILE_SIZE);
 
     Chol::__diag_update&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt;stripgrid, threads&gt;&gt;&gt;(a_d,
                                                 n_blocks_done, n_cols,
                                                 leading_dim);
 
     cudaThreadSynchronize();
     error=cudaGetLastError();
     <span class="keywordflow">if</span> (error != cudaSuccess)
     {
         printf(<span class="stringliteral">&quot;     Error code %d: %s.\n&quot;</span>,error,cudaGetErrorString(error));
         exit(-1);
     }
 }
</pre></div><p> <a class="anchor" id="plain-Functionlo_update"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> step1::Kernels&lt;T&gt;::Cholesky::lo_update(T *a_d,
                                             <span class="keywordtype">int</span> n_blocks_done,
                                             <span class="keywordtype">int</span> n_blocks,
                                             <span class="keywordtype">int</span> n_remaining_blocks ,
                                             <span class="keywordtype">int</span> n_cols,
                                             <span class="keywordtype">int</span> leading_dim)
 {
     cudaError_t error;
     dim3 logrid;
     logrid.x=1;
     logrid.y=n_remaining_blocks-2;
     dim3 threads(DEFAULT_TILE_SIZE, DEFAULT_TILE_SIZE);
 
     Chol::__lo_update&lt;T, DEFAULT_TILE_SIZE&gt;&lt;&lt;&lt; logrid, threads &gt;&gt;&gt;(a_d,
                                              n_blocks_done, n_blocks,  n_cols, leading_dim);
     cudaThreadSynchronize();
     error=cudaGetLastError();
     <span class="keywordflow">if</span> (error != cudaSuccess)
     {
         printf(<span class="stringliteral">&quot;     Error code %d: %s.\n&quot;</span>,error,cudaGetErrorString(error));
         exit(-1);
     }
 }
 
 
 
 <span class="keyword">template</span> <span class="keyword">class </span>step1::Kernels&lt;float&gt;;
 <span class="keyword">template</span> <span class="keyword">class </span>step1::Kernels&lt;double&gt;;
 
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CUDADriver_STEP_1_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define CUDADriver_STEP_1_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;step-1/SimParams.h&gt;</span>
 
<span class="preprocessor"> #include &lt;lac/FullMatrixAccessor.h&gt;</span>
<span class="preprocessor"> #include &lt;lac/blas++.h&gt;</span>
 
<span class="preprocessor"> #include &lt;step-1/cuda_kernel_wrapper_step-1.cu.h&gt;</span>
 
 
 
 <span class="keyword">namespace </span>step1 {
</pre></div><p> <a class="anchor" id="plain-ClassCUDADriver"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">class </span>CUDADriver : <span class="keyword">private</span> Kernels&lt;T&gt; {
 
 <span class="keyword">public</span>:
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::blas_wrapper_type BW;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::FullMatrixAccessor FullMatrixAccessor;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::Matrix Matrix;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::SubMatrix SubMatrix;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::MatrixSubCol MatrixSubCol;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::Vector Vector;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::SubColVector SubColVector;
     <span class="keyword">typedef</span> <span class="keyword">typename</span> blas_pp&lt;T, cublas&gt;::SubVectorBase SubVectorBase;
 
     <span class="keyword">typedef</span> std::map&lt;std::string,double&gt; TimerName2Value;
 
 
 
     CUDADriver(<span class="keyword">const</span> SimParams &amp;p);
 
 
 
     <span class="keywordtype">double</span> factorize(FullMatrixAccessor&amp; A);
 
     <span class="keywordtype">double</span> factorize(dealii::FullMatrix&lt;T&gt; &amp;A);
 
     <span class="keywordtype">void</span> chol_fac(FullMatrixAccessor&amp; A, TimerName2Value&amp; times);
 
     <span class="keywordtype">void</span> lu_fac(FullMatrixAccessor&amp; A, TimerName2Value&amp; times);
 
     <span class="keywordtype">void</span> single_thread_cholesky(FullMatrixAccessor&amp; A);
 
 
 <span class="keyword">private</span>:
     Matrix A_d;
 
     <span class="keyword">const</span> SimParams * params;
 };
 
 } <span class="comment">// namespace step1 END</span>
 
<span class="preprocessor"> #endif // CUDADriver_STEP_1_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CUDA_DRIVER_STEP_1_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define CUDA_DRIVER_STEP_1_HH</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;base/CUDATimer.h&gt;</span>
 
<span class="preprocessor"> #include &lt;step-1/cuda_driver_step-1.h&gt;</span>
 
<span class="preprocessor"> #include &lt;step-1/cuda_kernel_wrapper_step-1.cu.h&gt;</span>
 
 
 
<span class="preprocessor"> #include &lt;QTime&gt;</span>
</pre></div><p> <a class="anchor" id="plain-ConstructorCUDADriver"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 step1::CUDADriver&lt;T&gt;::CUDADriver(<span class="keyword">const</span> SimParams &amp;p)
     :
       params(&amp;p)
 {}
</pre></div><p> <a class="anchor" id="plain-Functionfactorize"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">double</span>
 step1::CUDADriver&lt;T&gt;::factorize(FullMatrixAccessor&amp; A)
 {
     this-&gt;A_d = A;
 
     QTime t;
     t.start();
     this-&gt;cholesky.blackbox(this-&gt;A_d.array().val(), this-&gt;A_d.n_cols(), this-&gt;A_d.leading_dim );
 
     <span class="keywordtype">double</span> kernel_time = t.elapsed()/1000.;
 
     A = this-&gt;A_d;
 
     <span class="keywordflow">return</span> kernel_time;
 }
</pre></div><p> <a class="anchor" id="plain-Functionchol_fac"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span>
 step1::CUDADriver&lt;T&gt;::chol_fac(FullMatrixAccessor&amp; A, TimerName2Value&amp; times)
 {
     this-&gt;A_d = A;
 
     QTime t;
 
     T* a_d = this-&gt;A_d.array().val();
 
     <span class="keywordtype">int</span> n_rows = this-&gt;A_d.n_rows();
 
     <span class="keywordtype">int</span> leading_dim = this-&gt;A_d.leading_dim;
 
 
     <span class="keywordtype">int</span> n_blocks = (A.n_rows()+int(DEFAULT_TILE_SIZE)-1)/<span class="keywordtype">int</span>(DEFAULT_TILE_SIZE);
 
     times[<span class="stringliteral">&quot;factorize_diagonal_block&quot;</span>] = 0.;
     times[<span class="stringliteral">&quot;strip_update&quot;</span>] = 0.;
     times[<span class="stringliteral">&quot;diag_update&quot;</span>] = 0.;
     times[<span class="stringliteral">&quot;lo_update&quot;</span>] = 0.;
 
     <span class="keywordflow">for</span>(<span class="keywordtype">int</span> i = n_blocks; i &gt; 2; --i)
     {
         t.restart();
 
 
         cudaError_t error = this-&gt;cholesky.factorize_diag_block(a_d, n_blocks-i, n_rows, leading_dim);
 
         times[<span class="stringliteral">&quot;factorize_diagonal_block&quot;</span>]+=t.elapsed();
 
         AssertThrow(error == cudaSuccess, dealii::ExcMessage( cudaGetErrorString(error) ) );
 
 
         t.restart();
         this-&gt;cholesky.strip_update(a_d, n_blocks-i, i, n_rows, leading_dim);
 
         times[<span class="stringliteral">&quot;strip_update&quot;</span>]+=t.elapsed();
 
 
         t.restart();
         this-&gt;cholesky.diag_update(a_d, n_blocks-i, i, n_rows, leading_dim);
 
         times[<span class="stringliteral">&quot;diag_update&quot;</span>]+=t.elapsed();
 
 
         t.restart();
         this-&gt;cholesky.lo_update(a_d, n_blocks-i, n_blocks, i, n_rows, leading_dim);
 
         times[<span class="stringliteral">&quot;lo_update&quot;</span>]+=t.elapsed();
     }
 
     <span class="keywordflow">if</span>(n_blocks&gt;1)
     {
         this-&gt;cholesky.factorize_diag_block(a_d, n_blocks-2, n_rows, leading_dim);
 
         this-&gt;cholesky.strip_update(a_d, n_blocks-2, 2, n_rows, leading_dim);
 
         this-&gt;cholesky.diag_update(a_d, n_blocks-2, 2,  n_rows, leading_dim);
     }
 
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;Cholesky decomposition...&quot;</span> &lt;&lt; std::endl;
     this-&gt;cholesky.factorize_diag_block(a_d, n_blocks-1, n_rows, leading_dim);
 
     A = this-&gt;A_d;
 }
</pre></div><p> <a class="anchor" id="plain-Functionsingle_thread_cholesky"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span>
 step1::CUDADriver&lt;T&gt;::single_thread_cholesky(FullMatrixAccessor&amp; A)
 {
     this-&gt;A_d = A;
 
     this-&gt;cholesky.single_thread(this-&gt;A_d.array().val(),
                                  this-&gt;A_d.n_rows(), this-&gt;A_d.leading_dim );
 
     A = this-&gt;A_d;
 }
 
<span class="preprocessor"> #endif // CUDA_DRIVER_STEP_1_HH</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef SIM_PARAMETER_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define SIM_PARAMETER_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;deal.II/base/parameter_handler.h&gt;</span>
 
<span class="preprocessor"> #include &lt;QDir&gt;</span>
 
 <span class="keyword">namespace </span>step1 {
</pre></div><p> <a class="anchor" id="plain-ClassSimParams"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">struct </span>SimParams {
 
     SimParams() {}
 
     <span class="keyword">static</span> <span class="keywordtype">void</span> declare(dealii::ParameterHandler &amp; prm);
 
     <span class="keywordtype">void</span> <span class="keyword">get</span>(dealii::ParameterHandler &amp; prm);
 
     <span class="keywordtype">int</span>
     device,
     matrix_low,
     matrix_high,
     step_size,
     average_runs;
 
     <span class="keywordtype">bool</span> use_double;
 
     QDir run_dir;
 
 <span class="keyword">private</span>:
     SimParams(<span class="keyword">const</span> SimParams&amp; / *other* /) {}
 
     SimParams&amp; operator= (<span class="keyword">const</span> SimParams&amp; / *other* /)
     {
         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
     }
 
 };
 }
 
 
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef SIM_PARAMETER_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define SIM_PARAMETER_HH</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;deal.II/base/parameter_handler.h&gt;</span>
<span class="preprocessor"> #include &lt;step-1/SimParams.h&gt;</span>
</pre></div><p> <a class="anchor" id="plain-Functiondeclare"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">void</span>
 step1::SimParams::declare(dealii::ParameterHandler &amp; prm)
 {
     prm.enter_subsection(<span class="stringliteral">&quot;Simulation basics&quot;</span>);
 
     prm.declare_entry(<span class="stringliteral">&quot;Run directory&quot;</span>, <span class="stringliteral">&quot;./test_me&quot;</span>,
                       dealii::Patterns::Anything(),
                       <span class="stringliteral">&quot;Specify a directory where results of &quot;</span>
                       <span class="stringliteral">&quot;the test are to be stored. This can be either &quot;</span>
                       <span class="stringliteral">&quot;an absolute path or path relative to the directory &quot;</span>
                       <span class="stringliteral">&quot;where the program has been started. The default is &quot;</span>
                       <span class="stringliteral">&quot;subdir called test_me-&lt;date&gt; where &lt;date&gt; will be replaced &quot;</span>
                       <span class="stringliteral">&quot;by the date at which the program has been started. &quot;</span>
                       <span class="stringliteral">&quot;this simplifies keeping the projects directory clean &quot;</span>
                       <span class="stringliteral">&quot;&quot;</span>);
 
     prm.leave_subsection();
 
 
     prm.enter_subsection(<span class="stringliteral">&quot;CUDA parameters&quot;</span>);
 
 
     prm.declare_entry(<span class="stringliteral">&quot;Device&quot;</span>, <span class="stringliteral">&quot;0&quot;</span>,
                       dealii::Patterns::Integer(),
                       <span class="stringliteral">&quot;which CUDA-enabled GPU should be used&quot;</span>);
 
     prm.declare_entry(<span class="stringliteral">&quot;Shared Memory&quot;</span>, <span class="stringliteral">&quot;true&quot;</span>,
                       dealii::Patterns::Bool(),
                       <span class="stringliteral">&quot;Whether shared (true) or L1 (false) memory should be used.&quot;</span>);
 
 
     prm.leave_subsection();
 
     prm.enter_subsection(<span class="stringliteral">&quot;Testcase parameters&quot;</span>);
 
     prm.declare_entry(<span class="stringliteral">&quot;Double-Precision&quot;</span>,<span class="stringliteral">&quot;true&quot;</span>,
                       dealii::Patterns::Bool(),
                       <span class="stringliteral">&quot;Decide between double (true) or float (false) precision&quot;</span>);
 
     prm.declare_entry(<span class="stringliteral">&quot;Matrix size - lower limit&quot;</span>, <span class="stringliteral">&quot;256&quot;</span>,
                       dealii::Patterns::Integer(),
                       <span class="stringliteral">&quot;Start value of the range of matrix sizes tested by the simulation&quot;</span>);
 
 
     prm.declare_entry(<span class="stringliteral">&quot;Matrix size - upper limit&quot;</span>, <span class="stringliteral">&quot;513&quot;</span>,
                       dealii::Patterns::Integer(),
                       <span class="stringliteral">&quot;End value of the range of matrix sizes tested by the simulation&quot;</span>);
 
     prm.declare_entry(<span class="stringliteral">&quot;Matrix size - step size&quot;</span>, <span class="stringliteral">&quot;1024&quot;</span>,
                       dealii::Patterns::Integer(),
                       <span class="stringliteral">&quot;Increment for the size of the test matrices&quot;</span>);
 
     prm.declare_entry(<span class="stringliteral">&quot;Average - runs&quot;</span>, <span class="stringliteral">&quot;10&quot;</span>,
                       dealii::Patterns::Integer(),
                       <span class="stringliteral">&quot;Number of runs being used for averaging&quot;</span>);
 
     prm.leave_subsection();
 
 }
</pre></div><p> <a class="anchor" id="plain-Functionget"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">void</span>
 step1::SimParams::get(dealii::ParameterHandler &amp; prm)
 {
     prm.enter_subsection(<span class="stringliteral">&quot;Simulation basics&quot;</span>);
 
     run_dir.setPath(prm.get(<span class="stringliteral">&quot;Run directory&quot;</span>).c_str());
     run_dir.makeAbsolute();
 
     <span class="keywordflow">if</span> (!run_dir.exists())
         run_dir.mkpath(<span class="stringliteral">&quot;.&quot;</span>);
 
     prm.leave_subsection();
 
     prm.enter_subsection(<span class="stringliteral">&quot;CUDA parameters&quot;</span>);
 
     device        = prm.get_integer(<span class="stringliteral">&quot;Device&quot;</span>);
 
     prm.leave_subsection();
 
     prm.enter_subsection(<span class="stringliteral">&quot;Testcase parameters&quot;</span>);
 
 
     use_double   = prm.get_bool(<span class="stringliteral">&quot;Double-Precision&quot;</span>);
 
     matrix_low   = prm.get_integer(<span class="stringliteral">&quot;Matrix size - lower limit&quot;</span>);
 
     matrix_high  = prm.get_integer(<span class="stringliteral">&quot;Matrix size - upper limit&quot;</span>);
 
     step_size    = prm.get_integer(<span class="stringliteral">&quot;Matrix size - step size&quot;</span>);
 
     average_runs = prm.get_integer(<span class="stringliteral">&quot;Average - runs&quot;</span>);
 
 
     prm.leave_subsection();
 
 
 }
 
 
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #include &lt;iostream&gt;</span>
<span class="preprocessor"> #include &lt;vector&gt;</span>
 
<span class="preprocessor"> #include &lt;QThread&gt;</span>
<span class="preprocessor"> #include &lt;QTime&gt;</span>
 
<span class="preprocessor"> #include &lt;deal.II/base/convergence_table.h&gt;</span>
<span class="preprocessor"> #include &lt;deal.II/base/parameter_handler.h&gt;</span>
<span class="preprocessor"> #include &lt;deal.II/lac/full_matrix.h&gt;</span>
 
<span class="preprocessor"> #include &lt;QDir&gt;</span>
 
 
<span class="preprocessor"> #include &lt;step-1/SimParams.h&gt;</span>
 
<span class="preprocessor"> #include &lt;step-1/cuda_driver_step-1.h&gt;</span>
<span class="preprocessor"> #include &lt;step-1/cuda_driver_step-1.hh&gt;</span>
 
<span class="preprocessor"> #include &lt;lac/FullMatrixAccessor.h&gt;</span>
<span class="preprocessor"> #include &lt;lac/MatrixCreator.h&gt;</span>
 
 
 <span class="keyword">namespace </span>step1 {
</pre></div><p> <a class="anchor" id="plain-ClassCholeskyTest"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 <span class="keyword">class </span>CholeskyTest : <span class="keyword">public</span> QThread
 {
     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> max_display_size = 20;
 
 <span class="keyword">public</span>:
 
     CholeskyTest(<span class="keywordtype">int</span> n_r,
                  dealii::ConvergenceTable&amp; s_table,
                  <span class="keyword">const</span> SimParams &amp;_params);
 
 <span class="keyword">protected</span>:
 
     <span class="keywordtype">void</span> setup_and_assemble_test_matrix();
 
     <span class="keywordtype">void</span> factorize();
 
     <span class="keywordtype">void</span> check_results();
 
     <span class="keywordtype">void</span> run();
 
 
 
     <span class="keywordtype">int</span> n_rows;
 
     dealii::ConvergenceTable &amp; speedup_table;
 
     dealii::FullMatrix&lt;Number&gt; A, L, L_T;
 
 <span class="keyword">private</span>:
 
     <span class="keyword">const</span> SimParams * params;
 };
</pre></div><p> <a class="anchor" id="plain-ClassCholesky"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">class </span>Cholesky {
 
 <span class="keyword">public</span>:
     <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt; <span class="keyword">static</span> <span class="keywordtype">void</span> cpu(std::vector&lt;std::vector&lt;T&gt; &gt; &amp; A);
 
     <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt; <span class="keyword">static</span> <span class="keywordtype">void</span> cpu_tiled(T* A, <span class="keywordtype">int</span> tile_size);
 
     <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt; <span class="keyword">static</span> <span class="keywordtype">void</span> LLtMult(T * A, <span class="keyword">const</span> T * L, <span class="keywordtype">int</span> n_rows);
 };
</pre></div><p> <a class="anchor" id="plain-ConstructorCholeskyTest"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 CholeskyTest&lt;Number&gt;::CholeskyTest(<span class="keywordtype">int</span> n_r,
                                    dealii::ConvergenceTable&amp; s_table,
                                    <span class="keyword">const</span> SimParams &amp;_params)
     :
       n_rows(n_r),
       speedup_table(s_table),
       params(&amp;_params)
 {}
</pre></div><p> <a class="anchor" id="plain-Functionsetup_and_assemble_test_matrix"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 <span class="keywordtype">void</span> CholeskyTest&lt;Number&gt;::setup_and_assemble_test_matrix()
 {
     this-&gt;A.reinit(n_rows, n_rows);
     this-&gt;L.reinit(n_rows, n_rows);
     this-&gt;L_T.reinit(n_rows, n_rows);
 
     QTime t;
 
     this-&gt;speedup_table.add_value(<span class="stringliteral">&quot;n rows&quot;</span>, n_rows);
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;Initial Cholesky factor deal.II :&quot;</span> &lt;&lt; std::endl;
     std::cout &lt;&lt; <span class="stringliteral">&quot;----------------------------------------------------&quot;</span>
               &lt;&lt; std::endl;
 
<span class="preprocessor"> #ifdef USE_HADAMARD</span>
<span class="preprocessor"></span>     MatrixCreator::extended_hadamard(n_rows, A);
<span class="preprocessor"> #else</span>
<span class="preprocessor"></span>     t.start();
 
     <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> r = 0; r &lt; n_rows; ++r)
         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> c = r; c &lt;n_rows; ++c)
             L(r,c) = 1e-0*(r+2)*(c+2);
 
 
     <span class="keywordflow">if</span>(<span class="keyword">false</span>)
     qDebug(<span class="stringliteral">&quot;Time for CPU-based setup of Cholesky factor : %f s&quot;</span>,
            t.elapsed()/1000.);
 
     <span class="keywordflow">if</span> ( L.n_rows() &lt; max_display_size)
         L.print(std::cout, 10, 5);
     <span class="keywordflow">if</span> ( L.n_rows() &lt; max_display_size)
         std::cout &lt;&lt; std::endl;std::cout &lt;&lt; std::endl;
 
     {
         t.restart();
         L_T.copy_from(L);
         <span class="keywordflow">if</span>(<span class="keyword">false</span>)
         qDebug(<span class="stringliteral">&quot;Time for CPU-based copying of Cholesky factor : %f s&quot;</span>,
                t.elapsed()/1000.);
 
         t.restart();
         L_T.Tmmult(A, L, <span class="keyword">false</span>);
         <span class="keywordflow">if</span>(<span class="keyword">false</span>)
         qDebug(<span class="stringliteral">&quot;Time for CPU-based multiplication of Cholesky factor&quot;</span>
                <span class="stringliteral">&quot; : %f s&quot;</span>,
                t.elapsed()/1000.);
         L_T.copy_from(A);
     }
 
     <span class="keywordflow">if</span> ( A.n_rows() &lt; max_display_size)
     {
         std::cout &lt;&lt; <span class="stringliteral">&quot;Matrix to factorize :&quot;</span> &lt;&lt; std::endl;
         std::cout &lt;&lt; <span class="stringliteral">&quot;----------------------------------------------------&quot;</span>
                   &lt;&lt; std::endl;
 
         A.print(std::cout, 10, 5);
 
         std::cout &lt;&lt; std::endl;std::cout &lt;&lt; std::endl;
     }
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
 }
</pre></div><p> <a class="anchor" id="plain-Functionrun"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 <span class="keywordtype">void</span> CholeskyTest&lt;Number&gt;::run()
 {
     this-&gt;setup_and_assemble_test_matrix();
 
     QTime t;
     <span class="keywordtype">double</span> cpu_time, gpu_time;
 
     FullMatrixAccessor&lt;Number&gt; A_h_cpu(A, <span class="keyword">true</span>);
     {
         t.restart();
 
 
         Cholesky::cpu_tiled&lt;Number&gt;(A_h_cpu.val(), A_h_cpu.n_rows() );
 
 
         cpu_time =  t.elapsed()/1000.;
         <span class="keywordflow">if</span> (<span class="keyword">false</span>)
         qDebug(<span class="stringliteral">&quot;Time for CPU-based Cholesky factorization : %f s&quot;</span>,
                cpu_time);
 
         this-&gt;speedup_table.add_value(<span class="stringliteral">&quot;CPU factorization&quot;</span>, cpu_time);
         this-&gt;speedup_table.set_precision(<span class="stringliteral">&quot;CPU factorization&quot;</span>, 10);
 
 
         std::cout &lt;&lt; <span class="stringliteral">&quot;CPU-factorized Matrix (lower triangle contains &quot;</span>
                   &lt;&lt; <span class="stringliteral">&quot;transposed Cholesky factor) :&quot;</span> &lt;&lt; std::endl;
         std::cout &lt;&lt; <span class="stringliteral">&quot;----------------------------------------------------&quot;</span>
                   &lt;&lt; std::endl;
 
         <span class="keywordflow">if</span> ( A.n_rows() &lt; max_display_size)
             A_h_cpu.print(); <span class="comment">//std::cout, 10, 5);</span>
 
     }
 
     std::cout &lt;&lt; std::endl;std::cout &lt;&lt; std::endl;
 
 
     Assert( A.n_rows() == A.n_cols(),
             dealii::ExcMessage(<span class="stringliteral">&quot;Matrix not square! Cholesky impossible&quot;</span>));
 
 
     <span class="keywordtype">double</span> kernel_time = 0;
 
     CUDADriver&lt;Number&gt; run(*params);
     t.restart();
     {
         FullMatrixAccessor&lt;Number&gt; A_h(A, <span class="keyword">true</span>);
         kernel_time = run.factorize(A_h);
 
         gpu_time =  t.elapsed()/1000.;
 
         <span class="keywordflow">if</span> (<span class="keyword">false</span>)
         qDebug(<span class="stringliteral">&quot;Time for GPU-based Cholesky factorization %f&quot;</span>
                <span class="stringliteral">&quot; including data transfer : %f s\n&quot;</span>
                <span class="stringliteral">&quot;speed up factor factorization : %f netto : %f n_rows : %d\n&quot;</span>,
                kernel_time,
                gpu_time,
                cpu_time/kernel_time,
                cpu_time/gpu_time,
                n_rows);
 
 
         std::cout &lt;&lt; <span class="stringliteral">&quot;GPU-factorized Matrix (lower triangle contains &quot;</span>
                   &lt;&lt; <span class="stringliteral">&quot;transposed Cholesky factor) :&quot;</span> &lt;&lt; std::endl;
         std::cout &lt;&lt; <span class="stringliteral">&quot;----------------------------------------------------&quot;</span>
                   &lt;&lt; std::endl;
 
         <span class="keywordflow">if</span> ( A_h.n_rows() &lt; max_display_size)
             A_h.print(); <span class="comment">//std::cout, 10, 5);</span>
 
         A_h_cpu -= A_h;
 
         std::cout &lt;&lt; <span class="stringliteral">&quot;difference of factorized matrices &quot;</span>
                         &lt;&lt; <span class="stringliteral">&quot; :&quot;</span> &lt;&lt; std::endl;
               std::cout &lt;&lt; <span class="stringliteral">&quot;----------------------------------------------------&quot;</span>
                         &lt;&lt; std::endl;
 
               <span class="keywordflow">if</span> ( A_h_cpu.n_rows() &lt; max_display_size)
                   A_h_cpu.print(); <span class="comment">//std::cout, 10, 5);</span>
 
               <span class="keywordtype">double</span> F_norm =  A_h_cpu.frobenius_norm();
 
         std::cout &lt;&lt; <span class="stringliteral">&quot;||A_cpu - A_d ||_F = &quot;</span> &lt;&lt; F_norm &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>
                   &lt;&lt; <span class="stringliteral">&quot;||A_cpu - A_d ||_F/n_el = &quot;</span> &lt;&lt; F_norm/A_h_cpu.n_elements() &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>
                   &lt;&lt; <span class="stringliteral">&quot;||A_cpu - A_d ||_F/||A_d||_F = &quot;</span> &lt;&lt; F_norm/A_h.frobenius_norm() &lt;&lt; std::endl;
 
     }
 
     this-&gt;speedup_table.add_value(<span class="stringliteral">&quot;pure GPU fac&quot;</span>, kernel_time);
     this-&gt;speedup_table.set_precision(<span class="stringliteral">&quot;pure GPU fac&quot;</span>, 10);
 
     this-&gt;speedup_table.add_value(<span class="stringliteral">&quot;GPU fac incl data transfer&quot;</span>, gpu_time);
     this-&gt;speedup_table.set_precision(<span class="stringliteral">&quot;GPU fac incl data transfer&quot;</span>, 10);
 
     FullMatrixAccessor&lt;Number&gt; A_h(A, <span class="keyword">true</span>);
     FullMatrixAccessor&lt;Number&gt; A_original = A_h;
 
     {
         <span class="keyword">typename</span> CUDADriver&lt;Number&gt;::TimerName2Value times;
 
         run.chol_fac(A_h, times);
 
 
         <span class="keyword">typename</span> CUDADriver&lt;Number&gt;::TimerName2Value::const_iterator
                 e=times.begin(),
                 end_t=times.end();
 
         <span class="keywordflow">for</span>( ; e != end_t ; ++e)
         {
             this-&gt;speedup_table.add_value(e-&gt;first, e-&gt;second);
             this-&gt;speedup_table.set_precision(e-&gt;first,10);
         }
     }
     <span class="keywordflow">return</span>;
 }
</pre></div><p> <a class="anchor" id="plain-Functioncpu_tiled"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> Cholesky::cpu_tiled(T* A,
                          <span class="keywordtype">int</span> tile_size)
 {
 
     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> r = 0; r &lt; tile_size; ++r)
     {
         T sum = 0.;
         <span class="keywordtype">int</span> idx;
         <span class="keywordtype">int</span> idx_c;
 
         <span class="keywordflow">for</span> (<span class="keywordtype">int</span> u = 0; u &lt; r; ++u)
         {
             idx = r*tile_size + u;
             sum += A[idx] * A[idx];
         }
         idx = r*tile_size + r;
         A[idx] = sqrt(A[idx] - sum);
 
         <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = r+1; c &lt; tile_size; ++c)
         {
             T tmp = 0.;
 
             <span class="keywordflow">for</span> (<span class="keywordtype">int</span> u = 0; u &lt; r; ++u)
             {
                 idx_c = c*tile_size + u;
                 idx   = r*tile_size + u;
                 tmp += A[idx_c]*A[idx];
             }
 
             idx_c = c*tile_size + r;
             idx   = r*tile_size + c;
             A[idx_c]  = A[idx] - tmp;
             A[idx_c] /= A[r*tile_size + r];
         }
     }
 }
</pre></div><p> <a class="anchor" id="plain-FunctionLLtMult"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> Cholesky::LLtMult(T * A, <span class="keyword">const</span> T * L, <span class="keywordtype">int</span> n_rows)
 {
     <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> r = 0; r &lt; n_rows; ++r)
         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> c = 0; c &lt;=r; ++c)
         {
             <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> idx = c + (r*(r+1))/2;
             <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k_max = std::min(r,c);
 
             A[idx] = 0.;
 
             <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k = 0; k &lt; k_max; ++k)
             {
                 <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> idx_k   = k + (r*(r+1))/2;
                 <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> idx_k_T = k + (c*(c+1))/2;
 
                 A[idx] += L[idx_k]*L[idx_k_T];
             }
         }
 }
</pre></div><p> <a class="anchor" id="plain-ClassMyFancySimulation"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 <span class="keyword">class </span>MyFancySimulation {
 
 <span class="keyword">public</span>:
 
     MyFancySimulation(SimParams &amp;p);
 
     <span class="keywordtype">void</span> run();
 
     <span class="keyword">static</span> std::string precision_id();
 
 <span class="keyword">private</span>:
     <span class="keyword">const</span> SimParams * params;
 
 };
</pre></div><p> <a class="anchor" id="plain-Constructor"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Number&gt;
 step1::MyFancySimulation&lt;Number&gt;::MyFancySimulation(SimParams &amp;p)
     :
       params(&amp;p)
 {
     cudaSetDevice(params-&gt;device); 
 }
</pre></div><p> <a class="anchor" id="plain-Functionprecision_id"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;&gt;
 std::string MyFancySimulation&lt;float&gt;::precision_id()
 {
     <span class="keywordflow">return</span> <span class="stringliteral">&quot;float&quot;</span>;
 }
 
 <span class="keyword">template</span>&lt;&gt;
 std::string MyFancySimulation&lt;double&gt;::precision_id()
 {
     <span class="keywordflow">return</span> <span class="stringliteral">&quot;double&quot;</span>;
 }
 
 }
</pre></div><p> <a class="anchor" id="plain-Functionrun"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 <span class="keywordtype">void</span> step1::MyFancySimulation&lt;Number&gt;::run()
 {   
 
     std::ostringstream filename;
 
     filename &lt;&lt; <span class="stringliteral">&quot;chol_fac_times_&quot;</span> &lt;&lt; params-&gt;matrix_low &lt;&lt; <span class="stringliteral">&quot;_&quot;</span> &lt;&lt; precision_id().c_str() &lt;&lt; <span class="stringliteral">&quot;.dat&quot;</span>;
 
 
     dealii::ConvergenceTable factorization_times;
 
     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> n = params-&gt;matrix_low; n &lt; params-&gt;matrix_high; n+=params-&gt;step_size)
     {
         CholeskyTest&lt;Number&gt; driver(n, factorization_times, *params);
 
         driver.start();
         / * driver.run();* /
         driver.wait();
 
         std::ofstream out(filename.str().c_str());
         factorization_times.write_text(out);
     }
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;Done.&quot;</span> &lt;&lt; std::endl;
 }
</pre></div><p> <a class="anchor" id="plain-Funktionmain"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> *argv[])
 {
     <span class="keyword">using namespace </span>step1;
 
     SimParams params;
 
     dealii::ParameterHandler prm_handler;
 
     QDir cwd = QDir::current();
 
     <span class="keyword">const</span> QDir launch_dir = cwd;
     cwd.setPath(<span class="stringliteral">&quot;../step-1&quot;</span>);
 
     std::string prm_filename;
     <span class="keywordflow">if</span> (argc == 1)
     {
         std::string tmp = argv[0];
         <span class="keywordtype">int</span> found=tmp.find_last_of(<span class="charliteral">&#39;/&#39;</span>);
         prm_filename = tmp.substr(found+1);
         prm_filename += <span class="stringliteral">&quot;-Decomp.prm&quot;</span>;
 
         cwd.setPath(<span class="stringliteral">&quot;./prm&quot;</span>);
     }
     <span class="keywordflow">else</span>
     {
         QFileInfo tmp(argv[1]);
 
         QString prm_path = tmp.absolutePath();
         cwd.setPath(prm_path);
         cwd.makeAbsolute();
         prm_filename = tmp.fileName().toStdString();
 
         std::cout &lt;&lt; <span class="stringliteral">&quot;chosen prm file : &quot;</span> &lt;&lt; tmp.absoluteFilePath().toStdString().c_str() &lt;&lt; std::endl;
     }
 
     <span class="keywordflow">if</span> (!cwd.exists() )
         launch_dir.mkpath( cwd.absolutePath() );
 
     QDir::setCurrent(cwd.absolutePath());
     SimParams::declare(prm_handler);
     prm_handler.read_input (prm_filename);
 
     QDir::setCurrent(launch_dir.absolutePath());
 
     params.get(prm_handler);
 
     cwd.setPath(params.run_dir.absolutePath());
     <span class="keywordflow">if</span> (!cwd.exists())
         cwd.mkpath( <span class="stringliteral">&quot;.&quot;</span> );
 
     QDir::setCurrent(cwd.absolutePath());
 
     cwd.setPath(<span class="stringliteral">&quot;./log&quot;</span>);
     cwd.makeAbsolute();
     <span class="keywordflow">if</span> (!cwd.exists())
         cwd.mkpath(<span class="stringliteral">&quot;.&quot;</span>);
 
     QDir::setCurrent(cwd.absolutePath());
 
     prm_filename += <span class="stringliteral">&quot;.log&quot;</span>;
     std::ofstream log_out_text(prm_filename.c_str());
     prm_handler.print_parameters (log_out_text,
                                   dealii::ParameterHandler::Text);
 
     QDir::setCurrent(params.run_dir.absolutePath());
 
 
     <span class="keywordflow">if</span> (!params.use_double) {
 
         MyFancySimulation&lt;float&gt; machma_float(params);
 
         machma_float.run();
     }
     <span class="keywordflow">else</span> {
 
         MyFancySimulation&lt;double&gt; machma_double(params);
 
         machma_double.run();
     }
 }
</pre></div> </div></div><!-- contents -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Files</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<hr size="1"><address style="align: right;"><small>
<img src="logo200.png" alt="blanc++"> documentation generated on Sun Jul 27 2014 17:41:51 by <a href="http://www.doxygen.org/index.html">
doxygen
</a> 1.7.6.1</small></address>
</body>
</html>
