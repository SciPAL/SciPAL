<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                 "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
  <link href="stylesheet.css" rel="stylesheet" type="text/css">
  <link href="tabs.css" rel="stylesheet" type="text/css">
  <title>The step-2 tutorial program</title>
  <meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1">
  <meta name="author" content="the blanc and blanc++ authors <authors@dealii.org>">
  <meta name="copyright" content="Copyright (C) 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007 by the deal.II authors">
  <meta name="blanc++ version" content="1.0.0">
</head>
<body>
<div class="head">
  <h1 class="head">CUDA Lab Course Reference Manual 2013</h1>
</div>
<!-- Generated by Doxygen 1.7.6.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<div class="title">The step-2 tutorial program </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"> 
<table class="tutorial" width="100%">
<tr><th colspan="2"><b><small>Table of contents</small></b></th></tr>
<tr><td width="50%" valign="top">
<ol>
  <li> <a href="#Intro" class=bold>Introduction</a>
    <ul>
      </ul>
  <li> <a href="#CommProg" class=bold>The commented program</a>
    <ul>
      <ul>
        <li><a href="#Functionmain">Function: main</a>
      </ul>
        <li><a href="#ClassMyFancySimulation">Class: MyFancySimulation</a>
      <ul>
        <li><a href="#ConstructorMyFancySimulation">Constructor: MyFancySimulation</a>
        <li><a href="#Functionrun">Function: run</a>
        <li><a href="#Functionsave_results">Function: save_results</a>
      </ul>
        <li><a href="#EnumMVCase">Enum: MVCase</a>
        <li><a href="#structSimUIParams">struct: SimUIParams</a>
        <li><a href="#ClassTestUIParamsBase">Class: TestUIParamsBase</a>
        <li><a href="#ClassMVTestUIParams">Class: MVTestUIParams</a>
        <li><a href="#ClassMVTest">Class: MVTest</a>
      <ul>
        <li><a href="#Constructor">Constructor</a>
        <li><a href="#Destructor">Destructor</a>
        <li><a href="#Functionrun">Function: run</a>
        <li><a href="#Functionsetup_and_assemble">Function: setup_and_assemble</a>
      </ul>
        <li><a href="#ClassMVMultDriverInterface">Class: MVMultDriverInterface</a>
      <ul>
        <li><a href="#Functionmvmult">Function: mvmult</a>
      </ul>
        <li><a href="#ClassCpuBlasDriver">Class: CpuBlasDriver</a>
      <ul>
        <li><a href="#Functionmvmult">Function: mvmult</a>
      </ul>
        <li><a href="#ClassCUBlasDriver">Class: CUBlasDriver</a>
      <ul>
        <li><a href="#ConstructorCUBlasDriver">Constructor: CUBlasDriver</a>
        <li><a href="#DestructorCUBlasDriver">Destructor: CUBlasDriver</a>
        <li><a href="#Functionmvmult">Function: mvmult</a>
      </ul>
        <li><a href="#ClassFujimotoDriver">Class: FujimotoDriver</a>
      <ul>
        <li><a href="#Functionmvmult">Function: mvmult</a>
      </ul>
        <li><a href="#DeclarationofCUDAInterface">Declaration of CUDA Interface</a>
        <li><a href="#ClassKernels">Class: Kernels</a>
        <li><a href="#Kernels">Kernels</a>
      <ul>
        <li><a href="#Kernel_mv_fujimoto">Kernel: _mv_fujimoto</a>
        <li><a href="#Kernel_mv_fujimoto_T">Kernel: _mv_fujimoto_T</a>
        <li><a href="#Kernel_mv_fujimoto_T2">Kernel: _mv_fujimoto_T2</a>
        <li><a href="#Kernel_mv_fujimoto_T3">Kernel: _mv_fujimoto_T3</a>
        <li><a href="#Functionmv_fujimoto">Function: mv_fujimoto</a>
      </ul>
      </ul>
</ol></td><td width="50%" valign="top"><ol>
  <li value="3"> <a href="#Results" class=bold>Results</a>
    <ul>
        <li><a href="#Plots">Plots</a>
      </ul>
  <li> <a href="#PlainProg" class=bold>The plain program</a>
    <ul>
      <ul>
        <li><a href="#plain-Functionmain">Function: main</a>
      </ul>
        <li><a href="#plain-ClassMyFancySimulation">Class: MyFancySimulation</a>
      <ul>
        <li><a href="#plain-ConstructorMyFancySimulation">Constructor: MyFancySimulation</a>
        <li><a href="#plain-Functionrun">Function: run</a>
        <li><a href="#plain-Functionsave_results">Function: save_results</a>
      </ul>
        <li><a href="#plain-EnumMVCase">Enum: MVCase</a>
        <li><a href="#plain-structSimUIParams">struct: SimUIParams</a>
        <li><a href="#plain-ClassTestUIParamsBase">Class: TestUIParamsBase</a>
        <li><a href="#plain-ClassMVTestUIParams">Class: MVTestUIParams</a>
        <li><a href="#plain-ClassMVTest">Class: MVTest</a>
      <ul>
        <li><a href="#plain-Constructor">Constructor</a>
        <li><a href="#plain-Destructor">Destructor</a>
        <li><a href="#plain-Functionrun">Function: run</a>
        <li><a href="#plain-Functionsetup_and_assemble">Function: setup_and_assemble</a>
      </ul>
        <li><a href="#plain-ClassMVMultDriverInterface">Class: MVMultDriverInterface</a>
      <ul>
        <li><a href="#plain-Functionmvmult">Function: mvmult</a>
      </ul>
        <li><a href="#plain-ClassCpuBlasDriver">Class: CpuBlasDriver</a>
      <ul>
        <li><a href="#plain-Functionmvmult">Function: mvmult</a>
      </ul>
        <li><a href="#plain-ClassCUBlasDriver">Class: CUBlasDriver</a>
      <ul>
        <li><a href="#plain-ConstructorCUBlasDriver">Constructor: CUBlasDriver</a>
        <li><a href="#plain-DestructorCUBlasDriver">Destructor: CUBlasDriver</a>
        <li><a href="#plain-Functionmvmult">Function: mvmult</a>
      </ul>
        <li><a href="#plain-ClassFujimotoDriver">Class: FujimotoDriver</a>
      <ul>
        <li><a href="#plain-Functionmvmult">Function: mvmult</a>
      </ul>
        <li><a href="#plain-DeclarationofCUDAInterface">Declaration of CUDA Interface</a>
        <li><a href="#plain-ClassKernels">Class: Kernels</a>
        <li><a href="#plain-Kernels">Kernels</a>
      <ul>
        <li><a href="#plain-Kernel_mv_fujimoto">Kernel: _mv_fujimoto</a>
        <li><a href="#plain-Kernel_mv_fujimoto_T">Kernel: _mv_fujimoto_T</a>
        <li><a href="#plain-Kernel_mv_fujimoto_T2">Kernel: _mv_fujimoto_T2</a>
        <li><a href="#plain-Kernel_mv_fujimoto_T3">Kernel: _mv_fujimoto_T3</a>
        <li><a href="#plain-Functionmv_fujimoto">Function: mv_fujimoto</a>
      </ul>
      </ul>
</ol> </td> </tr> </table>
 <a class="anchor" id="Introduction"></a></p>
<h1>Introduction</h1>
<p><a class="anchor" id="Overview"></a></p>
<h2>Overview </h2>
<p>A fundamental operation in scientific computing is the multiplication of a dense matrix with a dense vector. This program compares the performance of different implementations of this product using different hardware. A parallelized CPU version and two different CUDA implementations are benchmarked against each other. The results of running this program are two diagrams containing the runtimes of the different implementations and the speedup of the CUDA variants over the CPU-based version over a wide range of matrix sizes. </p>
<p>On the CPU we use the gemv fcuntino from ATLAS which is an open-source implementation of BLAS available on virtually any standard Linux installation. On the GPU we use gemv from CUDA's CUBLAS and Fujmoto's texture-based CUDA implementation of a matrix-vector product.  </p>
<p>The mathematical operation itself is rather straightforward. Thus, this program rather addresses several issues of practical importance: </p>
<ul>
<li>
The deal.II's ParameterHandler class is employed in order to feed the program with information at runtime, e.g. for which matrix sizes the tests should be performed  </li>
<li>
The directory from where the program is launched is separated from the directory where the results are to be stored. To do this, several QT classes are used.  </li>
<li>
Object-orientation is employed to create an extensible framework for unit testing of matrix-vector multiplications and similar operations.  </li>
<li>
To minimize the amount of source code template classes are used to implement the tests for the different BLAS versions independent of the particular number type. For each BLAS library there is only one class. By template specialization we get for each combination of BLAS and number type the appropriate implementation which can be chosen at runtime by letting them all derive from a common base class.  </li>
<li>
We plot the graphs for the runtimes and speedups from within the program using a gnuplot pipe. This frees us from the problem to figure out which columns have to be plotted versus each other and what to put into the legend. The necessary gnuplot commands are collected in a file so that we can polish the figures still a bit if the default values for e.g. the plot range do not give satisfactory results.  </li>
</ul>
<p>Before we study the program in detail let us still comment on why Fujimoto's implementation of a matrix-vector multiplication is still of interest.  </p>
<p>Back in 2008 the only memory in CUDA-enabled GPUs with integrated caching capabilities was the texture memory. However, it during the executino of a CUDA kernel it was limited to read-only caching and updates to the texture became visible only after a relaunch of a kernel. The shared memory basically worked like a cache but had to be managed manually. The Fermi architecture introduced a two-level cache hierarchy which buffered all accesses to the global memory so that there was no direct access from the multiprocessors to the global memory anymore. However, there was still only one central texture cache which buffered the texture fetches issued by the different multiprocessors. With the Kepler architecture each multiprocessor got its own texture cache which had the same size of 64KB as the central one in the former architectures. A nice feature of the texture cache, then and now, is that it is optimized for data accesses of 2D spatial locality. Thus reading a matrix not in an element-per-element manner but en block by subdividing it into tiles and reading each tile as a whole should profit from this special feature of the texture cache. <br/>
 This is the crucial idea of Fujimoto's method.  </p>
<p>Although the pay-off of this strategy should have decreased over the past due to the introduction of an "official" cache it is instructive to figure out whether it still is worth the effort today. </p>
<p><a class="anchor" id="Literature"></a></p>
<h2>Literature </h2>
<ul>
<li>
Fujimoto's article from 2008: Faster Matrix-Vector Multiplication on GeForce 8800GTX, In the Proceedings of the 22nd IEEE International Parallel and Distributed Processing Symposium (IPDPS), LSPP-402, pp.1-8, April 2008  </li>
<li>
CUBLAS Reference  </li>
<li>
Josuttis' book about C++ templates  </li>
<li>
(More) Effective C++ by Scott Meyers  </li>
</ul>
<p><a class="anchor" id="CommProg"></a> </p>
<h1>The commented program</h1>
<div class="fragment"><pre class="fragment">     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #include &lt;step-2/step-2.hh&gt;</span>
</pre></div><p><a class="anchor" id="Functionmain"></a> </p>
<h4>Function: main</h4>
<p>As usual, the main function is pretty boring.</p>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> *argv[])
 {
     step2::MyFancySimulation sim(argc, argv);
 
     sim.run();
 }
 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef STEP_2_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define STEP_2_HH</span>
<span class="preprocessor"> #include &lt;cstdio&gt;</span>
</pre></div><p>We walk through the program top-down starting with the file which contains the main() function.</p>
<p>We need several headers. First of all STL's vector class.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;vector&gt;</span>
</pre></div><p>To store the measured runtimes in a table we use deal.II's</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;deal.II/base/convergence_table.h&gt;</span>
</pre></div><p>The basis for all CUDA-related programs is provided by the CUDA runtime library.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;cuda_runtime.h&gt;</span>
</pre></div><p>Our SciPAL library provides a little helper class which offers a more comfortable interface to the technical data about the available GPUs.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;../SciPAL/include/base/GPUInfo.h&gt;</span>
</pre></div><p>Finally, one of the greatest aids in all the less-scientific issues in a program is QT's string class</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;QString&gt;</span>
</pre></div><p>Last but not least, we need the headers for the matrix-vector benchmark test</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;step-2/MVTest.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/MVTest.hh&gt;</span>
</pre></div><p>and for the user interface.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;step-2/MVTestUIParams.h&gt;</span>
</pre></div><p>We encapsulate the whole project into a dedicated namespace in order to be able to re-use parts of this program in others.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">namespace </span>step2 {
</pre></div><p><a class="anchor" id="ClassMyFancySimulation"></a> </p>
<h3>Class: MyFancySimulation</h3>
<p>To make this test facility extendible, we implement a class for a simple user interface. Its primary tasks are:</p>
<ul>
<li>Management of run-time parameters by a simple text-based parameter file.</li>
<li>Setting device parameters according to the user's parameters.</li>
<li>Preprocessing and output of results. The result of this program is a comparison of the performance of different implementations of the matrix-vector product for dense matrices and vectors. The runtimes are collected in a central table <code>results_table</code>. It is an instance of the dealii::ConvergenceTable class which has such nice member functions like <code>write_tex()</code> which writes the contents to a tex file such that it can be directly included in the tex source of an article. <br/>
 The non-public part of this class is declared only as protected and not as private in order to be able to reuse this class in other projects doing similar benchmark tests. This is also the reason why the two main functions of this class are declared as <em>virtual</em>.</li>
</ul>
<div class="fragment"><pre class="fragment"> <span class="keyword">class </span>MyFancySimulation {
 
 <span class="keyword">public</span>:
    MyFancySimulation(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> *argv[]);
 
    <span class="keyword">virtual</span> <span class="keywordtype">void</span> run();
 
 <span class="keyword">protected</span>:
     <span class="keyword">virtual</span> <span class="keywordtype">void</span> save_results();
 
 
     dealii::ConvergenceTable results_table;
 
     MVTestUIParams params;
 
     SciPAL::GPUInfo gpu_info;
 
     QString launch_dir;
 
     QString prm_dir;
 
     QString prm_log_dir;
 };
 
 }
</pre></div><p><a class="anchor" id="ConstructorMyFancySimulation"></a> </p>
<h4>Constructor: MyFancySimulation</h4>
<p>The constructor is responsible for reading parameters and initializing the device, i.e. the selected graphics card.</p>
<div class="fragment"><pre class="fragment"> step2::MyFancySimulation::MyFancySimulation(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> *argv[])
 {
</pre></div><p>Before setting up the simulation we figure out how many GPUs are available.</p>
<div class="fragment"><pre class="fragment">     cudaGetDeviceCount(&amp;gpu_info.n_CUDA_devices);
     std::cout
             &lt;&lt; <span class="stringliteral">&quot;N available CUDA devices : &quot;</span>
             &lt;&lt; gpu_info.n_CUDA_devices &lt;&lt; std::endl;
 
     gpu_info.get();
</pre></div><p>Then, we declare and read parameters from a file. Basically, the parameter file must have the same name as the binary. The extension has to be ".prm". What has been read will be dumped into a log file. We could use the parameter file to read a device ID and once the parameters are read we could reset the <code>gpu_info</code> object to the new device.</p>
<div class="fragment"><pre class="fragment">     dealii::ParameterHandler prm_handler;
 
     MVTestUIParams::declare(prm_handler);
</pre></div><p>Before reading the parameters we set up the directories needed during the execution of the program. As point of reference we use directory where the program has been started.</p>
<div class="fragment"><pre class="fragment">      QDir cwd = QDir::current();
      cwd.makeAbsolute();
</pre></div><p>This is also the current working directory.</p>
<div class="fragment"><pre class="fragment">    this-&gt;launch_dir = cwd.absolutePath();
</pre></div><p>By default, the parameter file has the same name as the binary and is supposed to be in a subdirectory prm of that directory where the program has been started.</p>
<div class="fragment"><pre class="fragment">     std::string prm_filename;
 
     <span class="keywordflow">if</span> (argc == 1)
     {
         QFileInfo tmp(argv[0]);
         this-&gt;prm_dir = tmp.absolutePath() + <span class="stringliteral">&quot;/prm&quot;</span>;
         prm_filename  = tmp.fileName().toStdString();
         prm_filename += <span class="stringliteral">&quot;.prm&quot;</span>;
     }
     <span class="keywordflow">else</span>
     {
</pre></div><p>Whatever gets passed as first command line argument is considered as path to a parameter file.</p>
<div class="fragment"><pre class="fragment">         std::cout &lt;&lt; <span class="stringliteral">&quot;Given parameter file : &quot;</span> &lt;&lt; argv[1] &lt;&lt; std::endl;
</pre></div><p>We convert the sequence of characters into something more meaningful.</p>
<div class="fragment"><pre class="fragment">         QFileInfo tmp(argv[1]);
</pre></div><p>Before we proceed, let us figure out whether the given parameter file exists. Note: If the file is a symlink that points to a non existing file, false is returned as well.</p>
<div class="fragment"><pre class="fragment">         <span class="keywordflow">if</span>(!tmp.exists())
         {
             std::cerr &lt;&lt; <span class="stringliteral">&quot;The following parameter file does not exist:\n&quot;</span>
                       &lt;&lt; argv[1] &lt;&lt; std::endl;
 
             qFatal(<span class="stringliteral">&quot;Cannot proceed without proper path to parameter file&quot;</span>);
         }
</pre></div><p>Next, we subdivide the given filename into its path and name so that the corresponding subdirectories can be created.</p>
<div class="fragment"><pre class="fragment">         this-&gt;prm_dir = tmp.absolutePath();
 
         prm_filename = tmp.fileName().toStdString();
 
         std::cout &lt;&lt; <span class="stringliteral">&quot;xx Parameter file path : &quot;</span>
                   &lt;&lt; tmp.absolutePath().toStdString().c_str()
                   &lt;&lt; std::endl;
     }
</pre></div><p>For control purposes it is useful to notify the user of which parameter file has been actually used.</p>
<div class="fragment"><pre class="fragment">     std::cout &lt;&lt; <span class="stringliteral">&quot;Parameter file : &quot;</span> &lt;&lt; prm_filename  &lt;&lt; std::endl;
</pre></div><p>Before the parameter file can be read, we have to make sure that its directory exists. In case of the default parameter file the directory will be created.</p>
<div class="fragment"><pre class="fragment">     cwd.mkpath(this-&gt;prm_dir);
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;step-2: prm path : &quot;</span> &lt;&lt; this-&gt;prm_dir.toStdString().c_str()  &lt;&lt; std::endl;
 
     QDir::setCurrent(this-&gt;prm_dir);
 
     prm_handler.read_input (prm_filename);
 
     this-&gt;params.get(prm_handler);
</pre></div><p>Having read the parameters we can create the toplevel run directory which was given in the parameter file.</p>
<div class="fragment"><pre class="fragment">     QDir::setCurrent(this-&gt;launch_dir);
     cwd.mkpath(this-&gt;params.run_dir);
     QDir::setCurrent(this-&gt;params.run_dir);
     cwd = QDir::current();
     this-&gt;params.run_dir = cwd.absolutePath();
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;Entering run dir : &quot;</span> &lt;&lt; this-&gt;params.run_dir.toStdString().c_str()  &lt;&lt; std::endl;
</pre></div><p>Create the log directory and write what has been actually read into a log file. Basically, this is just another parameter file and thus can be used again as input to another run after stripping the .log suffix.</p>
<div class="fragment"><pre class="fragment">     this-&gt;prm_log_dir = this-&gt;params.run_dir + <span class="stringliteral">&quot;/log&quot;</span>;
     cwd.mkpath(this-&gt;prm_log_dir);
 
 
 
     QDir::setCurrent(this-&gt;prm_log_dir);
 
     std::ofstream log_out_text( (prm_filename +<span class="stringliteral">&quot;.log&quot;</span> ).c_str() );
     prm_handler.print_parameters (log_out_text,
                                   dealii::ParameterHandler::Text);
</pre></div><p>At this point the toplevel run dir must exist. Thus, we can change to it without any further sanity test.</p>
<div class="fragment"><pre class="fragment">     assert(QDir::setCurrent(this-&gt;params.run_dir ) );
</pre></div><p>We know all the matrix sizes we are going to test and therefore initialize <code>results_table</code> with the number of rows and columns of the test matrices.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; this-&gt;params.matrix_sizes.size(); i++)
     {
         this-&gt;results_table.add_value(<span class="stringliteral">&quot;rows&quot;</span>,  (<span class="keywordtype">int</span>) this-&gt;params.matrix_sizes[i].first);
         this-&gt;results_table.add_value(<span class="stringliteral">&quot;columns&quot;</span>, (<span class="keywordtype">int</span>) this-&gt;params.matrix_sizes[i].second);
     }
 }
</pre></div><p><a class="anchor" id="Functionrun"></a> </p>
<h4>Function: run</h4>
<p>Running the performance test is done here.</p>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">void</span> step2::MyFancySimulation::run()
 {
</pre></div><p>The test runs are subdivided into groups for single and double precision. The list of matrix-vector product implementations which are to be executed are stored as vector. To keep the code short we introduce some references.</p>
<div class="fragment"><pre class="fragment">     <span class="keyword">const</span> std::vector&lt;MVCase&gt; &amp; float_tests  = this-&gt;params.float_tests;
     <span class="keyword">const</span> std::vector&lt;MVCase&gt; &amp; double_tests = this-&gt;params.double_tests;
</pre></div><p>For the comparisons of the runtimes we need the reverse, i.e. a mapping from the name of the implementation to its index in the list of tests.</p>
<div class="fragment"><pre class="fragment">     <span class="keyword">const</span> std::map&lt;MVCase, int&gt; &amp; float_vs  = this-&gt;params.float_vs;
     <span class="keyword">const</span> std::map&lt;MVCase, int&gt; &amp; double_vs = this-&gt;params.double_vs;
</pre></div><p>In the benchmark tests we measure the runtimes for different matrix sizes. The plot command for this raw data is assembled in</p>
<div class="fragment"><pre class="fragment">     QString gpplots_runtimes;
</pre></div><p>The interesting thing is which matrix-vector product is faster. To quantify this we will compute the speedup of the CUDA implementations over ATLAS. Basically, gnuplot can do this for us. The necessary plot commands are stored in a separate string.</p>
<div class="fragment"><pre class="fragment">     QString gpplots_speedup;
</pre></div><p>The string <code>gnuplot</code> will contain all commands we want to pass to gnuplot and merges the plot style settings with the plot commands. For a full documentation of gnuplot's capabilities have look at its <a href="http://www.gnuplot.info">online doc</a>.</p>
<div class="fragment"><pre class="fragment">     QString gnuplot
             =
</pre></div><p>We use the postscript terminal for publication-ready results.</p>
<div class="fragment"><pre class="fragment">             <span class="stringliteral">&quot;set term postscript landscape enhanced color solid &quot;</span>
             <span class="stringliteral">&quot; linewidth 2.0 \&quot;Helvetica\&quot; 20\n&quot;</span>
             <span class="stringliteral">&quot;set xlabel \&quot;matrix entries\&quot;\n&quot;</span>
             <span class="stringliteral">&quot;set ylabel \&quot;execution time\&quot;\n&quot;</span>
             <span class="stringliteral">&quot;set logscale xy\n&quot;</span>
             <span class="stringliteral">&quot;set grid\n&quot;</span>
             <span class="stringliteral">&quot;set output \&quot;runtimes.ps\&quot;\n&quot;</span>
             <span class="stringliteral">&quot;set key inside left Left box lw 0.5\n&quot;</span>;
 
     gnuplot += <span class="stringliteral">&quot;plot &quot;</span>;
</pre></div><p>Before we can complete the plot command we have to run the tests. Float comes first.</p>
<div class="fragment"><pre class="fragment">     std::vector&lt;MVCase&gt;::const_iterator
             t = float_tests.begin(),
             end_t = float_tests.end();
 
     <span class="keywordtype">int</span> col = 3;
 
     <span class="keywordflow">for</span> (; t != end_t; ++t)
     {
         MVTest&lt;float&gt; mv_test(this-&gt;params, results_table, *t);
         <span class="keywordflow">if</span>(col &gt; 3) gpplots_runtimes += <span class="stringliteral">&quot;,&quot;</span>;
</pre></div><p><code>gpplots_runtimes</code> contains all plot commands for the pure runtimes. The relative path to the data file reflects the fact that we will call gnuplot from a subdirectory of the run directory.</p>
<div class="fragment"><pre class="fragment">         gpplots_runtimes += QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):&quot;</span>)
</pre></div><p>Each run of <code>mv_test</code> appends an additional column with results to <em>MVTest_results.out</em>. By stepping through the columns we can plot the respective runtime</p>
<div class="fragment"><pre class="fragment">                 + QString::number(col++)
                 + QString(<span class="stringliteral">&quot; title \&quot;&quot;</span>) + mv_test.run() + QString(<span class="stringliteral">&quot;\&quot; w p&quot;</span>);
     }
</pre></div><p>Then come the double tests.</p>
<div class="fragment"><pre class="fragment">     t = double_tests.begin(), end_t = double_tests.end();
 
     <span class="keywordflow">for</span> (; t != end_t; ++t)
     {
         MVTest&lt;double&gt; mv_test(this-&gt;params, results_table, *t);
         <span class="keywordflow">if</span>(col &gt; 3) gpplots_runtimes += <span class="stringliteral">&quot;,&quot;</span>;
</pre></div><p>After the tests have finished we can compose the plotting command for the double results</p>
<div class="fragment"><pre class="fragment">         gpplots_runtimes += QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):&quot;</span>)
                 +
                 QString::number(col++)
                 +
                 QString(<span class="stringliteral">&quot; title \&quot;&quot;</span>) + mv_test.run() + QString(<span class="stringliteral">&quot;\&quot; w p&quot;</span>);
     }
</pre></div><p>Add the runtime plot commands to the global command string.</p>
<div class="fragment"><pre class="fragment">     gnuplot += gpplots_runtimes;
</pre></div><p>Then, set up titles for the speedup graphs.</p>
<div class="fragment"><pre class="fragment">     gnuplot +=
             <span class="stringliteral">&quot;\nset ylabel \&quot;speedup\&quot;\n&quot;</span>
             <span class="stringliteral">&quot;set output \&quot;speedup.ps\&quot;\n&quot;</span>
             <span class="stringliteral">&quot;set key inside left Left\n&quot;</span>;
</pre></div><p>For the speedups a linear scaling of the y-axis is more suitable</p>
<div class="fragment"><pre class="fragment">     gnuplot += <span class="stringliteral">&quot;unset logscale y\n&quot;</span>;
</pre></div><p>The order of the execution of the tests determines the order in which the runtimes appear in <code>results_table</code>. To compose the command string for plotting the speedups we use our lookup tables <code>float_vs</code> and <code>double_vs</code> to find out which columns we have to use for the calculation of the speedup. The column index is associated with the kind of test (like <code>atlas_mv</code>). Using the test as key the map returns the respective column to which we still have to add a 3 since the map starts with index 0 but the first 2 columns in our outputfile are reserved for the rows and columns of the matrix.</p>
<div class="fragment"><pre class="fragment">     gnuplot += <span class="stringliteral">&quot;plot&quot;</span>;
 
     <span class="keywordtype">int</span> offset = 3 + this-&gt;params.float_vs.size();
 
     <span class="keywordflow">if</span>(this-&gt;params.run_cpublas_vs_cublas_float)
         gpplots_speedup += ((gpplots_speedup.isEmpty()) ? QString(<span class="stringliteral">&quot;&quot;</span>) : QString(<span class="stringliteral">&quot;, &quot;</span>))
                 + QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):(%1 / %2)&quot;</span>)
                 .arg(float_vs.at(atlas_mv) + 3).arg(float_vs.at(cublas_mv) + 3)
                 + QString(<span class="stringliteral">&quot; title \&quot;CPU BLAS vs CUBLAS (float)\&quot; w p&quot;</span>);
 
     <span class="keywordflow">if</span>(this-&gt;params.run_cpublas_vs_cublas_double)
         gpplots_speedup += ((gpplots_speedup.isEmpty()) ? QString(<span class="stringliteral">&quot;&quot;</span>) : QString(<span class="stringliteral">&quot;, &quot;</span>))
                 + QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):(%1 / %2)&quot;</span>)
                 .arg(double_vs.at(atlas_mv) + offset).arg(double_vs.at(cublas_mv) + offset)
                 + QString(<span class="stringliteral">&quot; title \&quot;CPU BLAS vs CUBLAS (double)\&quot; w p&quot;</span>);
 
     <span class="keywordflow">if</span>(this-&gt;params.run_cpublas_vs_Fujimoto_float)
         gpplots_speedup += ((gpplots_speedup.isEmpty()) ? QString(<span class="stringliteral">&quot;&quot;</span>) : QString(<span class="stringliteral">&quot;, &quot;</span>))
                 + QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):(%1 / %2)&quot;</span>)
                 .arg(float_vs.at(atlas_mv) + 3).arg(float_vs.at(Fujimoto_mv) + 3)
                 + QString(<span class="stringliteral">&quot; title \&quot;CPU BLAS vs Fujimoto (float)\&quot; w p&quot;</span>);
 
     <span class="keywordflow">if</span>(this-&gt;params.run_cpublas_vs_Fujimoto_double)
         gpplots_speedup += ((gpplots_speedup.isEmpty()) ? QString(<span class="stringliteral">&quot;&quot;</span>) : QString(<span class="stringliteral">&quot;, &quot;</span>))
                 + QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):(%1 / %2)&quot;</span>)
                 .arg(double_vs.at(atlas_mv) + offset).arg(double_vs.at(Fujimoto_mv) + offset)
                 + QString(<span class="stringliteral">&quot; title \&quot;CPU BLAS vs Fujimoto (double)\&quot; w p&quot;</span>);
 
     <span class="keywordflow">if</span>(this-&gt;params.run_Fujimoto_vs_cublas_float)
         gpplots_speedup += ((gpplots_speedup.isEmpty()) ? QString(<span class="stringliteral">&quot;&quot;</span>) : QString(<span class="stringliteral">&quot;, &quot;</span>))
                 + QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):(%1 / %2)&quot;</span>)
                 .arg(float_vs.at(Fujimoto_mv) + 3).arg(float_vs.at(cublas_mv) + 3)
                 + QString(<span class="stringliteral">&quot; title \&quot;Fujimoto vs CUBLAS (float)\&quot; w p&quot;</span>);
 
     <span class="keywordflow">if</span>(this-&gt;params.run_Fujimoto_vs_cublas_double)
         gpplots_speedup += ((gpplots_speedup.isEmpty()) ? QString(<span class="stringliteral">&quot;&quot;</span>) : QString(<span class="stringliteral">&quot;, &quot;</span>))
                 + QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):(%1 / %2)&quot;</span>)
                 .arg(double_vs.at(Fujimoto_mv) + offset).arg(double_vs.at(cublas_mv) + offset)
                 + QString(<span class="stringliteral">&quot; title \&quot;Fujimoto vs CUBLAS (double)\&quot; w p&quot;</span>);
</pre></div><p>When the plotting commands for the speedup are complete we can add them to the global command string.</p>
<div class="fragment"><pre class="fragment">     gnuplot += gpplots_speedup;
</pre></div><p>Besides plotting data gnuplot can also be employed as interface to the console. We use this to convert the images from postscript to pdf and to remove old ps-files.</p>
<div class="fragment"><pre class="fragment">     gnuplot += <span class="stringliteral">&quot;\n!ps2pdf runtimes.ps runtimes.pdf&quot;</span>;
     gnuplot += <span class="stringliteral">&quot;\n!rm runtimes.ps&quot;</span>;
     gnuplot += <span class="stringliteral">&quot;\n!ps2pdf speedup.ps speedup.pdf&quot;</span>;
     gnuplot += <span class="stringliteral">&quot;\n!rm speedup.ps&quot;</span>;
 
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;Results are processed and saved.\n&quot;</span>;
</pre></div><p>Finally, save the runtimes to disc.</p>
<div class="fragment"><pre class="fragment">     this-&gt;save_results();
</pre></div><p>Then, we create the subdirectory for the plots from which gnuplot is going to be called.</p>
<div class="fragment"><pre class="fragment">      QDir cwd = QDir::current();
      QString plot_dir = this-&gt;params.run_dir + <span class="stringliteral">&quot;/plot&quot;</span>;
              cwd.mkpath(<span class="stringliteral">&quot;./plot&quot;</span>);
 
      QDir::setCurrent(plot_dir);
</pre></div><p>We write the plotting commands from the string <code>gnuplot</code> to a file <em>plot.gp</em>,</p>
<div class="fragment"><pre class="fragment">     QFile plotscript(<span class="stringliteral">&quot;plot.gp&quot;</span>);
 
     <span class="keywordtype">bool</span> success = plotscript.open(QIODevice::WriteOnly);
     <span class="keywordflow">if</span> (!success)
         std::cerr &lt;&lt; <span class="stringliteral">&quot;Opening gnuplot file failed!&quot;</span> &lt;&lt; std::endl;
 
     plotscript.write(gnuplot.toStdString().c_str());
 
     plotscript.close();
 
     <span class="keywordflow">if</span> (! plotscript.exists() )
         std::cerr &lt;&lt; <span class="stringliteral">&quot;Writing gnuplot file failed!&quot;</span> &lt;&lt; std::endl;
</pre></div><p>open a pipe to gnuplot and load the plot file we have just created.</p>
<div class="fragment"><pre class="fragment">     FILE *gp = popen(<span class="stringliteral">&quot;gnuplot -persist&quot;</span>, <span class="stringliteral">&quot;w&quot;</span>);
     fprintf(gp, <span class="stringliteral">&quot;load \&quot;plot.gp\&quot;\n&quot;</span>);
     fflush(gp);
</pre></div><p>After closing the pipe to gnuplot everything should have been plotted.</p>
<div class="fragment"><pre class="fragment">     pclose(gp);
 
 
     QDir::setCurrent(this-&gt;params.run_dir);
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;Finished.&quot;</span> &lt;&lt; std::endl;
 }
</pre></div><p><a class="anchor" id="Functionsave_results"></a> </p>
<h4>Function: save_results</h4>
<p>The final step in the benchmarking is to save the content of <code>results_table</code> to a text file. It should end up in the run directory given in the parameter file. The header of the results file contains the information about the sampling of the matrix sizes which allows to recreate the input data at a later time solely from the results file.</p>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">void</span> step2::MyFancySimulation::save_results()
 {
     std::string filename(<span class="stringliteral">&quot;MVTest_results&quot;</span>);
 
     filename += <span class="stringliteral">&quot;.out&quot;</span>;
 
     std::ofstream out(filename.c_str());
 
     out &lt;&lt; <span class="stringliteral">&quot;# max n_cols  : &quot;</span> &lt;&lt; this-&gt;params.max_n_cols &lt;&lt; std::endl
         &lt;&lt; <span class="stringliteral">&quot;# min n_cols  : &quot;</span> &lt;&lt; this-&gt;params.min_n_cols &lt;&lt; std::endl
         &lt;&lt; <span class="stringliteral">&quot;# growth rate : &quot;</span> &lt;&lt; this-&gt;params.n_rows_growth_rate &lt;&lt; std::endl
         &lt;&lt; std::endl;
 
     results_table.write_text(out);
 }
 
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef SimUIParams_H</span>
<span class="preprocessor"> #define SimUIParams_H</span>
</pre></div><p>Before we discuss the implementation of the benchmarking we briefly go through the parameters of the program which can be set at runtime.</p>
<p>The runtime parameters are grouped into several simple structures. Their main purpose is to encapsulate the declare() and get() functions needed to load the parameters by means of the deal.II ParameterHandler class. These functions are all very similar to each other so that we do not present all of their definitions in this documentation. To understand the program it suffices to know which parameters have been declared. Hence, we merely include the definitions of the parameter structures.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;QString&gt;</span>
<span class="preprocessor"> #include &lt;deal.II/base/parameter_handler.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p><a class="anchor" id="EnumMVCase"></a> </p>
<h3>Enum: MVCase</h3>
<p>These enumerated values will be used as tags for the different implementations of the matrix-vector product.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">enum</span> MVCase { Fujimoto_mv, atlas_mv, cublas_mv, none / * <span class="keywordflow">for</span> future use : , openmp_mv, ...* / };
</pre></div><p><a class="anchor" id="structSimUIParams"></a> </p>
<h3>struct: SimUIParams</h3>
<p>This structure contains all parameters which are needed for each test. These are essentially some flags which indicate whether the MV-test has to be executed for a certain combination of numerical precision and BLAS-implementation.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">struct </span>SimUIParams {
 
     SimUIParams() {}
 
     <span class="keyword">static</span> <span class="keywordtype">void</span> declare(dealii::ParameterHandler &amp; prm);
 
     <span class="keywordtype">void</span> <span class="keyword">get</span>(dealii::ParameterHandler &amp; prm);
</pre></div><p>The attributes consist of a long list of flags indicating which combinations of tests are to be run ...</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">bool</span>
     run_cpublas_vs_cublas_float,
     run_cpublas_vs_cublas_double,
     run_cpublas_vs_Fujimoto_float,
     run_cpublas_vs_Fujimoto_double,
     run_Fujimoto_vs_cublas_float,
     run_Fujimoto_vs_cublas_double;
 
     <span class="keywordtype">int</span> fj_version;
</pre></div><p>and a variable for holding the run directory.</p>
<div class="fragment"><pre class="fragment">     QString run_dir;
</pre></div><p>The test runs are subdivided into groups for single and double precision. The list of matrix-vector product implementations which are to be executed are stored as vector.</p>
<div class="fragment"><pre class="fragment">     std::vector&lt;MVCase&gt; float_tests, double_tests;
</pre></div><p>For the comparisons of the runtimes we need the reverse, i.e. a mapping from the name of the implementation to its index in the list of tests.</p>
<div class="fragment"><pre class="fragment">     std::map&lt;MVCase, int&gt; float_vs, double_vs;
 
 <span class="keyword">private</span>:
     SimUIParams (<span class="keyword">const</span> SimUIParams &amp; / *other* /) {}
 
     SimUIParams &amp; operator = (<span class="keyword">const</span> SimUIParams &amp; / *other* /) { <span class="keywordflow">return</span> *<span class="keyword">this</span>; }
 };
 
 }
<span class="preprocessor"> #endif // SimUIParams_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef MVTESTUIPARAMS_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define MVTESTUIPARAMS_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;step-2/SimUIParams.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/DeviceParams.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/MVMultDriverInterface.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p><a class="anchor" id="ClassTestUIParamsBase"></a> </p>
<h3>Class: TestUIParamsBase</h3>
<p>All factorization methods have to know the dimensions of the input matrix and the destination where the results should be stored. Therefore these details are collected in a separate class which allows us to re-use them in other projects.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">struct </span>TestUIParamsBase {
 
     TestUIParamsBase() {}
 
     <span class="keyword">static</span> <span class="keywordtype">void</span> declare(dealii::ParameterHandler &amp; prm);
 
     <span class="keywordtype">void</span> <span class="keyword">get</span>(dealii::ParameterHandler &amp; prm);
</pre></div><p>problem size. A minimal and maximal column number is given.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span>  min_n_cols;
     <span class="keywordtype">int</span>  max_n_cols;
</pre></div><p>growth-rate of rows until column number is reached.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">double</span> n_rows_growth_rate;
</pre></div><p>For time measurements it is convenient to repeat the test several times and average over the results.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> n_repetitions;
 
 
 <span class="keyword">private</span>:
</pre></div><p>Dummy implementation to avoid the automatic creation by the compiler. Whenever an object should be copied this results in an error at compile-time.</p>
<div class="fragment"><pre class="fragment">     TestUIParamsBase(<span class="keyword">const</span> TestUIParamsBase &amp; ) {}
 
     TestUIParamsBase &amp; operator = (<span class="keyword">const</span> TestUIParamsBase &amp; / *other* /)
     {
         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
     }
 };
</pre></div><p><a class="anchor" id="ClassMVTestUIParams"></a> </p>
<h3>Class: MVTestUIParams</h3>
<p>All run-time parameters are assembled in this structure so that they can be passed around as a whole. We compose the different subsections by public inheritance.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">struct </span>MVTestUIParams
         :
         <span class="keyword">public</span> SimUIParams,
         <span class="keyword">public</span> DeviceParams,
         <span class="keyword">public</span> TestUIParamsBase
 {
     MVTestUIParams()
         :
           SimUIParams(),
           DeviceParams(),
           TestUIParamsBase()
     {}
 
     <span class="keyword">static</span> <span class="keywordtype">void</span> declare(dealii::ParameterHandler &amp; prm);
 
     <span class="keywordtype">void</span> <span class="keyword">get</span>(dealii::ParameterHandler &amp; prm);
 
 
     <span class="keywordtype">int</span> n_random_trials;
 
     std::vector&lt;step2::matrixSize&gt; matrix_sizes;
 
 <span class="keyword">protected</span>:
     <span class="keywordtype">void</span> create_random_matrix_sizes();
     <span class="keywordtype">void</span> create_regular_matrix_sizes();
 
 <span class="keyword">private</span>:
     MVTestUIParams (<span class="keyword">const</span> MVTestUIParams &amp; / *other* /)
         :
           SimUIParams(),
           DeviceParams(),
           TestUIParamsBase()
     {}
 
     MVTestUIParams &amp; operator = (<span class="keyword">const</span> MVTestUIParams &amp; / *other* /)
     {
         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
     }
 };
 
 }
<span class="preprocessor"> #endif // MVTESTUIPARAMS_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef MVTEST_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define MVTEST_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;QDir&gt;</span>
<span class="preprocessor"> #include &lt;step-2/Fujimoto_driver_step-2.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/cuda_driver_step-2.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/CpuBlas_driver_step-2.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/MVTestUIParams.h&gt;</span>
 
<span class="preprocessor"> #include &lt;deal.II/base/convergence_table.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p><a class="anchor" id="ClassMVTest"></a> </p>
<h3>Class: MVTest</h3>
<p>This class drives the tests of the different tuning parameters for Fujimoto's matrix-vector product or the test of the CUBLAS or ATLAS (CPU) matrix-vector product. The sole template parameter of this class is the number type, i.e. real float and double (or the complex counterparts in a future version).</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">class </span>MVTest {
 
 <span class="keyword">public</span>:
     typedef ::FullMatrixAccessor&lt;T&gt; FullMatrixAccessor;
 
     MVTest(<span class="keyword">const</span> MVTestUIParams &amp; p,
            dealii::ConvergenceTable &amp; results_table,
            MVCase variant=atlas_mv);
 
     ~MVTest();
 
     <span class="keyword">virtual</span> QString run();
 
 
 <span class="keyword">protected</span>:
     <span class="keyword">typename</span> step2::MVMultDriverInterface&lt;T&gt; * driver_m;
 
     <span class="keyword">virtual</span> <span class="keywordtype">void</span> setup_and_assemble(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> nr,
                                     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> nc);
 
     <span class="keyword">const</span> MVTestUIParams * params;
 
     FullMatrixAccessor A;
 
     dealii::Vector&lt;T&gt; x_orig, y_orig;
 
     std::string col_head;
 
     dealii::ConvergenceTable &amp; results_table;
 };
 }
<span class="preprocessor"> #endif // MVTEST_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef MVTEST_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define MVTEST_HH</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;step-2/MVTest.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/PrecisionName.h&gt;</span>
<span class="preprocessor"> #include &lt;deal.II/base/convergence_table.h&gt;</span>
</pre></div><p><a class="anchor" id="Constructor"></a> </p>
<h4>Constructor</h4>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">p</td><td>: Reference to the full set of runtime parameters. </td></tr>
    <tr><td class="paramname">rt</td><td>: Reference to the runtimes table. </td></tr>
    <tr><td class="paramname">mv_variant</td><td>: Selects the implementation of the matrix-vector product.</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;
 step2::MVTest&lt;T&gt;::MVTest(<span class="keyword">const</span> step2::MVTestUIParams &amp; p,
                          dealii::ConvergenceTable &amp;rt,
                          MVCase mv_variant)
     :
       params(&amp;p),
       results_table(rt)
 {
     driver_m = NULL;
</pre></div><p>Depending on the variant we instantiate the driver and choose a suitable header for the column in the results table.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">switch</span> (mv_variant) {
 
     <span class="keywordflow">case</span> Fujimoto_mv:
         driver_m = <span class="keyword">new</span> FujimotoDriver&lt;T,cublas&gt; (this-&gt;params-&gt;fj_version);
         col_head = <span class="stringliteral">&quot;Fujimoto &quot;</span> + QString::number(this-&gt;params-&gt;fj_version).toStdString();
         <span class="keywordflow">break</span>;
     <span class="keywordflow">case</span> cublas_mv:
         driver_m = <span class="keyword">new</span> CUBlasDriver&lt;T,cublas&gt; ();
         col_head  = <span class="stringliteral">&quot;CUBLAS&quot;</span>;
         <span class="keywordflow">break</span>;
     <span class="keywordflow">case</span> atlas_mv:
         driver_m = <span class="keyword">new</span> step2::CpuBlasDriver&lt;T,blas&gt; ();
         col_head  = <span class="stringliteral">&quot;CPU Blas&quot;</span>;
         <span class="keywordflow">break</span>;
     <span class="keywordflow">default</span>: <span class="comment">// do nothing</span>
         <span class="keywordflow">break</span>;
     }
 
     <span class="keywordflow">if</span> (mv_variant != none)
     {
         assert(driver_m);
</pre></div><p>After checking that we have successfully allocated the driver object we append a string to the column header indicating the precision and number type used in this test.</p>
<div class="fragment"><pre class="fragment">         col_head += <span class="stringliteral">&quot; &quot;</span> + PrecisionName&lt;T&gt;::name();
</pre></div><p>Although it is not an error we use</p>
<div class="fragment"><pre class="fragment">         std::cerr &lt;&lt; <span class="stringliteral">&quot;\nTesting &quot;</span> &lt;&lt; col_head.c_str() &lt;&lt; <span class="stringliteral">&quot; mvmult &quot;</span>
                   &lt;&lt; std::endl;
</pre></div><p>so that QTCreator highlights this message in red.</p>
<div class="fragment"><pre class="fragment">     }
 }
</pre></div><p><a class="anchor" id="Destructor"></a> </p>
<h4>Destructor</h4>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;
 step2::MVTest&lt;T&gt;::~MVTest()
 {
     <span class="keywordflow">if</span> (driver_m)
         <span class="keyword">delete</span> driver_m;
 }
</pre></div><p><a class="anchor" id="Functionrun"></a> </p>
<h4>Function: run</h4>
<p>This function manages the loop over the matrix sizes. The loops over the repetitions are delegated to the different driver classes.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;
 QString
 step2::MVTest&lt;T&gt;::run()
 {
     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i=0; i&lt; this-&gt;params-&gt;matrix_sizes.size(); i++)
     {
         <span class="keywordtype">size_t</span> nr = this-&gt;params-&gt;matrix_sizes[i].first ;
         <span class="keywordtype">size_t</span> nc = this-&gt;params-&gt;matrix_sizes[i].second;
 
<span class="preprocessor"> #ifdef DEBUG</span>
<span class="preprocessor"></span>         std::cout  &lt;&lt; <span class="stringliteral">&quot;Testing MV for &quot;</span> &lt;&lt; nr &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; nc &lt;&lt; <span class="stringliteral">&quot; matrix&quot;</span> &lt;&lt; std::endl;
<span class="preprocessor"> #endif</span>
</pre></div><p>For unit testing purposes we reallocate the complete matrix-vector multiplication test for each matrix size to test.</p>
<div class="fragment"><pre class="fragment">         setup_and_assemble(nr, nc);
</pre></div><p>We copy the reference right-hand side into a local vector and allocate a temporary destination vector.</p>
<div class="fragment"><pre class="fragment">         std::vector&lt;T&gt; x(this-&gt;x_orig.begin(), this-&gt;x_orig.end());
</pre></div><p>The reinitialization of <code>y</code> is done such that we can use it as matrix in step-3 which tests different matrix-matrix multiplications.</p>
<div class="fragment"><pre class="fragment">         <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> n_elements =  this-&gt;y_orig.size();
         std::vector&lt;T&gt; y(n_elements, 0.);
 
         <span class="keywordtype">double</span> elapsed_time
                 =
                 driver_m-&gt;mvmult(y, A, x,
                                  this-&gt;params-&gt;n_repetitions) / this-&gt;params-&gt;n_repetitions;
</pre></div><p>After the test we check whether <code>y</code> <code>==</code> <code>y_orig</code>. As error measure we use the max-norm of the difference divided by the reference solution. This yields an error roughly independent of the matrix size.</p>
<div class="fragment"><pre class="fragment">         dealii::Vector&lt;T&gt; diff ( n_elements );
         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; n_elements; i++)
             diff(i) = (y[i] - y_orig(i)) / y_orig(i);
 
         <span class="keywordtype">double</span> linfty_error = diff.linfty_norm();
</pre></div><p>If the error appears to be too large, we print a warning message. For sufficiently small vectors we dump them onto the screen.</p>
<div class="fragment"><pre class="fragment">         <span class="keywordflow">if</span> (linfty_error&gt; (<span class="keyword">sizeof</span>(T)&lt;8 ? 1e-5 : 1e-14))
         {
             std::cerr &lt;&lt; nr &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; nc &lt;&lt; <span class="stringliteral">&quot; matrix : &quot;</span>
                       &lt;&lt; <span class="stringliteral">&quot;|| (y - y_orig)/y_orig||_infty = &quot;</span> &lt;&lt; linfty_error
                       &lt;&lt; <span class="stringliteral">&quot; MVTest probably failed!&quot;</span>
                       &lt;&lt; std::endl;
</pre></div><p>The maximum length of a vector which can still be reasonably displayed in a terminal is something like 20. Since this is mostly needed when debugging this magic number should not harm anything.</p>
<div class="fragment"><pre class="fragment">             <span class="keywordflow">if</span> (y.size() &lt; 20) {
                 std::cerr &lt;&lt; y_orig &lt;&lt; std::endl;
</pre></div><p>We do not need the <code>diff</code> vector anymore, so we use it for storing the result of the matrix-vector product such that it can be put into the out stream.</p>
<div class="fragment"><pre class="fragment">                 std::copy(y.begin(), y.end(), diff.begin());
                 std::cerr &lt;&lt; diff &lt;&lt; std::endl;
             }
         }
</pre></div><p>Finally, add the measured runtimes to the table collecting the results and set the precision of the column's contents.</p>
<div class="fragment"><pre class="fragment">         this-&gt;results_table.add_value(col_head.c_str(), elapsed_time);
 
         this-&gt;results_table.set_precision(col_head.c_str(), 12);
     }
</pre></div><p>We return the header of the results column which simplifies the further processing of the results.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">return</span> col_head.c_str();
 }
</pre></div><p><a class="anchor" id="Functionsetup_and_assemble"></a> </p>
<h4>Function: setup_and_assemble</h4>
<p>The second purpose of the MVTest class is the creation of reasonable test data. This is done in this function. This is the place where one could use the deal.II examples as blackbox matrix generators. For the time being we define the entries of the matrix <img class="formulaInl" alt="$A \in \mathbb{R}^{m \times n}$" src="form_36.png"/>, the source vector <img class="formulaInl" alt="$x\in \mathbb{R}^{n}$" src="form_37.png"/> and destination <img class="formulaInl" alt="$y\in \mathbb{R}^{m}$" src="form_38.png"/> as </p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{eqnarray} A_{ik} &amp; = &amp; i + k\,, \\ x_k &amp; = &amp; \frac{1}{k}\,, \\ y_i&amp; = &amp; \sum_{k=1}^n A_{ik} x_k = n + i\sum_{k=1}^n\frac{1}{k} \quad i \in \lbrace 1, \ldots , m\rbrace\,. \end{eqnarray}" src="form_39.png"/>
</p>
<p> Having different assembly routines is another possible extension of this program.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span>
 step2::MVTest&lt;T&gt;::setup_and_assemble(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> nr, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> nc)
 {
</pre></div><p>First we have to setup our linear system, i.e. to allocate enough memory.</p>
<div class="fragment"><pre class="fragment">     this-&gt;A.reinit(nr, nc);
     this-&gt;x_orig.reinit(nc);
     this-&gt;y_orig.reinit(nr);
</pre></div><p>Then we assemble. It would be nice to have that in parallel as well.</p>
<div class="fragment"><pre class="fragment">     y_orig = 0.;
     <span class="keywordtype">int</span> tmp = 1;
     <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> r = 0; r &lt; nr; ++r)
         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> c = 0; c &lt; nc; ++c)
         {
             x_orig(c)  = (c+1);
             A(r,c)     = tmp; tmp++;<span class="comment">//r+1 + 1./(c+1);</span>
             y_orig(r) +=  A(r,c)*x_orig(c);
         }
 }
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef MVMultDriverInterface_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define MVMultDriverInterface_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;vector&gt;</span>
<span class="preprocessor"> #include &lt;numeric&gt;</span>
<span class="preprocessor"> #include &lt;lac/blas++.h&gt;</span>
</pre></div><p>To avoid boring code we declare the member functions of the classes defined in this file inline.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">namespace </span>step2 {
 
 <span class="keyword">typedef</span>    std::pair&lt;size_t, size_t&gt; matrixSize;
</pre></div><p><a class="anchor" id="ClassMVMultDriverInterface"></a> </p>
<h3>Class: MVMultDriverInterface</h3>
<p>This is the common base class for all matrix-vector multiplications tested in this program. We define the type of dense matrix which is to be used on the host side in this class. As this is a template class w.r.t the data type of the matrix entries the MVMultDriverInterface class has to be a template class as well.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 <span class="keyword">class </span>MVMultDriverInterface {
 
 <span class="keyword">public</span>:
 
     typedef ::FullMatrixAccessor&lt;Number&gt; FullMatrixAccessor;
 
     MVMultDriverInterface()        {}
 
     <span class="keyword">virtual</span> ~MVMultDriverInterface () {}
</pre></div><p><a class="anchor" id="Functionmvmult"></a> </p>
<h4>Function: mvmult</h4>
<p>This function has to implement the profiling of a matrix-vector product in a derived class. There is no reasonable default implementation thus we make this an abstract virtual function. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">y</td><td>: The vector for the result of <img class="formulaInl" alt="$Ax$" src="form_40.png"/>. </td></tr>
    <tr><td class="paramname">A</td><td>: The matrix to multiply with <code><img class="formulaInl" alt="$x$" src="form_22.png"/></code>. </td></tr>
    <tr><td class="paramname">x</td><td>: The source vector. </td></tr>
    <tr><td class="paramname">n_repetitions</td><td>: How many times the matrix-vector product is to be run. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd>: cumulative runtime.</dd></dl>
<div class="fragment"><pre class="fragment">     <span class="keyword">virtual</span> <span class="keywordtype">double</span> mvmult(std::vector&lt;Number&gt; &amp; y,
                           <span class="keyword">const</span> FullMatrixAccessor &amp; A,
                           <span class="keyword">const</span> std::vector&lt;Number&gt; &amp; x,
                           <span class="keywordtype">int</span> n_repetitions) = 0;
 };
 
 } <span class="comment">// namespace step2 END</span>
<span class="preprocessor"> #endif // MVMultDriverInterface_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CPUBLAS_DRIVER_STEP2_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define CPUBLAS_DRIVER_STEP2_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;vector&gt;</span>
<span class="preprocessor"> #include &lt;lac/blas++.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/MVMultDriverInterface.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p><a class="anchor" id="ClassCpuBlasDriver"></a> </p>
<h3>Class: CpuBlasDriver</h3>
<p>The first of our driver classes implements the CPU-based matrix-vector multiplication.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> EntryType, <span class="keyword">typename</span> blasType&gt;
 <span class="keyword">class </span>CpuBlasDriver : <span class="keyword">public</span> MVMultDriverInterface&lt;EntryType&gt;
 {
 <span class="keyword">public</span>:
 
     <span class="keyword">typedef</span>
     <span class="keyword">typename</span> MVMultDriverInterface&lt; EntryType&gt;::FullMatrixAccessor
     FullMatrixAccessor;
 
     CpuBlasDriver() {}
 
     <span class="keyword">virtual</span> ~CpuBlasDriver () {}
</pre></div><p>The only function of interest of this class is the one which profiles the matrix-vector multiplication.</p>
<div class="fragment"><pre class="fragment">     <span class="keyword">virtual</span> <span class="keywordtype">double</span> mvmult(std::vector&lt;EntryType&gt;&amp; y,
                           <span class="keyword">const</span> FullMatrixAccessor&amp; A,
                           <span class="keyword">const</span> std::vector&lt;EntryType&gt;&amp; x,
                           <span class="keywordtype">int</span> n_repetitions);
 };
 
 } <span class="comment">// namespace step2 END</span>
</pre></div><p>In standard C++ it is a good habit to separate function declarations from their definitions. For template classes this does not work. Therefore, we put the definitions of the member functions into a separate header file to keep at least the improved overview provided by this separation.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;step-2/CpuBlas_driver_step-2.hh&gt;</span>
<span class="preprocessor"> #endif // CPUBLAS_DRIVER_STEP2_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CPUBLAS_DRIVER_STEP_2_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define CPUBLAS_DRIVER_STEP_2_HH</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;base/CUDATimer.h&gt;</span>
</pre></div><p><a class="anchor" id="Functionmvmult"></a> </p>
<h4>Function: mvmult</h4>
<p>We overload the mvmult() function from the base class to delegate the execution of the matrix-vector product to the ATLAS library.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> EntryType,<span class="keyword">typename</span> blasType&gt;
 <span class="keywordtype">double</span> step2::CpuBlasDriver&lt;EntryType,blasType&gt;::mvmult(std::vector&lt;EntryType&gt;&amp; y,
                                                         <span class="keyword">const</span> FullMatrixAccessor&amp; A,
                                                         <span class="keyword">const</span> std::vector&lt;EntryType&gt;&amp; x,
                                                         <span class="keywordtype">int</span> n_repetitions)
 {
</pre></div><p>We introduce some convenience variables.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> n_rows = A.n_rows();
     <span class="keywordtype">int</span> n_cols = A.n_cols();
</pre></div><p>For better readability we create local variables for the arguments of the BLAS function.</p>
<div class="fragment"><pre class="fragment">     EntryType * d_y = &amp;y[0];
 
     EntryType * d_A = <span class="keyword">const_cast&lt;</span>FullMatrixAccessor &amp;<span class="keyword">&gt;</span>(A).val();
 
     EntryType * d_x = &amp;<span class="keyword">const_cast&lt;</span>std::vector&lt;EntryType&gt; &amp;<span class="keyword">&gt;</span>(x)[0];
 
     EntryType alpha = 1;
     EntryType beta  = 1;
 
     <span class="keywordtype">int</span> incx = 1; <span class="keywordtype">int</span> incy = 1;
</pre></div><p>Internally, BLAS assumes a column-major storage of the matrix. Therefore, the leading dimension is the number of columns.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> lda = n_cols;
</pre></div><p>However, we use a row-major ordering and thus have to invoke BLAS' gemv() function such that it performs the transposed matrix-vector product. To do this, we have to swap the roles of the number of rows and columns and pass a 't' as first argument to gemv().</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> m = n_cols;
     <span class="keywordtype">int</span> n = n_rows;
</pre></div><p>We execute the matrix-vector product several times for a given matrix size to get a reliable estimate of the runtime.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">double</span> cumulative_runtime = 0.;
     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;n_repetitions; i++)
     {
</pre></div><p>BLAS does not take care of properly initializing the result vector to zero. Hence, we have to do it ourselves.</p>
<div class="fragment"><pre class="fragment">         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k = 0; k &lt; n_rows; k++)
             d_y[k] = 0.;
 
         CUDATimer timer;
 
         blasType::gemv (<span class="charliteral">&#39;t&#39;</span>, m, n, alpha,
                         d_A, lda,
                         d_x, incx,
                         beta,
                         d_y, incy);
 
         timer.stop();
         cumulative_runtime += timer.elapsed();
     }
 
     <span class="keywordflow">return</span> cumulative_runtime;
 }
<span class="preprocessor"> #endif // CPUBLAS_DRIVER_STEP_2_HH</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CUBlasDriver_STEP_2_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define CUBlasDriver_STEP_2_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;vector&gt;</span>
<span class="preprocessor"> #include &lt;lac/blas++.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/MVMultDriverInterface.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p><a class="anchor" id="ClassCUBlasDriver"></a> </p>
<h3>Class: CUBlasDriver</h3>
<p>In contrast to the CpuBlasDriver class which has just wrapped the blas function into the mvmult() function for providing a more comfortable progammer's interface this class additionally has to manage the host-device-communication, i.e. the data transfer between the two different memories.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T,<span class="keyword">typename</span> blasType=cublas&gt;
 <span class="keyword">class </span>CUBlasDriver : <span class="keyword">public</span> MVMultDriverInterface&lt;T&gt;
 {
 <span class="keyword">public</span>:
     <span class="keyword">typedef</span>
     <span class="keyword">typename</span> MVMultDriverInterface&lt;T&gt;::FullMatrixAccessor
     FullMatrixAccessor;
 
 
     CUBlasDriver();
 
     <span class="keyword">virtual</span> ~CUBlasDriver ();
 
     <span class="keyword">virtual</span> <span class="keywordtype">double</span> mvmult(std::vector&lt;T&gt;&amp; y,
                           <span class="keyword">const</span> FullMatrixAccessor&amp; A,
                           <span class="keyword">const</span> std::vector&lt;T&gt;&amp; x,
                           <span class="keywordtype">int</span>        n_repetitions);
 };
 
 } <span class="comment">// namespace step2 END</span>
 
<span class="preprocessor"> #include &lt;step-2/cuda_driver_step-2.hh&gt;</span>
<span class="preprocessor"> #endif // CUBlasDriver_STEP_2_H</span>
<span class="preprocessor"></span> 
 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CUDA_DRIVER_STEP_2_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define CUDA_DRIVER_STEP_2_HH</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;base/CUDATimer.h&gt;</span>
</pre></div><p><a class="anchor" id="ConstructorCUBlasDriver"></a> </p>
<h4>Constructor: CUBlasDriver</h4>
<p>In case of CUBLAS the constructor and destructor take care of initializing the library and shutting it down again.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T,<span class="keyword">typename</span> blasType&gt;
 step2::CUBlasDriver&lt;T,blasType&gt;::CUBlasDriver() : MVMultDriverInterface&lt;T&gt;()
 {
     blasType::Init();
 }
</pre></div><p><a class="anchor" id="DestructorCUBlasDriver"></a> </p>
<h4>Destructor: CUBlasDriver</h4>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T,<span class="keyword">typename</span> blasType&gt;
 step2::CUBlasDriver&lt;T,blasType&gt;::~CUBlasDriver()
 {
     blasType::Shutdown();
 }
</pre></div><p><a class="anchor" id="Functionmvmult"></a> </p>
<h4>Function: mvmult</h4>
<p>For details about the function arguments see the base class.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T,<span class="keyword">typename</span> blasType&gt;
 <span class="keywordtype">double</span> step2::CUBlasDriver&lt;T,blasType&gt;::mvmult(std::vector&lt;T&gt;&amp; y,
                                                <span class="keyword">const</span> FullMatrixAccessor&amp; A,
                                                <span class="keyword">const</span> std::vector&lt;T&gt;&amp; x,
                                                <span class="keywordtype">int</span> n_repetitions)
 {   
</pre></div><p>As before, we introduce some convenience variables and local variables for the arguments of the BLAS function.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> n_rows = A.n_rows();
     <span class="keywordtype">int</span> n_cols = A.n_cols();
 
     T * dst = &amp;y[0];
 
     T * A_entries = <span class="keyword">const_cast&lt;</span>FullMatrixAccessor &amp;<span class="keyword">&gt;</span>(A).val();
 
     T * src = &amp;<span class="keyword">const_cast&lt;</span>std::vector&lt;T&gt; &amp;<span class="keyword">&gt;</span>(x)[0];
 
     T alpha=1.;
     T beta=1.;
     <span class="keywordtype">int</span> incx=1;
     <span class="keywordtype">int</span> incy=1;
</pre></div><p>Since CUBLAS is also designed to work column-major everything we have said in the body of CpuBlasDriver::mvmult() applies here as well.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> lda=n_cols;
     <span class="keywordtype">int</span> m = n_cols;
     <span class="keywordtype">int</span> n = n_rows;
</pre></div><p>Up to this point there is no difference to CpuBlasDriver::mvmult(). In order to use CUBLAS we have to copy the matrix, the source and the destination vector to the device. To do this, we have to declare pointers in the device memory ...</p>
<div class="fragment"><pre class="fragment">     T *d_A, *d_x, *d_y;
</pre></div><p>allocate enough space ...</p>
<div class="fragment"><pre class="fragment">     cudaMalloc((<span class="keywordtype">void</span> **) &amp;d_A, n_rows * n_cols * <span class="keyword">sizeof</span>(T));
 
     cudaMalloc((<span class="keywordtype">void</span> **) &amp;d_x, n_cols * <span class="keyword">sizeof</span>(T));
     cudaMalloc((<span class="keywordtype">void</span> **) &amp;d_y, n_rows * <span class="keyword">sizeof</span>(T));
</pre></div><p>and copy everything from host to device.</p>
<div class="fragment"><pre class="fragment">     cudaMemcpy(d_x, src, n_cols * <span class="keyword">sizeof</span>(T), cudaMemcpyHostToDevice);
 
     cudaMemcpy(d_A, A_entries, n_rows * n_cols * <span class="keyword">sizeof</span>(T), cudaMemcpyHostToDevice);
</pre></div><p>It should be obvious that excessive use of <code>cudaMalloc</code>, <code>cudaMemcpy</code> and <code>cudaFree</code> quickly becomes error-prone and leads to a lot of redundant code. To remedy this, we have introduced our SciPal library which hides memory transfers behind assignment operators and the bare blas functions are wrapped up in an operator-based interface for linear algebra operations.</p>
<p>After these preparations we execute the CUBLAS version of gemv() via SciPal's CUBLAS wrapper which allows us to use a precision-independent formulation. After each run we have to synchronize in order to measure the actual runtime and not the time CUBLAS needs to start its kernels.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">double</span> cumulative_runtime = 0.;
     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;n_repetitions; i++)
     {
         cudaThreadSynchronize();
         CUDATimer timer;
</pre></div><p>Like BLAS, CUBLAS does not take care of properly initializing the result vector to zero. Hence, for each run we copy the vector from the host to the device.</p>
<div class="fragment"><pre class="fragment">         cudaMemcpy(d_y, dst, n_rows * <span class="keyword">sizeof</span>(T), cudaMemcpyHostToDevice);
 
         blasType::gemv (<span class="charliteral">&#39;t&#39;</span>, m, n, alpha,
                         d_A, lda,
                         d_x,  incx,
                         beta,
                         d_y,  incy);
 
         cudaThreadSynchronize();
         timer.stop();
         cumulative_runtime += timer.elapsed();
     }
</pre></div><p>Once we are done, we can copy the result back to the host and return the cumulative runtime.</p>
<div class="fragment"><pre class="fragment">     cudaMemcpy(dst, d_y, n_rows * <span class="keyword">sizeof</span>(T), cudaMemcpyDeviceToHost);
</pre></div><p>After the test is complete, we deallocate the arrays on the device.</p>
<div class="fragment"><pre class="fragment">     cudaFree(d_y);
     cudaFree(d_x);
     cudaFree(d_A);
 
     <span class="keywordflow">return</span> cumulative_runtime;
 }
<span class="preprocessor"> #endif // CUDA_DRIVER_STEP_2_HH</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef FUJIMOTO_DRIVER_step2_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define FUJIMOTO_DRIVER_step2_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;vector&gt;</span>
<span class="preprocessor"> #include &lt;lac/blas++.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/MVMultDriverInterface.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/cuda_kernel_wrapper_step-2.cu.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p><a class="anchor" id="ClassFujimotoDriver"></a> </p>
<h3>Class: FujimotoDriver</h3>
<p>The most interesting variant is the matrix-vector product by Fujimoto. Although it is executed on the GPU its driver class is more similar to CpuBlasDriver because the management of the host-device memory transfers is moved into the wrapper function of the CUDA kernel. We use private inheritance for the Kernels&lt;T&gt; structure to express the "is implemented with" relationship.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T,<span class="keyword">typename</span> blasType=cublas&gt;
 <span class="keyword">class </span>FujimotoDriver : <span class="keyword">public</span> MVMultDriverInterface&lt;T&gt;, <span class="keyword">private</span> Kernels&lt;T&gt;
 {
 <span class="keyword">public</span>:
     <span class="keyword">typedef</span>
     <span class="keyword">typename</span> MVMultDriverInterface&lt;T&gt;::FullMatrixAccessor FullMatrixAccessor;
 
     FujimotoDriver(<span class="keyword">const</span> <span class="keywordtype">int</span> v) : fj_version(v) {}
 
     <span class="keyword">virtual</span>  ~FujimotoDriver () {}
 
     <span class="keyword">virtual</span> <span class="keywordtype">double</span> mvmult(std::vector&lt;T&gt;&amp; y,
                           <span class="keyword">const</span> FullMatrixAccessor&amp; A,
                           <span class="keyword">const</span> std::vector&lt;T&gt;&amp; x,
                           <span class="keywordtype">int</span> n_repetitions);
 
 <span class="keyword">protected</span>:
     <span class="keyword">const</span> <span class="keywordtype">int</span> fj_version;
 };
 
 } <span class="comment">// namespace step2 END</span>
 
<span class="preprocessor"> #include &lt;step-2/Fujimoto_driver_step-2.hh&gt;</span>
<span class="preprocessor"> #endif // FUJIMOTO_DRIVER_step2_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef FUJIMOTO_DRIVER_step2_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define FUJIMOTO_DRIVER_step2_HH</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;step-2/cuda_kernel_wrapper_step-2.cu.h&gt;</span>
<span class="preprocessor"> #include &lt;base/CUDATimer.h&gt;</span>
</pre></div><p><a class="anchor" id="Functionmvmult"></a> </p>
<h4>Function: mvmult</h4>
<p>For details about the function arguments see the base class. It is very similar to CpuBlasDriver::mvmult(). The major differences are that instead of a blas function a CUDA kernel is invoked and that the measurement of the runtime is moved into the kernel wrapper function which gives us a cumulative runtime and not an average.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number,<span class="keyword">typename</span> blasType&gt;
 <span class="keywordtype">double</span> step2::FujimotoDriver&lt;Number,blasType&gt;::mvmult(std::vector&lt;Number&gt; &amp; y,
                                                       <span class="keyword">const</span> FullMatrixAccessor&amp; A,
                                                       <span class="keyword">const</span> std::vector&lt;Number&gt; &amp; x,
                                                       <span class="keywordtype">int</span> n_repetitions)
 {
     <span class="keywordtype">int</span> n_rows = A.n_rows();
     <span class="keywordtype">int</span> n_cols = A.n_cols();
 
     Number * dst = &amp;y[0];
 
     <span class="keyword">const</span> Number * A_entries = A.val();
 
     <span class="keyword">const</span> Number * src = &amp;x[0];
 
 
     <span class="keywordtype">double</span> cumulative_elapsed_time = 0;
 
     this-&gt;mv_fujimoto(dst, A_entries, src,
                       n_rows, n_cols,
                       n_repetitions,
                       this-&gt;fj_version,
                       cumulative_elapsed_time);
 
     <span class="keywordflow">return</span> cumulative_elapsed_time;
 }
 
<span class="preprocessor"> #endif // FUJIMOTO_DRIVER_step2_HH</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CUDA_KERNEL_STEP_2_CU_H</span>
<span class="preprocessor"> #define CUDA_KERNEL_STEP_2_CU_H</span>
</pre></div><p><a class="anchor" id="DeclarationofCUDAInterface"></a> </p>
<h3>Declaration of CUDA Interface</h3>
<div class="fragment"><pre class="fragment"> <span class="keyword">namespace </span>step2 {
</pre></div><p><a class="anchor" id="ClassKernels"></a> </p>
<h3>Class: Kernels</h3>
<p>In our example programs we try to encapsulate CUDA as much as possible such that CUDA-independent parts of the source code can be reused easily. Especially, we want to localize CUDA-specific extensions of the C/C++language in only a few files. The bridge between these two parts is formed by the Kernels class. Its member functions mirror the arguments of the CUDA kernels and their bodies provide the encapsulation of the non-standard syntax for the kernels calls. Currently, there is only one wrapper function for the kernel by Fujimoto. Often kernels can be implemented in a type-independent way. Therefore, the Kernels class is templated with respect to the number type.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">struct </span>Kernels {
 
     <span class="keywordtype">void</span> mv_fujimoto(T *y, <span class="keyword">const</span> T *A, <span class="keyword">const</span> T *x,
                      <span class="keyword">const</span> <span class="keywordtype">int</span> m, <span class="keyword">const</span> <span class="keywordtype">int</span> n,
                      <span class="keyword">const</span> <span class="keywordtype">int</span> n_repetitions, <span class="keyword">const</span> <span class="keywordtype">int</span> fj_version, <span class="keywordtype">double</span>&amp; elapsed_time);
 };
 }
<span class="preprocessor"> #endif // CUDA_KERNEL_STEP_2_CU_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
 
<span class="preprocessor"> #include &lt;step-2/cuda_kernel_wrapper_step-2.cu.h&gt;</span>
</pre></div><p>On OSX10.9 the CUDATimer class causes linker errors. Therefore, we disable it. #define DONT_USE_CUDATIMER</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #ifndef DONT_USE_CUDATIMER</span>
<span class="preprocessor"></span><span class="preprocessor"> #include &lt;base/CUDATimer.h&gt;</span>
<span class="preprocessor"> #endif</span>
</pre></div><p>With the advent of the Fermi architecture it became possible to use the printf command from within a kernel. To enable this feature one has to include the corresponding header from the C standard library.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #include &lt;stdio.h&gt;</span>
</pre></div><p><a class="anchor" id="Kernels"></a> </p>
<h3>Kernels</h3>
<p>The core of any CUDA-based application are its kernels. They are the place where the actual numerical labour is executed. Like on the host side we put all kernels in a separate namespace to avoid collisions with other steps.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">namespace </span>step2 {
</pre></div><p>To shorten the kernel code we introduce some abbreviations for built-in variables.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #define bx blockIdx.x</span>
<span class="preprocessor"></span><span class="preprocessor"> #define tx threadIdx.x</span>
<span class="preprocessor"> #define ty threadIdx.y</span>
</pre></div><p>The crucial idea of Fujimoto's method is to use the texture cache(s) to speed up the reading of the matrix by tiling and accessing it as a texture, as we have already mentioned in the introduction. To manage textures CUDA allows to either define texture objects or texture references (for the details have a look at the programming guide, Sec. 3.2.10). We follow Fujimoto and use references. A subtlety of texture references is that they must exist as global variables in the same file as the kernel which is going to access them. In computer graphics it is often desirable to normalize the values read from a texture to the range [-1., +1] or [0, +1.] depending on whether they are signed or unsigned. Defining the access as <em>cudaReadModeElementType</em> assures that during the texture fetch the data is read "as is". The immutable parameters needed at compile time are the element type, the spatial dimension and the type of access.</p>
<div class="fragment"><pre class="fragment"> texture&lt;float4, 2, cudaReadModeElementType&gt; fTexRefA;
</pre></div><p><a class="anchor" id="Kernel_mv_fujimoto"></a> </p>
<h4>Kernel: _mv_fujimoto</h4>
<p>This is the CUDA kernel for the matrix-vector multiplication</p>
<p class="formulaDsp">
<img class="formulaDsp" alt="\begin{equation} y = Ax \end{equation}" src="form_41.png"/>
</p>
<p> introduced by Noriyuki Fujimoto.</p>
<p>Copyright (C) 2008 Noriyuki Fujimoto, All Rights Reserved <a href="mailto:Fujimoto@mi.s.osakafu-u.ac.jp">Fujimoto@mi.s.osakafu-u.ac.jp</a></p>
<p>Please refer the paper below if you use Fujimoto's algorithm in your published work :</p>
<p>Noriyuki Fujimoto, Faster Matrix-Vector Multiplication on GeForce 8800GTX, In the Proceedings of the 22nd IEEE International Parallel and Distributed Processing Symposium (IPDPS), LSPP-402, pp.1-8, April 2008</p>
<p>This CUDA kernel heavily relies on bitshift operations. A good review can be found <a href="http://www.cprogramming.com/tutorial/bitwise_operators.html">here</a>.</p>
<p>We start with the original version to explain the details of the parallelization. Afterwards we generalize it to double precision, consider the dependence of performance on the bitshifting and discuss an improved way of reading a double-precision matrix.</p>
<p>To parallelize the multiplication of a large, dense matrix with a dense vector the matrix gets subdivided into small tiles. One row of tiles is assigned to one thread block of 16 x 16 threads. These sizes are chosen such that no thread of a block is idle when the entries of the vector are loaded into shared memory. Each thread block loads one tile at a time and computes its product with the corresponding slice from the source vectors. </p>
<dl class="params"><dt><b>Parameters:</b></dt><dd>
  <table class="params">
    <tr><td class="paramname">y</td><td>: pointer to array containing the entries of the results vector. </td></tr>
    <tr><td class="paramname">A</td><td>: pointer to a cudaArray which the matrix has been copied. </td></tr>
    <tr><td class="paramname">x</td><td>: pointer to array containing the entries of the source vector. </td></tr>
    <tr><td class="paramname">m</td><td>: Number of rows of the matrix. The internal dimensions of the cudaArray may be different. </td></tr>
    <tr><td class="paramname">n</td><td>: Number of columns of the matrix. The internal dimensions of the cudaArray may be different.</td></tr>
  </table>
  </dd>
</dl>
<div class="fragment"><pre class="fragment"> __global__
 <span class="keywordtype">void</span>
 _mv_fujimoto(<span class="keywordtype">float</span>* y, cudaArray* A, <span class="keywordtype">float</span>* x, <span class="keywordtype">int</span> m, <span class="keywordtype">int</span> n)
 {
</pre></div><p>In the original version each 16x16 threadblock computes the matrix-vector product of a 16x16 submatrix of the texture with 256 entries of the source vector <img class="formulaInl" alt="$x$" src="form_22.png"/> at a time. Due to the frequent reuse of the vector entries they are stored in shared memory.</p>
<div class="fragment"><pre class="fragment">     __shared__ <span class="keywordtype">float</span> xs[16][16];
</pre></div><p>The intermediate partial sums are buffered in shared memory</p>
<div class="fragment"><pre class="fragment">     __shared__ <span class="keywordtype">float</span> Ps[16][16];
</pre></div><p>and the matrix entries read from the texture in a small vector.</p>
<div class="fragment"><pre class="fragment">     float4 a;
</pre></div><p>The 2D matrix indices must be converted to a 1D index (leftshift of 4 = multiplication with 16 (2^4) which is the blocksize)</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">float</span> *Psptr = (<span class="keywordtype">float</span> *) Ps + (ty &lt;&lt; 4) + tx;
</pre></div><p>Then we determine the <img class="formulaInl" alt="$y$" src="form_23.png"/> coordinate of the position in the texture, i.e. the global row index</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> ay = (bx &lt;&lt; 4) + ty;
</pre></div><p>The entries of the solution vector and the partial sums which will be computed by this thread are addressed via pointers to hide the index arithmetic.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">float</span> *xptr = x + (ty &lt;&lt; 4) + tx;
     <span class="keywordtype">float</span> *xsptr = (<span class="keywordtype">float</span> *) xs + (tx &lt;&lt; 2);
</pre></div><p>Each thread initializes its partial sum to 0.</p>
<div class="fragment"><pre class="fragment">     *Psptr = 0.0f;
</pre></div><p>Since the loop over the column index gets partially unrolled we have to define it outside the loop unlike standard C++ procedure.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> i;
</pre></div><p>Each row of a thread block deals with one row of the matrix. Each thread walks through the texture with a stride of 64 and computes the scalar product of 4 consecutive matrix elements with 4 consecutive elements of the source vector. The loop for the scalar product is unrolled. With respect to the individual matrix elements this leads to an outer stride of 256. Hence, one row of threads in the thread block simultaneously works on 64 texture elements or 256 matrix and source vector elements respectively. Thus, there are no idle threads for most of the time especially when the next bunch of source vector entries is loaded. Exceptions may occur when the threads have reached the right boundary of the matrix.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">for</span> (i = 0; i &lt; (n &amp; ~255); i += 256, xptr += 256)
     {
</pre></div><p>Since the source vector entries are the only ones which can be reused they are copied into shared memory.</p>
<div class="fragment"><pre class="fragment">         xs[ty][tx] = *xptr;
         __syncthreads();
</pre></div><p>The core of the algorithm is to compute the scalar product of 4 consecutive entries of a matrix row with the corresponding subvector of the source vector. The matrix is read through a texture to take advantage of their optimization with respect to 2D spatial locality. Each texture element represents 4 consecutive entries of a matrix row as float4, i.e. a vector of 4 floats.</p>
<p>The texture elements are formed by 4-component vectors. The 16 threads of one row of the thread block are supposed to read 16 consecutive texture elements. Therefore, the <img class="formulaInl" alt="$x$" src="form_22.png"/> coordinate for the texture fetch is given by the <img class="formulaInl" alt="$x$" src="form_22.png"/> component of the thread index <code>tx</code> plus the column index <code>i</code> divided by 4. The division is realized by shifting the bits of <code>i</code> to the right. This algorithm is also illustrated in <a href="http://ch.nvidia.com/docs/IO/47905/fujimoto_lspp2008.pdf">Fujimoto's paper</a>.</p>
<div class="fragment"><pre class="fragment">         <span class="keywordtype">int</span> ax = tx + (i &gt;&gt; 2);
 
         a = tex2D(fTexRefA, ax     , ay);
</pre></div><p>After reading the texture element we can compute the inner product of <code>a</code> with the corresponding 4 entries of <code>x</code>. This is done by all threads and thus simultaneously for 64 consecutive elements of <img class="formulaInl" alt="$x$" src="form_22.png"/>.</p>
<div class="fragment"><pre class="fragment">         *Psptr += a.x * *xsptr         + a.y * *(xsptr +   1) + a.z * *(xsptr +   2) + a.w * *(xsptr +   3);
</pre></div><p>The next statements repeat this procedure for the remaining 3 subgroups comprising 64 elements of <img class="formulaInl" alt="$x$" src="form_22.png"/> each.</p>
<div class="fragment"><pre class="fragment">         a = tex2D(fTexRefA, ax + 16, ay);
         *Psptr += a.x * *(xsptr +  64) + a.y * *(xsptr +  65) + a.z * *(xsptr +  66) + a.w * *(xsptr +  67);
 
         a = tex2D(fTexRefA, ax + 32, ay);
         *Psptr += a.x * *(xsptr + 128) + a.y * *(xsptr + 129) + a.z * *(xsptr + 130) + a.w * *(xsptr + 131);
 
         a = tex2D(fTexRefA, ax + 48, ay);
         *Psptr += a.x * *(xsptr + 192) + a.y * *(xsptr + 193) + a.z * *(xsptr + 194) + a.w * *(xsptr + 195);
 
         __syncthreads();
     }
</pre></div><p>At this point the number of remaining columns does not suffice to keep all threads busy with the unrolling strategy. Especially, there are less than 256 vector entries which still can be read.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span> (i + (ty &lt;&lt; 4) + tx &lt; n) {
         xs[ty][tx] = *xptr;
     }
     __syncthreads();
</pre></div><p>After reading what is left over the 16 threads of a row in the thread block work on the remaining columns in chunks of 64. Increasing <code>xsptr</code> only by 61 in each iteration is due to the fact that it is already incremented in the body of the loop three times.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> j;
     <span class="keywordflow">for</span> (j = 0; j &lt; ((n - i) &gt;&gt; 6); j++, xsptr += 61) {
         a = tex2D(fTexRefA, tx + (i &gt;&gt; 2) + (j &lt;&lt; 4), ay);
         *Psptr += a.x * *xsptr++ + a.y * *xsptr++ + a.z * *xsptr++ + a.w * *xsptr;
     }
     __syncthreads();
</pre></div><p>When there are less than 64 columns left some threads have to stay idle while the rest finishes the job.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> remain = (n - i) &amp; 63;
 
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) &lt; remain) {
         a = tex2D(fTexRefA, tx + (i &gt;&gt; 2) + (j &lt;&lt; 4), ay);
         *Psptr += a.x * *xsptr++;
     }
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) + 1 &lt; remain) *Psptr += a.y * *xsptr++;
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) + 2 &lt; remain) *Psptr += a.z * *xsptr++;
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) + 3 &lt; remain) *Psptr += a.w * *xsptr;
     __syncthreads();
</pre></div><p>The last step, before we can write the result to global memory, is to reduce the partial sums into one.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span> (tx &lt; 8) *Psptr += *(Psptr + 8);
     <span class="keywordflow">if</span> (tx &lt; 4) *Psptr += *(Psptr + 4);
     <span class="keywordflow">if</span> (tx &lt; 2) *Psptr += *(Psptr + 2);
     <span class="keywordflow">if</span> (tx &lt; 1) *Psptr += *(Psptr + 1);
     __syncthreads();
 
     <span class="keywordflow">if</span> (ty == 0 &amp;&amp; (bx &lt;&lt; 4) + tx &lt; m) y[(bx &lt;&lt; 4) + tx] = Ps[tx][0];
 }
</pre></div><p><a class="anchor" id="Kernel_mv_fujimoto_T"></a> </p>
<h4>Kernel: _mv_fujimoto_T</h4>
<p>A limitation of Fujimoto's original kernel is that it is implemented only for single-precision, real-valued matrices. Here, we show how to extend it to double precision. Complex numbers should be similar.</p>
<p>The first thing we need is a structure which allows us to distinguish floats from doubles at compile-time.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">struct </span>IsFloat;
 
 <span class="keyword">template</span>&lt;&gt;
 <span class="keyword">struct </span>IsFloat&lt;float&gt;
 {
     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">bool</span> value = <span class="keyword">true</span>;
 };
 
 <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">struct </span>IsFloat
 {
     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">bool</span> value = <span class="keyword">false</span>;
 };
</pre></div><p>Then we need a template structure which depending on the number type <code>T</code> of the matrix elements provides the correct data types for the texture elements and the buffer of the matrix elements. Further, it has to provide the stride for the texture access which is needed in the determination of the effective width of the cudaArray through which the texture is accessed, see below in the wrapper function.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">struct </span>TexEl;
</pre></div><p>For single-precision, real numbers we need the types and values from the original implementation.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;&gt;
 <span class="keyword">struct </span>TexEl&lt;float&gt;
 {
     <span class="keyword">typedef</span> float4 value_type;
     <span class="keyword">typedef</span> float4 alt_value_type;
     <span class="keyword">typedef</span> float4 texel_type;
     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">int</span> tex_stride = 4;
 };
</pre></div><p>For double precision we can use <code>double4</code> as buffer but there are no such texture fetches. Therefore, we have to compose the texture of elements of type <code>int4</code> and each double has to be reconstructed from 2 ints using CUDA's <code>__hiloint2double</code> function.</p>
<p>For later use we introduce <code>double2</code> as alternative value type.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;&gt;
 <span class="keyword">struct </span>TexEl&lt;double&gt;
 {
     <span class="keyword">typedef</span> double4 value_type;
     <span class="keyword">typedef</span> double2 alt_value_type;
     <span class="keyword">typedef</span> int4 texel_type;
     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">int</span> tex_stride = 2;
 };
</pre></div><p>Last but not least we need a separate texture reference for double precision.</p>
<div class="fragment"><pre class="fragment"> texture&lt;TexEl&lt;double&gt;::texel_type, 2, cudaReadModeElementType&gt; dTexRefA;
</pre></div><p>The problem with the texture references is that we have to define one for each data type. Yet, we want to abstract the fetching from the data type. To do this, we define a little structure for the texture access which only provides an overloaded operator().</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">struct </span>texAccessor {
 
     __device__
     <span class="keyword">typename</span> TexEl&lt;T&gt;::value_type
     operator() (<span class="keywordtype">int</span> ax, <span class="keywordtype">int</span> ay);
 
 };
</pre></div><p>Depending on the template specialization we can access the different texture references. For single precision we return what we fetch right away.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;&gt;
 TexEl&lt;float&gt;::value_type texAccessor&lt;float&gt;::operator() (<span class="keywordtype">int</span> ax, <span class="keywordtype">int</span> ay)
 {
     <span class="keywordflow">return</span> tex2D(fTexRefA, ax, ay);
 }
</pre></div><p>In case of double precision this is also place where we reconstruct the matrix entries.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;&gt;
 TexEl&lt;double&gt;::value_type texAccessor&lt;double&gt;::operator() (<span class="keywordtype">int</span> ax, <span class="keywordtype">int</span> ay)
 {
     TexEl&lt;double&gt;::texel_type tmp;
     TexEl&lt;double&gt;::value_type a;
 
     tmp = tex2D(dTexRefA, 2*ax, ay);
     a.x = __hiloint2double(tmp.y, tmp.x);
     a.y = __hiloint2double(tmp.w, tmp.z);
 
     tmp = tex2D(dTexRefA, 2*ax+1, ay);
     a.z = __hiloint2double(tmp.y, tmp.x);
     a.w = __hiloint2double(tmp.w, tmp.z);
 
<span class="preprocessor"> #ifndef nDEBUG</span>
<span class="preprocessor"></span>     printf(<span class="stringliteral">&quot;a : %f, %f, %f, %f\n&quot;</span>, a.x, a.y, a.z, a.w);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>     <span class="keywordflow">return</span> a;
 }
</pre></div><p>Since there are only so few changes we only comment the differences. First of all, all occurences of <code>float</code> are replaced by <code>T</code>.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 __global__
 <span class="keywordtype">void</span>
 _mv_fujimoto_T( T* y, cudaArray* A, T* x, <span class="keywordtype">int</span> m, <span class="keywordtype">int</span> n)
 {
     __shared__ T xs[16][16];
 
     __shared__ T Ps[16][16];
</pre></div><p>Instead of a hard-coded type for buffer for the matrix elements we let the TexEl structure determine the correct type from which particular  is passed in as template argument. This is typical template metaprogramming.</p>
<div class="fragment"><pre class="fragment">     <span class="keyword">typename</span> TexEl&lt;T&gt;::value_type a;
 
     T *Psptr = (T *) Ps + (ty &lt;&lt; 4) + tx;
 
     <span class="keywordtype">int</span> ay = (bx &lt;&lt; 4) + ty;
 
     T *xptr = x + (ty &lt;&lt; 4) + tx;
     T *xsptr = (T *) xs + (tx &lt;&lt; 2);
 
     *Psptr = 0.0f;
     <span class="keywordtype">int</span> i;
</pre></div><p>In contrast to the original kernel we now need an accessor object for the texture fetches which eliminiates the texture reference from the list of arguments of the texture fetch.</p>
<div class="fragment"><pre class="fragment">     texAccessor&lt;T&gt; tex_2D;
</pre></div><p>Except for the changes in the texture fetches everything else remains unchanged.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">for</span> (i = 0; i &lt; (n &amp; ~255); i += 256, xptr += 256)
     {
         xs[ty][tx] = *xptr;
         __syncthreads();
 
         <span class="keywordtype">int</span> ax = tx + (i &gt;&gt; 2);
 
         a = tex_2D(ax, ay);
         *Psptr += a.x * *xsptr         + a.y * *(xsptr +   1) + a.z * *(xsptr +   2) + a.w * *(xsptr +   3);
 
         a = tex_2D(ax+16, ay);
         *Psptr += a.x * *(xsptr +  64) + a.y * *(xsptr +  65) + a.z * *(xsptr +  66) + a.w * *(xsptr +  67);
 
         a = tex_2D(ax+32, ay);
         *Psptr += a.x * *(xsptr + 128) + a.y * *(xsptr + 129) + a.z * *(xsptr + 130) + a.w * *(xsptr + 131);
 
         a = tex_2D(ax+48, ay);
         *Psptr += a.x * *(xsptr + 192) + a.y * *(xsptr + 193) + a.z * *(xsptr + 194) + a.w * *(xsptr + 195);
 
         __syncthreads();
     }
 
     <span class="keywordflow">if</span> (i + (ty &lt;&lt; 4) + tx &lt; n) {
         xs[ty][tx] = *xptr;
     }
     __syncthreads();
 
     <span class="keywordtype">int</span> j;
     <span class="keywordflow">for</span> (j = 0; j &lt; ((n - i) &gt;&gt; 6); j++, xsptr += 61) {
         a = tex_2D(tx + (i &gt;&gt; 2) + (j &lt;&lt; 4), ay);
         *Psptr += a.x * *xsptr++ + a.y * *xsptr++    +     a.z * *xsptr++ + a.w * *xsptr;
     }
     __syncthreads();
 
     <span class="keywordtype">int</span> remain = (n - i) &amp; 63;
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) &lt; remain) {
         a = tex_2D(tx + (i &gt;&gt; 2) + (j &lt;&lt; 4), ay);
 
         *Psptr += a.x * *xsptr++;
     }
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) + 1 &lt; remain) *Psptr += a.y * *xsptr++;
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) + 2 &lt; remain) *Psptr += a.z * *xsptr++;
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) + 3 &lt; remain) *Psptr += a.w * *xsptr;
     __syncthreads();
 
 
     <span class="keywordflow">if</span> (tx &lt; 8) *Psptr += *(Psptr + 8);
     <span class="keywordflow">if</span> (tx &lt; 4) *Psptr += *(Psptr + 4);
     <span class="keywordflow">if</span> (tx &lt; 2) *Psptr += *(Psptr + 2);
     <span class="keywordflow">if</span> (tx &lt; 1) *Psptr += *(Psptr + 1);
 
     __syncthreads();
     <span class="keywordflow">if</span> (ty == 0 &amp;&amp; (bx &lt;&lt; 4) + tx &lt; m) y[(bx &lt;&lt; 4) + tx] = Ps[tx][0];
 }
</pre></div><p><a class="anchor" id="Kernel_mv_fujimoto_T2"></a> </p>
<h4>Kernel: _mv_fujimoto_T2</h4>
<p>Bitshifting maybe efficient. Yet it limits the readability of the code. Therefore, we provide one version where the bitshift operations are replaced by multiplications and divisions. Running the different Fujimoto versions then gives an overview of whether that technique pays off. Except for the bitshifts everything else is a verbatim copy of the previous kernel.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 __global__
 <span class="keywordtype">void</span>
 _mv_fujimoto_T2( T* y, cudaArray* A, T* x, <span class="keywordtype">int</span> m, <span class="keywordtype">int</span> n)
 {
     __shared__ T xs[16][16];
 
     __shared__ T Ps[16][16];
 
     <span class="keyword">typename</span> TexEl&lt;T&gt;::value_type a;
 
     T *Psptr = (T *) Ps + (16*ty) + tx;
 
     <span class="keywordtype">int</span> ay = (16*bx) + ty;
 
     T *xptr = x + (16*ty) + tx;
     T *xsptr = (T *) xs + (4*tx);
 
     *Psptr = 0.0f;
     <span class="keywordtype">int</span> i;
 
     texAccessor&lt;T&gt; tex_2D;
 
 
     <span class="keywordflow">for</span> (i = 0; i &lt; (n &amp; ~255); i += 256, xptr += 256)
     {
         xs[ty][tx] = *xptr;
         __syncthreads();
 
         <span class="keywordtype">int</span> ax = tx + (i/4);
 
         a = tex_2D(ax, ay);
         *Psptr += a.x * *xsptr         + a.y * *(xsptr +   1) + a.z * *(xsptr +   2) + a.w * *(xsptr +   3);
 
         a = tex_2D(ax+16, ay);
         *Psptr += a.x * *(xsptr +  64) + a.y * *(xsptr +  65) + a.z * *(xsptr +  66) + a.w * *(xsptr +  67);
 
         a = tex_2D(ax+32, ay);
         *Psptr += a.x * *(xsptr + 128) + a.y * *(xsptr + 129) + a.z * *(xsptr + 130) + a.w * *(xsptr + 131);
 
         a = tex_2D(ax+48, ay);
         *Psptr += a.x * *(xsptr + 192) + a.y * *(xsptr + 193) + a.z * *(xsptr + 194) + a.w * *(xsptr + 195);
 
         __syncthreads();
     }
 
     <span class="keywordflow">if</span> (i + (16*ty) + tx &lt; n) {
         xs[ty][tx] = *xptr;
     }
     __syncthreads();
 
     <span class="keywordtype">int</span> j;
     <span class="keywordflow">for</span> (j = 0; j &lt; ((n - i)/64); j++, xsptr += 61) {
         a = tex_2D(tx + (i/4) + (16*j), ay);
         *Psptr += a.x * *xsptr++ + a.y * *xsptr++    +     a.z * *xsptr++ + a.w * *xsptr;
     }
     __syncthreads();
 
     <span class="keywordtype">int</span> remain = (n - i) &amp; 63;
     <span class="keywordflow">if</span> ((4*tx) &lt; remain) {
         a = tex_2D(tx + (i/4) + (16*j), ay);
 
         *Psptr += a.x * *xsptr++;
     }
     <span class="keywordflow">if</span> ((4*tx) + 1 &lt; remain) *Psptr += a.y * *xsptr++;
     <span class="keywordflow">if</span> ((4*tx) + 2 &lt; remain) *Psptr += a.z * *xsptr++;
     <span class="keywordflow">if</span> ((4*tx) + 3 &lt; remain) *Psptr += a.w * *xsptr;
     __syncthreads();
 
 
     <span class="keywordflow">if</span> (tx &lt; 8) *Psptr += *(Psptr + 8);
     <span class="keywordflow">if</span> (tx &lt; 4) *Psptr += *(Psptr + 4);
     <span class="keywordflow">if</span> (tx &lt; 2) *Psptr += *(Psptr + 2);
     <span class="keywordflow">if</span> (tx &lt; 1) *Psptr += *(Psptr + 1);
 
     __syncthreads();
     <span class="keywordflow">if</span> (ty == 0 &amp;&amp; (16*bx) + tx &lt; m) y[(16*bx) + tx] = Ps[tx][0];
 }
</pre></div><p><a class="anchor" id="Kernel_mv_fujimoto_T3"></a> </p>
<h4>Kernel: _mv_fujimoto_T3</h4>
<p>The next issue is the optimization of double precision performance. The way it is handled up to now should lead to warps running at only half of their possible memory bandwidth. To change that we have to modify the texAccessor class and the magic numbers in the unrolled innermost loop.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">struct </span>texAccessorOpt {
 
     __device__
     <span class="keyword">typename</span> TexEl&lt;T&gt;::alt_value_type
     operator() (<span class="keywordtype">int</span> ax, <span class="keywordtype">int</span> ay);
 
 };
</pre></div><p>Depending on the template specialization we can access the different texture references. For single precision nothing changes.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;&gt;
 TexEl&lt;float&gt;::alt_value_type texAccessorOpt&lt;float&gt;::operator() (<span class="keywordtype">int</span> ax, <span class="keywordtype">int</span> ay)
 {
     <span class="keywordflow">return</span> tex2D(fTexRefA, ax, ay);
 }
</pre></div><p>In case of double precision we now read only one texture element. This has to be compensated in the magic numbers for the partial unrolling of the loop over the columns of a row.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;&gt;
 TexEl&lt;double&gt;::alt_value_type texAccessorOpt&lt;double&gt;::operator() (<span class="keywordtype">int</span> ax, <span class="keywordtype">int</span> ay)
 {
     TexEl&lt;double&gt;::texel_type tmp;
     TexEl&lt;double&gt;::alt_value_type a;
 
     tmp = tex2D(dTexRefA, ax, ay);
     a.x = __hiloint2double(tmp.y, tmp.x);
     a.y = __hiloint2double(tmp.w, tmp.z);
 
<span class="preprocessor"> #ifdef DEBUG</span>
<span class="preprocessor"></span>     printf(<span class="stringliteral">&quot;a : %f, %f\n&quot;</span>, a.x, a.y);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>     <span class="keywordflow">return</span> a;
 }
</pre></div><p>In the kernel we distinguish between floats and doubles using our IsFloat structure.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 __global__
 <span class="keywordtype">void</span>
 _mv_fujimoto_T3( T* y, cudaArray* A, T* x, <span class="keywordtype">int</span> m, <span class="keywordtype">int</span> n)
 {
     __shared__ T xs[16][16];
 
     __shared__ T Ps[16][16];
 
 
     T *Psptr = (T *) Ps + (16*ty) + tx;
 
     <span class="keywordtype">int</span> ay = (16*bx) + ty;
 
     T *xptr = x + (16*ty) + tx;
 
 
     *Psptr = 0.0f;
     <span class="keywordtype">int</span> i;
 
     <span class="keywordflow">if</span>(IsFloat&lt;T&gt;::value==<span class="keyword">true</span>)
     {
         T *xsptr = (T *) xs + (4*tx);
         <span class="keyword">typename</span> TexEl&lt;T&gt;::value_type a;
         texAccessor&lt;T&gt; tex_2D;
         <span class="keywordflow">for</span> (i = 0; i &lt; (n &amp; ~255); i += 256, xptr += 256)
         {
             xs[ty][tx] = *xptr;
             __syncthreads();
 
             <span class="keywordtype">int</span> ax = tx + (i/4);
 
             a = tex_2D(ax, ay);
              printf(<span class="stringliteral">&quot;a : %f, %f, %f, %f\n&quot;</span>, a.x, a.y, a.z, a.w);
             *Psptr += a.x * *xsptr         + a.y * *(xsptr +   1) + a.z * *(xsptr +   2) + a.w * *(xsptr +   3);
 
             a = tex_2D(ax+16, ay);
             *Psptr += a.x * *(xsptr +  64) + a.y * *(xsptr +  65) + a.z * *(xsptr +  66) + a.w * *(xsptr +  67);
 
             a = tex_2D(ax+32, ay);
             *Psptr += a.x * *(xsptr + 128) + a.y * *(xsptr + 129) + a.z * *(xsptr + 130) + a.w * *(xsptr + 131);
 
             a = tex_2D(ax+48, ay);
             *Psptr += a.x * *(xsptr + 192) + a.y * *(xsptr + 193) + a.z * *(xsptr + 194) + a.w * *(xsptr + 195);
 
             __syncthreads();
         }
 
         <span class="keywordflow">if</span> (i + (16*ty) + tx &lt; n) {
             xs[ty][tx] = *xptr;
         }
         __syncthreads();
 
 
         <span class="keywordtype">int</span> j;
         <span class="keywordflow">for</span> (j = 0; j &lt; ((n - i)/64); j++, xsptr += 61) {
             a = tex_2D(tx + (i/4) + (16*j), ay);
             *Psptr += a.x * *xsptr++ + a.y * *xsptr++ + a.z * *xsptr++ + a.w * *xsptr;
         }
         __syncthreads();
 
 
         <span class="keywordtype">int</span> remain = (n - i) &amp; 63;
         <span class="keywordflow">if</span> ((4*tx) &lt; remain) {
             a = tex_2D(tx + (i/4) + (16*j), ay);
 
             *Psptr += a.x * *xsptr++;
         }
         <span class="keywordflow">if</span> ((4*tx) + 1 &lt; remain) *Psptr += a.y * *xsptr++;
         <span class="keywordflow">if</span> ((4*tx) + 2 &lt; remain) *Psptr += a.z * *xsptr++;
         <span class="keywordflow">if</span> ((4*tx) + 3 &lt; remain) *Psptr += a.w * *xsptr;
         __syncthreads();
     }
</pre></div><p>For double precision we still have 16 multiplications in the innermost unrolled loop but we have to read twice as often from the texture. Yet, it is done such that threads read contiguous pieces of memory when the instruction for a texture fetch is issued unlike before.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">else</span> {
         T *xsptr = (T *) xs + (2*tx);
 
         <span class="keyword">typename</span> TexEl&lt;T&gt;::alt_value_type a;
 
         texAccessorOpt&lt;T&gt; tex_2D;
 
         <span class="keywordflow">for</span> (i = 0; i &lt; (n &amp; ~255); i += 256, xptr += 256)
         {
             xs[ty][tx] = *xptr;
 
             __syncthreads();
 
             <span class="keywordtype">int</span> ax = tx + (i/2);
 
 
             a = tex_2D(ax, ay);
             *Psptr += a.x * *xsptr         + a.y * *(xsptr +   1);
 
             a = tex_2D(ax+16, ay);
             *Psptr += a.x * *(xsptr +  32) + a.y * *(xsptr +  33);
 
             a = tex_2D(ax+32, ay);
             *Psptr += a.x * *(xsptr + 64) + a.y * *(xsptr + 65);
 
             a = tex_2D(ax+48, ay);
             *Psptr += a.x * *(xsptr + 96) + a.y * *(xsptr + 97);
 
             a = tex_2D(ax+64, ay);
             *Psptr += a.x * *(xsptr + 128) + a.y * *(xsptr + 129);
 
             a = tex_2D(ax+80, ay);
             *Psptr += a.x * *(xsptr + 160) + a.y * *(xsptr + 161);
 
             a = tex_2D(ax+96, ay);
             *Psptr += a.x * *(xsptr + 192) + a.y * *(xsptr + 193);
 
             a = tex_2D(ax+112, ay);
             *Psptr += a.x * *(xsptr + 224) + a.y * *(xsptr + 225);
 
             __syncthreads();
         }
 
         <span class="keywordflow">if</span> (i + (16*ty) + tx &lt; n) xs[ty][tx] = *xptr;
 
         __syncthreads();
 
 
         <span class="keywordtype">int</span> j;
 
         <span class="keywordflow">for</span> (j = 0; j &lt; ((n - i)/32); j++, xsptr += 31)
         {
             a = tex_2D(tx + (i/2) + (16*j), ay);
             *Psptr += a.x * *xsptr++ + a.y * *xsptr;
         }
         __syncthreads();
 
 
         <span class="keywordtype">int</span> remain = (n - i) &amp; 31;
 
         <span class="keywordflow">if</span> ((2*tx) &lt; remain) {
             a = tex_2D(tx + (i/2) + (16*j), ay);
 
             *Psptr += a.x * *xsptr++;
         }
 
         <span class="keywordflow">if</span> ( (2*tx) + 1 &lt; remain)
         {
             *Psptr += a.y * *xsptr;
         }
 
         __syncthreads();
     }
 
     <span class="keywordflow">if</span> (tx &lt; 8) *Psptr += *(Psptr + 8);
     <span class="keywordflow">if</span> (tx &lt; 4) *Psptr += *(Psptr + 4);
     <span class="keywordflow">if</span> (tx &lt; 2) *Psptr += *(Psptr + 2);
     <span class="keywordflow">if</span> (tx &lt; 1) *Psptr += *(Psptr + 1);
 
     __syncthreads();
     <span class="keywordflow">if</span> (ty == 0 &amp;&amp; (16*bx) + tx &lt; m) y[(16*bx) + tx] = Ps[tx][0];
 }
</pre></div><p><a class="anchor" id="Functionmv_fujimoto"></a> </p>
<h4>Function: mv_fujimoto</h4>
<p>After all the kernels we finally have to define the wrapper function for the kernel call. Its task is to setup the size of the thread blocks and the size of the grid which depends on the dimensions of the matrix. Furthermore, it binds the texture, allocates the memory and copies the matrix and vectors to the device. after all this is done it starts the selected kernel and when it has finished copies the result back to the host. To accomodate for the original kernel we have to provide an auxiliary wrapper function which in the case float calls Fujimoto's kernel and in all other cases does nothing.</p>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">void</span> __do_FJ_orig(<span class="keywordtype">float</span>* d_y, cudaArray* d_A, <span class="keywordtype">float</span>* d_x, <span class="keywordtype">int</span> m, <span class="keywordtype">int</span> n, dim3 grid, dim3 threads)
 {
     _mv_fujimoto&lt;&lt;&lt; grid, threads &gt;&gt;&gt;(d_y, d_A, d_x, m, n);
 }
 
 <span class="keywordtype">void</span> __do_FJ_orig(<span class="keywordtype">double</span>* , cudaArray* , <span class="keywordtype">double</span>* , <span class="keywordtype">int</span> , <span class="keywordtype">int</span> , dim3 , dim3 )
 {
     printf(<span class="stringliteral">&quot;For double precision the original version of Fujimoto is not available!\n&quot;</span>);
 }
</pre></div><p>After these preparations we can define the generic wrapper function.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> Kernels&lt;T&gt;::mv_fujimoto(T *y, <span class="keyword">const</span> T *A, <span class="keyword">const</span> T *x, <span class="keyword">const</span> <span class="keywordtype">int</span> m, <span class="keyword">const</span> <span class="keywordtype">int</span> n,
                              <span class="keyword">const</span> <span class="keywordtype">int</span> n_repetitions,
                              <span class="keyword">const</span> <span class="keywordtype">int</span> fj_version,
                              <span class="keywordtype">double</span>&amp;  elapsed_time)
 {
</pre></div><p>To compute the number of blocks we have to divide the number of rows <code>m</code> by 16 and add 1, if (m mod 16) != 0. We keep the original version by Fujimoto as comment.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> blkNum = (m + 15)/16; <span class="comment">// (m &gt;&gt; 4) + ((m &amp; 15) ? 1 : 0);</span>
     <span class="keywordtype">int</span> height = blkNum*16; <span class="comment">// blkNum &lt;&lt; 4;</span>
</pre></div><p>For the width we have to do the same but with 16 replaced by 256.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordtype">int</span> width = 256*((n+255)/256); <span class="comment">// (n &amp; 255) ? (((n &gt;&gt; 8) + 1) &lt;&lt; 8) : n;</span>
</pre></div><p>Each row of a thread block deals with one row of the matrix.</p>
<div class="fragment"><pre class="fragment">     dim3 threads(16, 16);
</pre></div><p>Therefore, we need a one-dimensional grid of thread blocks which is large enough so that all rows of the matrix are covered.</p>
<div class="fragment"><pre class="fragment">     dim3 grid(blkNum, 1);
</pre></div><p>The crucial idea of Fujimoto is to read the matrix via the texture cache. To do this, the matrix must be stored in a cudaArray.</p>
<div class="fragment"><pre class="fragment">     cudaArray *d_A;
     T *d_x, *d_y;
</pre></div><p>In contrast to Fujimoto we do not pass the type of the texture element directly to the channel description but ask the TexEl structure for it. The original version is kept in a comment.</p>
<div class="fragment"><pre class="fragment">     cudaChannelFormatDesc
             channelDesc = cudaCreateChannelDesc&lt;typename TexEl&lt;T&gt;::texel_type/ *float4* /&gt;();
</pre></div><p>In case of float we can store the matrix entries as float4. Therefore, the width of the cudaArray is only <code>width/4</code>. For double precision we store 2 doubles as one int4 which requires twice as much texels per row. Thus, the width of the cudaArray is <code>width/2</code>. To select these numbers automatically we use the static constant <code>tex_stride</code> from the TeXEl structure.</p>
<div class="fragment"><pre class="fragment">     cudaMallocArray(&amp;d_A, &amp;channelDesc, width/TexEl&lt;T&gt;::tex_stride, height);
 
     <span class="keywordtype">size_t</span> size_of_T = <span class="keyword">sizeof</span>(T);
 
     cudaMemcpy2DToArray(d_A, 0, 0, A,
                         n * size_of_T,
                         n * size_of_T,
                         m,
                         cudaMemcpyHostToDevice);
</pre></div><p>The reference to the texture is created at runtime. Depending on the number type we either bind the float4 or int4 texture.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span> (IsFloat&lt;T&gt;::value)
         cudaBindTextureToArray(fTexRefA, d_A);
     <span class="keywordflow">else</span>
         cudaBindTextureToArray(dTexRefA, d_A);
 
     cudaMalloc((<span class="keywordtype">void</span> **) &amp;d_x, n * size_of_T );
     cudaMalloc((<span class="keywordtype">void</span> **) &amp;d_y, m * size_of_T );
 
     cudaMemcpy(d_x, x, n * size_of_T, cudaMemcpyHostToDevice);
</pre></div><p>Although the final values of matrix-vector product are assigned to <code>d_y</code> the result is only correct if we initialize <code>d_y</code> with zeros. To do this, we copy for each run the vector from the host to the device.</p>
<div class="fragment"><pre class="fragment"><span class="preprocessor"> #ifndef DONT_USE_CUDATIMER</span>
<span class="preprocessor"></span>     CUDATimer timer;
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;n_repetitions; i++)
     {
         cudaMemcpy(d_y, y, m * size_of_T, cudaMemcpyHostToDevice);
         <span class="keywordflow">switch</span> (fj_version) {
         <span class="keywordflow">case</span> 0:
             __do_FJ_orig(d_y, d_A, d_x, m, n, grid, threads);
             <span class="keywordflow">break</span>;
         <span class="keywordflow">case</span> 1:
             _mv_fujimoto_T&lt;&lt;&lt; grid, threads &gt;&gt;&gt;(d_y, d_A, d_x, m, n);
             <span class="keywordflow">break</span>;
         <span class="keywordflow">case</span> 2:
             _mv_fujimoto_T2&lt;&lt;&lt; grid, threads &gt;&gt;&gt;(d_y, d_A, d_x, m, n);
             <span class="keywordflow">break</span>;
         <span class="keywordflow">case</span> 3:
             _mv_fujimoto_T3&lt;&lt;&lt; grid, threads &gt;&gt;&gt;(d_y, d_A, d_x, m, n);
             <span class="keywordflow">break</span>;
         <span class="keywordflow">default</span>:
             <span class="keywordflow">break</span>;
         }
     }
     cudaThreadSynchronize();
<span class="preprocessor"> #ifndef DONT_USE_CUDATIMER</span>
<span class="preprocessor"></span>     timer.stop();
     elapsed_time = timer.elapsed() ;
<span class="preprocessor"> #else</span>
<span class="preprocessor"></span>     elapsed_time = 3.1415926;
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span><span class="preprocessor"> #ifdef DEBUG</span>
<span class="preprocessor"></span><span class="preprocessor"> #ifndef DONT_USE_CUDATIMER</span>
<span class="preprocessor"></span>     timer.print_elapsed(<span class="stringliteral">&quot;Time spent in Fujimotos MV product:&quot;</span>);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"> #endif</span>
</pre></div><p>After the matrix-vector products are done we copy the result back to the host and clean up.</p>
<div class="fragment"><pre class="fragment">     cudaMemcpy(y, d_y, m * size_of_T, cudaMemcpyDeviceToHost);
 
     cudaFree(d_y);
     cudaFree(d_x);
</pre></div><p>Depending on which texture we have bound we have to selectively unbind.</p>
<div class="fragment"><pre class="fragment">     <span class="keywordflow">if</span>(IsFloat&lt;T&gt;::value)
         cudaUnbindTexture( fTexRefA);
     <span class="keywordflow">else</span>
         cudaUnbindTexture( dTexRefA);
     cudaFreeArray(d_A);
 }
</pre></div><p>This 2-liner provides all possible template specializations for real-valued matrices and finally explains why we enclosed the wrapper functions in a structure.</p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> <span class="keyword">class </span>Kernels&lt;float&gt;;
 <span class="keyword">template</span> <span class="keyword">class </span>Kernels&lt;double&gt;;
 
 } <span class="comment">// namespace step2 END</span>
</pre></div><p> <a class="anchor" id="Results"></a></p>
<h1>Results</h1>
<p>Before we show the results, we want to describe briefly how to use the program.  </p>
<p>The easiest way is to load the step-2.pro into QtCreator and hit the play button. The program is then executed with its default parameters.  </p>
<p>The execution path and arguments which are passed to the executable can be changed in the project settings in QTCreator (in this case the only valid argument is the location of the parameter file). It may also be necessary to change the LD_LIBRARY_PATH such that all necessary libraries are found. </p>
<div class="image"><div class="image">
<img src="qt_config.png"  alt="qt_config.png" width=" 700"/>
</div>
<div class="caption"> Screen shot of the project settings window in QtCreator. You should uncheck "Run in Terminal", because it frequently causes problems.</div></div><div style="display: none;"><div class="image">
<img src="qt_config.png" alt="qt_config.png"/>
</div>
<p> "" </div>   <p>The results of the different tests are provided in the following plots. The first depicts runtime measurements obtained on a Tesla K20c GPU and a Dell T7500 workstation with two X5675 Xeons each with 6 cores. From this raw data we compute the speedups of the GPU-based methods over the CPU reference implementation provided by ATLAS. Then, we compare the different Fujimoto variants with each other and last but not least show the memory bandwidth achieved by CUBLAS and the different Fujimoto versions. </p>
<div class="image"><div class="image">
<img src="runtimes_150ppi.png"  alt="runtimes_150ppi.png" width=" 700"/>
</div>
<div class="caption"> Runtimes for Fujimoto, ATLAS and CUBLAS matrix-vector products. In contrast to ATLAS the CUDA-based methods display a considerable startup overhead as for small matrix sizes the runtime is almost constant.</div></div><div style="display: none;"><div class="image">
<img src="runtimes_150ppi.png" alt="runtimes_150ppi.png"/>
</div>
<p> "" </div> <div class="image"><div class="image">
<img src="speedup-logplot_150ppi.png"  alt="speedup-logplot_150ppi.png" width=" 700"/>
</div>
<div class="caption"> Speedup of Fujimoto and CUBLAS over ATLAS. For sufficiently large matrices the GPU is saturated and the speedup becomes constant as expected.</div></div><div style="display: none;"><div class="image">
<img src="speedup-logplot_150ppi.png" alt="speedup-logplot_150ppi.png"/>
</div>
<p> "" </div> <div class="image"><div class="image">
<img src="speedup-FJ-bitshift_150ppi.png"  alt="speedup-FJ-bitshift_150ppi.png" width=" 700"/>
</div>
<div class="caption"> Comparison of Fujimotos original kernel with bitshifts against the float version of the generic implementation without bitshifts. Values larger 1 favor the bitshift version by Fujimoto whereas values less than 1 indicate that bitshifting does not pay off. Due to the large scattering there is no clear winner. </div></div><div style="display: none;"><div class="image">
<img src="speedup-FJ-bitshift_150ppi.png" alt="speedup-FJ-bitshift_150ppi.png"/>
</div>
<p> "" </div> <div class="image"><div class="image">
<img src="speedup-FJ-double-opt_150ppi.png"  alt="speedup-FJ-double-opt_150ppi.png" width=" 700"/>
</div>
<div class="caption"> Unlike bitshifting the optimization of the texture fetches for double precision does pay off which is indicated by values larger than 1.</div></div><div style="display: none;"><div class="image">
<img src="speedup-FJ-double-opt_150ppi.png" alt="speedup-FJ-double-opt_150ppi.png"/>
</div>
<p> "" </div> <div class="image"><div class="image">
<img src="speedup-logplot-FJ-vs-CUBLAS_150ppi.png"  alt="speedup-logplot-FJ-vs-CUBLAS_150ppi.png" width=" 700"/>
</div>
<div class="caption"> As in 2008 Fujimoto's kernel is faster than the gemv function from CUBLAS which now is indicated by values less than 1. For large matrices Fujimoto needs approximately only half the time as CUBLAS. Our extension to double precision shares this feature although not that prominent but there is still a gain of 20-30% over CUBLAS.</div></div><div style="display: none;"><div class="image">
<img src="speedup-logplot-FJ-vs-CUBLAS_150ppi.png" alt="speedup-logplot-FJ-vs-CUBLAS_150ppi.png"/>
</div>
<p> "" </div> <div class="image"><div class="image">
<img src="bandwidths_150ppi.png"  alt="bandwidths_150ppi.png" width=" 700"/>
</div>
<div class="caption"> Estimated memory bandwidth for different Fujimoto variants and CUBLAS for single and double precision. To compute the bandwidth we divide the memory consumed by the matrix by the runtime. For small matrices this is a bit conservative because the vectors are not yet negligible. These numbers are also more conservative as the results one obtains with NVVP. </div></div><div style="display: none;"><div class="image">
<img src="bandwidths_150ppi.png" alt="bandwidths_150ppi.png"/>
</div>
<p> "" </div> <p><a class="anchor" id="Plots"></a></p>
<h3>Plots</h3>
<p>After the performance tests have been completed, the results are stored in the file <em>MVTest_results.out</em>. During execution a gnuplot script in the <code>plot</code> subdirectory is generated and produces the corresponding plots. <br/>
</p>
<p><br/>
 The parameters used to generate the plots above are listed in the following lines:  </p>
<pre>
# Listing of Parameters
# ---------------------</pre><pre>subsection Dimensions of test problems.
  # Binary logarithm of minimal number of columns of upper triangular matrix
  # R. Allowed range : [3,15]
  set log2(max n cols)   = 13.001</pre><pre>  # Binary logarithm of minimal number of columns of upper triangular matrix
  # R. Allowed range : [2,15]
  set log2(min n cols)   = 3</pre><pre>  # Perform the test for this many randomly chosen matrix sizes.If the value
  # given is 0, then a list of matrix sizes is used which is generated
  # deterministically from the growth strategy.
  set n random trials    = 0</pre><pre>  # Repeat the test for a given matrix size this many times.
  set n repetitions      = 20</pre><pre>  # In each test instance the number of rows of R is increased by this factor.
  # Allowed range : [1.1,10]
  set n rows growth rate = 1.12517
end</pre><pre>subsection Global parameters
  # CPU-BLAS and CUBLAS double.
  set Run CPU-BLAS vs CUBLAS double   = false</pre><pre>  # CPU-BLAS and CUBLAS float.
  set Run CPU-BLAS vs CUBLAS float    = false</pre><pre>  # CPU-BLAS and Fujimoto double.
  set Run CPU-BLAS vs Fujimoto double = false</pre><pre>  # CPU-BLAS and Fujimoto float.
  set Run CPU-BLAS vs Fujimoto float  = false</pre><pre>  # Fujimoto and CUBLAS double.
  set Run Fujimoto vs CUBLAS double   = true</pre><pre>  # Fujimoto and CUBLAS float.
  set Run Fujimoto vs CUBLAS float    = false</pre><pre>end</pre><pre>subsection Fujimoto parameters</pre><pre>  # In case of float the &lt;generic&gt; version is a verbatim copy
  # of the original version. In case of double the reading of the matrix
  # induces 50% idle threads. &lt;no bitshift&gt;=""&gt; is identical to the generic version
  # except that index arithmetic is done in a more human readable fashion.
  # &lt;double optimization&gt;=""&gt; provides optimized access to the matrix entries
  # in the case of double precision.
  # possible values : generic|no bitshift|double optimization
  set Fujimoto variant = generic #original #|double optimization</pre><pre>end</pre><pre>subsection Simulation basics
  # Specify a directory results of the test are to be stored. This can be
  # either an absolute path or path relative to the directory where the
  # program has been started. The default is subdir called test_me-&lt;date&gt;
  # where &lt;date&gt; will be replaced by the date at which the program has been
  # started. this simplifies keeping the projects directory clean
  set Run directory = ../step-2/reference-results/Thu-25-04-2013-FJ-generic-vs-CUBLAS-double-max_8192x8192</pre><pre>end</pre><pre>subsection Device flags
  # This allows to dedicate the local L1 caches completely to buffering
  # register spilling effects.
  set Disable L1 caching for global memory = false</pre><pre>  # This allows to rather use 48 KB as L1 cache.
  set Maximize L1 cache                    = false</pre><pre>  # This allows to access the matrix via texture and not by direct memory
  # accesses. On older hardware textures can exploit the 2D locality of matrix
  # entries. On Fermi- or Kepler-based GPUs this should not make much sense.
  set Wrap matrix into texture             = true
end
</pre><p><a class="anchor" id="PlainProg"></a> </p>
<h1>The plain program</h1>
<p>(If you are looking at a locally installed CUDA HPC Praktikum version, then the program can be found at <em> .. /.. /testsite / /step-2 /step-cu.cc </em>. Otherwise, this is only the path on some remote server.) </p>
<div class="fragment"><pre class="fragment"> / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #include &lt;step-2/step-2.hh&gt;</span>
</pre></div><p> <a class="anchor" id="plain-Functionmain"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> *argv[])
 {
     step2::MyFancySimulation sim(argc, argv);
 
     sim.run();
 }
 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef STEP_2_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define STEP_2_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #include &lt;cstdio&gt;</span>
<span class="preprocessor"> #include &lt;vector&gt;</span>
 
<span class="preprocessor"> #include &lt;deal.II/base/convergence_table.h&gt;</span>
 
<span class="preprocessor"> #include &lt;cuda_runtime.h&gt;</span>
<span class="preprocessor"> #include &lt;../SciPAL/include/base/GPUInfo.h&gt;</span>
 
<span class="preprocessor"> #include &lt;QString&gt;</span>
 
<span class="preprocessor"> #include &lt;step-2/MVTest.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/MVTest.hh&gt;</span>
 
<span class="preprocessor"> #include &lt;step-2/MVTestUIParams.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p> <a class="anchor" id="plain-ClassMyFancySimulation"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">class </span>MyFancySimulation {
 
 <span class="keyword">public</span>:
    MyFancySimulation(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> *argv[]);
 
    <span class="keyword">virtual</span> <span class="keywordtype">void</span> run();
 
 <span class="keyword">protected</span>:
     <span class="keyword">virtual</span> <span class="keywordtype">void</span> save_results();
 
 
     dealii::ConvergenceTable results_table;
 
     MVTestUIParams params;
 
     SciPAL::GPUInfo gpu_info;
 
     QString launch_dir;
 
     QString prm_dir;
 
     QString prm_log_dir;
 };
 
 }
</pre></div><p> <a class="anchor" id="plain-ConstructorMyFancySimulation"></a> </p>
<div class="fragment"><pre class="fragment"> step2::MyFancySimulation::MyFancySimulation(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> *argv[])
 {
     cudaGetDeviceCount(&amp;gpu_info.n_CUDA_devices);
     std::cout
             &lt;&lt; <span class="stringliteral">&quot;N available CUDA devices : &quot;</span>
             &lt;&lt; gpu_info.n_CUDA_devices &lt;&lt; std::endl;
 
     gpu_info.get();
 
     dealii::ParameterHandler prm_handler;
 
     MVTestUIParams::declare(prm_handler);
 
      QDir cwd = QDir::current();
      cwd.makeAbsolute();
 
    this-&gt;launch_dir = cwd.absolutePath();
 
     std::string prm_filename;
 
     <span class="keywordflow">if</span> (argc == 1)
     {
         QFileInfo tmp(argv[0]);
         this-&gt;prm_dir = tmp.absolutePath() + <span class="stringliteral">&quot;/prm&quot;</span>;
         prm_filename  = tmp.fileName().toStdString();
         prm_filename += <span class="stringliteral">&quot;.prm&quot;</span>;
     }
     <span class="keywordflow">else</span>
     {
         std::cout &lt;&lt; <span class="stringliteral">&quot;Given parameter file : &quot;</span> &lt;&lt; argv[1] &lt;&lt; std::endl;
 
         QFileInfo tmp(argv[1]);
 
         <span class="keywordflow">if</span>(!tmp.exists())
         {
             std::cerr &lt;&lt; <span class="stringliteral">&quot;The following parameter file does not exist:\n&quot;</span>
                       &lt;&lt; argv[1] &lt;&lt; std::endl;
 
             qFatal(<span class="stringliteral">&quot;Cannot proceed without proper path to parameter file&quot;</span>);
         }
 
         this-&gt;prm_dir = tmp.absolutePath();
 
         prm_filename = tmp.fileName().toStdString();
 
         std::cout &lt;&lt; <span class="stringliteral">&quot;xx Parameter file path : &quot;</span>
                   &lt;&lt; tmp.absolutePath().toStdString().c_str()
                   &lt;&lt; std::endl;
     }
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;Parameter file : &quot;</span> &lt;&lt; prm_filename  &lt;&lt; std::endl;
 
     cwd.mkpath(this-&gt;prm_dir);
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;step-2: prm path : &quot;</span> &lt;&lt; this-&gt;prm_dir.toStdString().c_str()  &lt;&lt; std::endl;
 
     QDir::setCurrent(this-&gt;prm_dir);
 
     prm_handler.read_input (prm_filename);
 
     this-&gt;params.get(prm_handler);
 
     QDir::setCurrent(this-&gt;launch_dir);
     cwd.mkpath(this-&gt;params.run_dir);
     QDir::setCurrent(this-&gt;params.run_dir);
     cwd = QDir::current();
     this-&gt;params.run_dir = cwd.absolutePath();
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;Entering run dir : &quot;</span> &lt;&lt; this-&gt;params.run_dir.toStdString().c_str()  &lt;&lt; std::endl;
 
 
 
     this-&gt;prm_log_dir = this-&gt;params.run_dir + <span class="stringliteral">&quot;/log&quot;</span>;
     cwd.mkpath(this-&gt;prm_log_dir);
 
 
 
     QDir::setCurrent(this-&gt;prm_log_dir);
 
     std::ofstream log_out_text( (prm_filename +<span class="stringliteral">&quot;.log&quot;</span> ).c_str() );
     prm_handler.print_parameters (log_out_text,
                                   dealii::ParameterHandler::Text);
 
     assert(QDir::setCurrent(this-&gt;params.run_dir ) );
 
     <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; this-&gt;params.matrix_sizes.size(); i++)
     {
         this-&gt;results_table.add_value(<span class="stringliteral">&quot;rows&quot;</span>,  (<span class="keywordtype">int</span>) this-&gt;params.matrix_sizes[i].first);
         this-&gt;results_table.add_value(<span class="stringliteral">&quot;columns&quot;</span>, (<span class="keywordtype">int</span>) this-&gt;params.matrix_sizes[i].second);
     }
 }
</pre></div><p> <a class="anchor" id="plain-Functionrun"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">void</span> step2::MyFancySimulation::run()
 {
     <span class="keyword">const</span> std::vector&lt;MVCase&gt; &amp; float_tests  = this-&gt;params.float_tests;
     <span class="keyword">const</span> std::vector&lt;MVCase&gt; &amp; double_tests = this-&gt;params.double_tests;
 
     <span class="keyword">const</span> std::map&lt;MVCase, int&gt; &amp; float_vs  = this-&gt;params.float_vs;
     <span class="keyword">const</span> std::map&lt;MVCase, int&gt; &amp; double_vs = this-&gt;params.double_vs;
 
     QString gpplots_runtimes;
 
     QString gpplots_speedup;
 
     QString gnuplot
             =
             <span class="stringliteral">&quot;set term postscript landscape enhanced color solid &quot;</span>
             <span class="stringliteral">&quot; linewidth 2.0 \&quot;Helvetica\&quot; 20\n&quot;</span>
             <span class="stringliteral">&quot;set xlabel \&quot;matrix entries\&quot;\n&quot;</span>
             <span class="stringliteral">&quot;set ylabel \&quot;execution time\&quot;\n&quot;</span>
             <span class="stringliteral">&quot;set logscale xy\n&quot;</span>
             <span class="stringliteral">&quot;set grid\n&quot;</span>
             <span class="stringliteral">&quot;set output \&quot;runtimes.ps\&quot;\n&quot;</span>
             <span class="stringliteral">&quot;set key inside left Left box lw 0.5\n&quot;</span>;
 
     gnuplot += <span class="stringliteral">&quot;plot &quot;</span>;
 
     std::vector&lt;MVCase&gt;::const_iterator
             t = float_tests.begin(),
             end_t = float_tests.end();
 
     <span class="keywordtype">int</span> col = 3;
 
     <span class="keywordflow">for</span> (; t != end_t; ++t)
     {
         MVTest&lt;float&gt; mv_test(this-&gt;params, results_table, *t);
         <span class="keywordflow">if</span>(col &gt; 3) gpplots_runtimes += <span class="stringliteral">&quot;,&quot;</span>;
         gpplots_runtimes += QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):&quot;</span>)
                 + QString::number(col++)
                 + QString(<span class="stringliteral">&quot; title \&quot;&quot;</span>) + mv_test.run() + QString(<span class="stringliteral">&quot;\&quot; w p&quot;</span>);
     }
 
     t = double_tests.begin(), end_t = double_tests.end();
 
     <span class="keywordflow">for</span> (; t != end_t; ++t)
     {
         MVTest&lt;double&gt; mv_test(this-&gt;params, results_table, *t);
         <span class="keywordflow">if</span>(col &gt; 3) gpplots_runtimes += <span class="stringliteral">&quot;,&quot;</span>;
         gpplots_runtimes += QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):&quot;</span>)
                 +
                 QString::number(col++)
                 +
                 QString(<span class="stringliteral">&quot; title \&quot;&quot;</span>) + mv_test.run() + QString(<span class="stringliteral">&quot;\&quot; w p&quot;</span>);
     }
 
     gnuplot += gpplots_runtimes;
 
     gnuplot +=
             <span class="stringliteral">&quot;\nset ylabel \&quot;speedup\&quot;\n&quot;</span>
             <span class="stringliteral">&quot;set output \&quot;speedup.ps\&quot;\n&quot;</span>
             <span class="stringliteral">&quot;set key inside left Left\n&quot;</span>;
 
     gnuplot += <span class="stringliteral">&quot;unset logscale y\n&quot;</span>;
 
     gnuplot += <span class="stringliteral">&quot;plot&quot;</span>;
 
     <span class="keywordtype">int</span> offset = 3 + this-&gt;params.float_vs.size();
 
     <span class="keywordflow">if</span>(this-&gt;params.run_cpublas_vs_cublas_float)
         gpplots_speedup += ((gpplots_speedup.isEmpty()) ? QString(<span class="stringliteral">&quot;&quot;</span>) : QString(<span class="stringliteral">&quot;, &quot;</span>))
                 + QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):(%1 / %2)&quot;</span>)
                 .arg(float_vs.at(atlas_mv) + 3).arg(float_vs.at(cublas_mv) + 3)
                 + QString(<span class="stringliteral">&quot; title \&quot;CPU BLAS vs CUBLAS (float)\&quot; w p&quot;</span>);
 
     <span class="keywordflow">if</span>(this-&gt;params.run_cpublas_vs_cublas_double)
         gpplots_speedup += ((gpplots_speedup.isEmpty()) ? QString(<span class="stringliteral">&quot;&quot;</span>) : QString(<span class="stringliteral">&quot;, &quot;</span>))
                 + QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):(%1 / %2)&quot;</span>)
                 .arg(double_vs.at(atlas_mv) + offset).arg(double_vs.at(cublas_mv) + offset)
                 + QString(<span class="stringliteral">&quot; title \&quot;CPU BLAS vs CUBLAS (double)\&quot; w p&quot;</span>);
 
     <span class="keywordflow">if</span>(this-&gt;params.run_cpublas_vs_Fujimoto_float)
         gpplots_speedup += ((gpplots_speedup.isEmpty()) ? QString(<span class="stringliteral">&quot;&quot;</span>) : QString(<span class="stringliteral">&quot;, &quot;</span>))
                 + QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):(%1 / %2)&quot;</span>)
                 .arg(float_vs.at(atlas_mv) + 3).arg(float_vs.at(Fujimoto_mv) + 3)
                 + QString(<span class="stringliteral">&quot; title \&quot;CPU BLAS vs Fujimoto (float)\&quot; w p&quot;</span>);
 
     <span class="keywordflow">if</span>(this-&gt;params.run_cpublas_vs_Fujimoto_double)
         gpplots_speedup += ((gpplots_speedup.isEmpty()) ? QString(<span class="stringliteral">&quot;&quot;</span>) : QString(<span class="stringliteral">&quot;, &quot;</span>))
                 + QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):(%1 / %2)&quot;</span>)
                 .arg(double_vs.at(atlas_mv) + offset).arg(double_vs.at(Fujimoto_mv) + offset)
                 + QString(<span class="stringliteral">&quot; title \&quot;CPU BLAS vs Fujimoto (double)\&quot; w p&quot;</span>);
 
     <span class="keywordflow">if</span>(this-&gt;params.run_Fujimoto_vs_cublas_float)
         gpplots_speedup += ((gpplots_speedup.isEmpty()) ? QString(<span class="stringliteral">&quot;&quot;</span>) : QString(<span class="stringliteral">&quot;, &quot;</span>))
                 + QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):(%1 / %2)&quot;</span>)
                 .arg(float_vs.at(Fujimoto_mv) + 3).arg(float_vs.at(cublas_mv) + 3)
                 + QString(<span class="stringliteral">&quot; title \&quot;Fujimoto vs CUBLAS (float)\&quot; w p&quot;</span>);
 
     <span class="keywordflow">if</span>(this-&gt;params.run_Fujimoto_vs_cublas_double)
         gpplots_speedup += ((gpplots_speedup.isEmpty()) ? QString(<span class="stringliteral">&quot;&quot;</span>) : QString(<span class="stringliteral">&quot;, &quot;</span>))
                 + QString(<span class="stringliteral">&quot;\&quot;../MVTest_results.out\&quot; using (1*2):(%1 / %2)&quot;</span>)
                 .arg(double_vs.at(Fujimoto_mv) + offset).arg(double_vs.at(cublas_mv) + offset)
                 + QString(<span class="stringliteral">&quot; title \&quot;Fujimoto vs CUBLAS (double)\&quot; w p&quot;</span>);
 
     gnuplot += gpplots_speedup;
 
     gnuplot += <span class="stringliteral">&quot;\n!ps2pdf runtimes.ps runtimes.pdf&quot;</span>;
     gnuplot += <span class="stringliteral">&quot;\n!rm runtimes.ps&quot;</span>;
     gnuplot += <span class="stringliteral">&quot;\n!ps2pdf speedup.ps speedup.pdf&quot;</span>;
     gnuplot += <span class="stringliteral">&quot;\n!rm speedup.ps&quot;</span>;
 
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;Results are processed and saved.\n&quot;</span>;
 
     this-&gt;save_results();
 
      QDir cwd = QDir::current();
      QString plot_dir = this-&gt;params.run_dir + <span class="stringliteral">&quot;/plot&quot;</span>;
              cwd.mkpath(<span class="stringliteral">&quot;./plot&quot;</span>);
 
      QDir::setCurrent(plot_dir);
 
 
     QFile plotscript(<span class="stringliteral">&quot;plot.gp&quot;</span>);
 
     <span class="keywordtype">bool</span> success = plotscript.open(QIODevice::WriteOnly);
     <span class="keywordflow">if</span> (!success)
         std::cerr &lt;&lt; <span class="stringliteral">&quot;Opening gnuplot file failed!&quot;</span> &lt;&lt; std::endl;
 
     plotscript.write(gnuplot.toStdString().c_str());
 
     plotscript.close();
 
     <span class="keywordflow">if</span> (! plotscript.exists() )
         std::cerr &lt;&lt; <span class="stringliteral">&quot;Writing gnuplot file failed!&quot;</span> &lt;&lt; std::endl;
 
 
     FILE *gp = popen(<span class="stringliteral">&quot;gnuplot -persist&quot;</span>, <span class="stringliteral">&quot;w&quot;</span>);
     fprintf(gp, <span class="stringliteral">&quot;load \&quot;plot.gp\&quot;\n&quot;</span>);
     fflush(gp);
     pclose(gp);
 
 
     QDir::setCurrent(this-&gt;params.run_dir);
 
     std::cout &lt;&lt; <span class="stringliteral">&quot;Finished.&quot;</span> &lt;&lt; std::endl;
 }
</pre></div><p> <a class="anchor" id="plain-Functionsave_results"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">void</span> step2::MyFancySimulation::save_results()
 {
     std::string filename(<span class="stringliteral">&quot;MVTest_results&quot;</span>);
 
     filename += <span class="stringliteral">&quot;.out&quot;</span>;
 
     std::ofstream out(filename.c_str());
 
     out &lt;&lt; <span class="stringliteral">&quot;# max n_cols  : &quot;</span> &lt;&lt; this-&gt;params.max_n_cols &lt;&lt; std::endl
         &lt;&lt; <span class="stringliteral">&quot;# min n_cols  : &quot;</span> &lt;&lt; this-&gt;params.min_n_cols &lt;&lt; std::endl
         &lt;&lt; <span class="stringliteral">&quot;# growth rate : &quot;</span> &lt;&lt; this-&gt;params.n_rows_growth_rate &lt;&lt; std::endl
         &lt;&lt; std::endl;
 
     results_table.write_text(out);
 }
 
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef SimUIParams_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define SimUIParams_H</span>
<span class="preprocessor"></span> 
 
<span class="preprocessor"> #include &lt;QString&gt;</span>
<span class="preprocessor"> #include &lt;deal.II/base/parameter_handler.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p> <a class="anchor" id="plain-EnumMVCase"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">enum</span> MVCase { Fujimoto_mv, atlas_mv, cublas_mv, none / * <span class="keywordflow">for</span> future use : , openmp_mv, ...* / };
</pre></div><p> <a class="anchor" id="plain-structSimUIParams"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">struct </span>SimUIParams {
 
     SimUIParams() {}
 
     <span class="keyword">static</span> <span class="keywordtype">void</span> declare(dealii::ParameterHandler &amp; prm);
 
     <span class="keywordtype">void</span> <span class="keyword">get</span>(dealii::ParameterHandler &amp; prm);
 
     <span class="keywordtype">bool</span>
     run_cpublas_vs_cublas_float,
     run_cpublas_vs_cublas_double,
     run_cpublas_vs_Fujimoto_float,
     run_cpublas_vs_Fujimoto_double,
     run_Fujimoto_vs_cublas_float,
     run_Fujimoto_vs_cublas_double;
 
     <span class="keywordtype">int</span> fj_version;
 
     QString run_dir;
 
     std::vector&lt;MVCase&gt; float_tests, double_tests;
     std::map&lt;MVCase, int&gt; float_vs, double_vs;
 
 <span class="keyword">private</span>:
     SimUIParams (<span class="keyword">const</span> SimUIParams &amp; / *other* /) {}
 
     SimUIParams &amp; operator = (<span class="keyword">const</span> SimUIParams &amp; / *other* /) { <span class="keywordflow">return</span> *<span class="keyword">this</span>; }
 };
 
 }
<span class="preprocessor"> #endif // SimUIParams_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef MVTESTUIPARAMS_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define MVTESTUIPARAMS_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;step-2/SimUIParams.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/DeviceParams.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/MVMultDriverInterface.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p> <a class="anchor" id="plain-ClassTestUIParamsBase"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">struct </span>TestUIParamsBase {
 
     TestUIParamsBase() {}
 
     <span class="keyword">static</span> <span class="keywordtype">void</span> declare(dealii::ParameterHandler &amp; prm);
 
     <span class="keywordtype">void</span> <span class="keyword">get</span>(dealii::ParameterHandler &amp; prm);
 
     <span class="keywordtype">int</span>  min_n_cols;
     <span class="keywordtype">int</span>  max_n_cols;
 
     <span class="keywordtype">double</span> n_rows_growth_rate;
 
     <span class="keywordtype">int</span> n_repetitions;
 
 
 <span class="keyword">private</span>:
     TestUIParamsBase(<span class="keyword">const</span> TestUIParamsBase &amp; ) {}
 
     TestUIParamsBase &amp; operator = (<span class="keyword">const</span> TestUIParamsBase &amp; / *other* /)
     {
         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
     }
 };
</pre></div><p> <a class="anchor" id="plain-ClassMVTestUIParams"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">struct </span>MVTestUIParams
         :
         <span class="keyword">public</span> SimUIParams,
         <span class="keyword">public</span> DeviceParams,
         <span class="keyword">public</span> TestUIParamsBase
 {
     MVTestUIParams()
         :
           SimUIParams(),
           DeviceParams(),
           TestUIParamsBase()
     {}
 
     <span class="keyword">static</span> <span class="keywordtype">void</span> declare(dealii::ParameterHandler &amp; prm);
 
     <span class="keywordtype">void</span> <span class="keyword">get</span>(dealii::ParameterHandler &amp; prm);
 
 
     <span class="keywordtype">int</span> n_random_trials;
 
     std::vector&lt;step2::matrixSize&gt; matrix_sizes;
 
 <span class="keyword">protected</span>:
     <span class="keywordtype">void</span> create_random_matrix_sizes();
     <span class="keywordtype">void</span> create_regular_matrix_sizes();
 
 <span class="keyword">private</span>:
     MVTestUIParams (<span class="keyword">const</span> MVTestUIParams &amp; / *other* /)
         :
           SimUIParams(),
           DeviceParams(),
           TestUIParamsBase()
     {}
 
     MVTestUIParams &amp; operator = (<span class="keyword">const</span> MVTestUIParams &amp; / *other* /)
     {
         <span class="keywordflow">return</span> *<span class="keyword">this</span>;
     }
 };
 
 }
<span class="preprocessor"> #endif // MVTESTUIPARAMS_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef MVTEST_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define MVTEST_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;QDir&gt;</span>
<span class="preprocessor"> #include &lt;step-2/Fujimoto_driver_step-2.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/cuda_driver_step-2.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/CpuBlas_driver_step-2.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/MVTestUIParams.h&gt;</span>
 
<span class="preprocessor"> #include &lt;deal.II/base/convergence_table.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p> <a class="anchor" id="plain-ClassMVTest"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">class </span>MVTest {
 
 <span class="keyword">public</span>:
     typedef ::FullMatrixAccessor&lt;T&gt; FullMatrixAccessor;
 
     MVTest(<span class="keyword">const</span> MVTestUIParams &amp; p,
            dealii::ConvergenceTable &amp; results_table,
            MVCase variant=atlas_mv);
 
     ~MVTest();
 
     <span class="keyword">virtual</span> QString run();
 
 
 <span class="keyword">protected</span>:
     <span class="keyword">typename</span> step2::MVMultDriverInterface&lt;T&gt; * driver_m;
 
     <span class="keyword">virtual</span> <span class="keywordtype">void</span> setup_and_assemble(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> nr,
                                     <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> nc);
 
     <span class="keyword">const</span> MVTestUIParams * params;
 
     FullMatrixAccessor A;
 
     dealii::Vector&lt;T&gt; x_orig, y_orig;
 
     std::string col_head;
 
     dealii::ConvergenceTable &amp; results_table;
 };
 }
<span class="preprocessor"> #endif // MVTEST_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef MVTEST_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define MVTEST_HH</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;step-2/MVTest.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/PrecisionName.h&gt;</span>
<span class="preprocessor"> #include &lt;deal.II/base/convergence_table.h&gt;</span>
</pre></div><p> <a class="anchor" id="plain-Constructor"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;
 step2::MVTest&lt;T&gt;::MVTest(<span class="keyword">const</span> step2::MVTestUIParams &amp; p,
                          dealii::ConvergenceTable &amp;rt,
                          MVCase mv_variant)
     :
       params(&amp;p),
       results_table(rt)
 {
     driver_m = NULL;
 
     <span class="keywordflow">switch</span> (mv_variant) {
 
     <span class="keywordflow">case</span> Fujimoto_mv:
         driver_m = <span class="keyword">new</span> FujimotoDriver&lt;T,cublas&gt; (this-&gt;params-&gt;fj_version);
         col_head = <span class="stringliteral">&quot;Fujimoto &quot;</span> + QString::number(this-&gt;params-&gt;fj_version).toStdString();
         <span class="keywordflow">break</span>;
     <span class="keywordflow">case</span> cublas_mv:
         driver_m = <span class="keyword">new</span> CUBlasDriver&lt;T,cublas&gt; ();
         col_head  = <span class="stringliteral">&quot;CUBLAS&quot;</span>;
         <span class="keywordflow">break</span>;
     <span class="keywordflow">case</span> atlas_mv:
         driver_m = <span class="keyword">new</span> step2::CpuBlasDriver&lt;T,blas&gt; ();
         col_head  = <span class="stringliteral">&quot;CPU Blas&quot;</span>;
         <span class="keywordflow">break</span>;
     <span class="keywordflow">default</span>: <span class="comment">// do nothing</span>
         <span class="keywordflow">break</span>;
     }
 
     <span class="keywordflow">if</span> (mv_variant != none)
     {
         assert(driver_m);
 
         col_head += <span class="stringliteral">&quot; &quot;</span> + PrecisionName&lt;T&gt;::name();
 
         std::cerr &lt;&lt; <span class="stringliteral">&quot;\nTesting &quot;</span> &lt;&lt; col_head.c_str() &lt;&lt; <span class="stringliteral">&quot; mvmult &quot;</span>
                   &lt;&lt; std::endl;
     }
 }
</pre></div><p> <a class="anchor" id="plain-Destructor"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;
 step2::MVTest&lt;T&gt;::~MVTest()
 {
     <span class="keywordflow">if</span> (driver_m)
         <span class="keyword">delete</span> driver_m;
 }
</pre></div><p> <a class="anchor" id="plain-Functionrun"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;
 QString
 step2::MVTest&lt;T&gt;::run()
 {
     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i=0; i&lt; this-&gt;params-&gt;matrix_sizes.size(); i++)
     {
         <span class="keywordtype">size_t</span> nr = this-&gt;params-&gt;matrix_sizes[i].first ;
         <span class="keywordtype">size_t</span> nc = this-&gt;params-&gt;matrix_sizes[i].second;
 
<span class="preprocessor"> #ifdef DEBUG</span>
<span class="preprocessor"></span>         std::cout  &lt;&lt; <span class="stringliteral">&quot;Testing MV for &quot;</span> &lt;&lt; nr &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; nc &lt;&lt; <span class="stringliteral">&quot; matrix&quot;</span> &lt;&lt; std::endl;
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>         setup_and_assemble(nr, nc);
 
 
         std::vector&lt;T&gt; x(this-&gt;x_orig.begin(), this-&gt;x_orig.end());
 
         <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> n_elements =  this-&gt;y_orig.size();
         std::vector&lt;T&gt; y(n_elements, 0.);
 
         <span class="keywordtype">double</span> elapsed_time
                 =
                 driver_m-&gt;mvmult(y, A, x,
                                  this-&gt;params-&gt;n_repetitions) / this-&gt;params-&gt;n_repetitions;
 
 
         dealii::Vector&lt;T&gt; diff ( n_elements );
         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> i = 0; i &lt; n_elements; i++)
             diff(i) = (y[i] - y_orig(i)) / y_orig(i);
 
         <span class="keywordtype">double</span> linfty_error = diff.linfty_norm();
 
         <span class="keywordflow">if</span> (linfty_error&gt; (<span class="keyword">sizeof</span>(T)&lt;8 ? 1e-5 : 1e-14))
         {
             std::cerr &lt;&lt; nr &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; nc &lt;&lt; <span class="stringliteral">&quot; matrix : &quot;</span>
                       &lt;&lt; <span class="stringliteral">&quot;|| (y - y_orig)/y_orig||_infty = &quot;</span> &lt;&lt; linfty_error
                       &lt;&lt; <span class="stringliteral">&quot; MVTest probably failed!&quot;</span>
                       &lt;&lt; std::endl;
 
             <span class="keywordflow">if</span> (y.size() &lt; 20) {
                 std::cerr &lt;&lt; y_orig &lt;&lt; std::endl;
 
                 std::copy(y.begin(), y.end(), diff.begin());
                 std::cerr &lt;&lt; diff &lt;&lt; std::endl;
             }
         }
 
         this-&gt;results_table.add_value(col_head.c_str(), elapsed_time);
 
         this-&gt;results_table.set_precision(col_head.c_str(), 12);
     }
 
     <span class="keywordflow">return</span> col_head.c_str();
 }
</pre></div><p> <a class="anchor" id="plain-Functionsetup_and_assemble"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span>
 step2::MVTest&lt;T&gt;::setup_and_assemble(<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> nr, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> nc)
 {
     this-&gt;A.reinit(nr, nc);
     this-&gt;x_orig.reinit(nc);
     this-&gt;y_orig.reinit(nr);
 
     y_orig = 0.;
     <span class="keywordtype">int</span> tmp = 1;
     <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> r = 0; r &lt; nr; ++r)
         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> c = 0; c &lt; nc; ++c)
         {
             x_orig(c)  = (c+1);
             A(r,c)     = tmp; tmp++;<span class="comment">//r+1 + 1./(c+1);</span>
             y_orig(r) +=  A(r,c)*x_orig(c);
         }
 }
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef MVMultDriverInterface_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define MVMultDriverInterface_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;vector&gt;</span>
<span class="preprocessor"> #include &lt;numeric&gt;</span>
<span class="preprocessor"> #include &lt;lac/blas++.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
 
 <span class="keyword">typedef</span>    std::pair&lt;size_t, size_t&gt; matrixSize;
</pre></div><p> <a class="anchor" id="plain-ClassMVMultDriverInterface"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number&gt;
 <span class="keyword">class </span>MVMultDriverInterface {
 
 <span class="keyword">public</span>:
 
     typedef ::FullMatrixAccessor&lt;Number&gt; FullMatrixAccessor;
 
     MVMultDriverInterface()    {}
 
     <span class="keyword">virtual</span> ~MVMultDriverInterface () {}
</pre></div><p> <a class="anchor" id="plain-Functionmvmult"></a> </p>
<div class="fragment"><pre class="fragment">     <span class="keyword">virtual</span> <span class="keywordtype">double</span> mvmult(std::vector&lt;Number&gt; &amp; y,
                           <span class="keyword">const</span> FullMatrixAccessor &amp; A,
                           <span class="keyword">const</span> std::vector&lt;Number&gt; &amp; x,
                           <span class="keywordtype">int</span> n_repetitions) = 0;
 };
 
 } <span class="comment">// namespace step2 END</span>
<span class="preprocessor"> #endif // MVMultDriverInterface_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CPUBLAS_DRIVER_STEP2_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define CPUBLAS_DRIVER_STEP2_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;vector&gt;</span>
<span class="preprocessor"> #include &lt;lac/blas++.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/MVMultDriverInterface.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p> <a class="anchor" id="plain-ClassCpuBlasDriver"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> EntryType, <span class="keyword">typename</span> blasType&gt;
 <span class="keyword">class </span>CpuBlasDriver : <span class="keyword">public</span> MVMultDriverInterface&lt;EntryType&gt;
 {
 <span class="keyword">public</span>:
 
     <span class="keyword">typedef</span>
     <span class="keyword">typename</span> MVMultDriverInterface&lt; EntryType&gt;::FullMatrixAccessor
     FullMatrixAccessor;
 
     CpuBlasDriver() {}
 
     <span class="keyword">virtual</span> ~CpuBlasDriver () {}
 
     <span class="keyword">virtual</span> <span class="keywordtype">double</span> mvmult(std::vector&lt;EntryType&gt;&amp; y,
                           <span class="keyword">const</span> FullMatrixAccessor&amp; A,
                           <span class="keyword">const</span> std::vector&lt;EntryType&gt;&amp; x,
                           <span class="keywordtype">int</span> n_repetitions);
 };
 
 } <span class="comment">// namespace step2 END</span>
 
<span class="preprocessor"> #include &lt;step-2/CpuBlas_driver_step-2.hh&gt;</span>
<span class="preprocessor"> #endif // CPUBLAS_DRIVER_STEP2_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CPUBLAS_DRIVER_STEP_2_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define CPUBLAS_DRIVER_STEP_2_HH</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;base/CUDATimer.h&gt;</span>
</pre></div><p> <a class="anchor" id="plain-Functionmvmult"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> EntryType,<span class="keyword">typename</span> blasType&gt;
 <span class="keywordtype">double</span> step2::CpuBlasDriver&lt;EntryType,blasType&gt;::mvmult(std::vector&lt;EntryType&gt;&amp; y,
                                                         <span class="keyword">const</span> FullMatrixAccessor&amp; A,
                                                         <span class="keyword">const</span> std::vector&lt;EntryType&gt;&amp; x,
                                                         <span class="keywordtype">int</span> n_repetitions)
 {
     <span class="keywordtype">int</span> n_rows = A.n_rows();
     <span class="keywordtype">int</span> n_cols = A.n_cols();
 
     EntryType * d_y = &amp;y[0];
 
     EntryType * d_A = <span class="keyword">const_cast&lt;</span>FullMatrixAccessor &amp;<span class="keyword">&gt;</span>(A).val();
 
     EntryType * d_x = &amp;<span class="keyword">const_cast&lt;</span>std::vector&lt;EntryType&gt; &amp;<span class="keyword">&gt;</span>(x)[0];
 
     EntryType alpha = 1;
     EntryType beta  = 1;
 
     <span class="keywordtype">int</span> incx = 1; <span class="keywordtype">int</span> incy = 1;
 
     <span class="keywordtype">int</span> lda = n_cols;
 
     <span class="keywordtype">int</span> m = n_cols;
     <span class="keywordtype">int</span> n = n_rows;
 
     <span class="keywordtype">double</span> cumulative_runtime = 0.;
     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;n_repetitions; i++)
     {
         <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> k = 0; k &lt; n_rows; k++)
             d_y[k] = 0.;
 
         CUDATimer timer;
 
         blasType::gemv (<span class="charliteral">&#39;t&#39;</span>, m, n, alpha,
                         d_A, lda,
                         d_x, incx,
                         beta,
                         d_y, incy);
 
         timer.stop();
         cumulative_runtime += timer.elapsed();
     }
 
     <span class="keywordflow">return</span> cumulative_runtime;
 }
<span class="preprocessor"> #endif // CPUBLAS_DRIVER_STEP_2_HH</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CUBlasDriver_STEP_2_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define CUBlasDriver_STEP_2_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;vector&gt;</span>
<span class="preprocessor"> #include &lt;lac/blas++.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/MVMultDriverInterface.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p> <a class="anchor" id="plain-ClassCUBlasDriver"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T,<span class="keyword">typename</span> blasType=cublas&gt;
 <span class="keyword">class </span>CUBlasDriver : <span class="keyword">public</span> MVMultDriverInterface&lt;T&gt;
 {
 <span class="keyword">public</span>:
     <span class="keyword">typedef</span>
     <span class="keyword">typename</span> MVMultDriverInterface&lt;T&gt;::FullMatrixAccessor
     FullMatrixAccessor;
 
 
     CUBlasDriver();
 
     <span class="keyword">virtual</span> ~CUBlasDriver ();
 
     <span class="keyword">virtual</span> <span class="keywordtype">double</span> mvmult(std::vector&lt;T&gt;&amp; y,
                           <span class="keyword">const</span> FullMatrixAccessor&amp; A,
                           <span class="keyword">const</span> std::vector&lt;T&gt;&amp; x,
                           <span class="keywordtype">int</span>  n_repetitions);
 };
 
 } <span class="comment">// namespace step2 END</span>
 
<span class="preprocessor"> #include &lt;step-2/cuda_driver_step-2.hh&gt;</span>
<span class="preprocessor"> #endif // CUBlasDriver_STEP_2_H</span>
<span class="preprocessor"></span> 
 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CUDA_DRIVER_STEP_2_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define CUDA_DRIVER_STEP_2_HH</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;base/CUDATimer.h&gt;</span>
</pre></div><p> <a class="anchor" id="plain-ConstructorCUBlasDriver"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T,<span class="keyword">typename</span> blasType&gt;
 step2::CUBlasDriver&lt;T,blasType&gt;::CUBlasDriver() : MVMultDriverInterface&lt;T&gt;()
 {
     blasType::Init();
 }
</pre></div><p> <a class="anchor" id="plain-DestructorCUBlasDriver"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T,<span class="keyword">typename</span> blasType&gt;
 step2::CUBlasDriver&lt;T,blasType&gt;::~CUBlasDriver()
 {
     blasType::Shutdown();
 }
</pre></div><p> <a class="anchor" id="plain-Functionmvmult"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T,<span class="keyword">typename</span> blasType&gt;
 <span class="keywordtype">double</span> step2::CUBlasDriver&lt;T,blasType&gt;::mvmult(std::vector&lt;T&gt;&amp; y,
                                                <span class="keyword">const</span> FullMatrixAccessor&amp; A,
                                                <span class="keyword">const</span> std::vector&lt;T&gt;&amp; x,
                                                <span class="keywordtype">int</span> n_repetitions)
 {   
     <span class="keywordtype">int</span> n_rows = A.n_rows();
     <span class="keywordtype">int</span> n_cols = A.n_cols();
 
     T * dst = &amp;y[0];
 
     T * A_entries = <span class="keyword">const_cast&lt;</span>FullMatrixAccessor &amp;<span class="keyword">&gt;</span>(A).val();
 
     T * src = &amp;<span class="keyword">const_cast&lt;</span>std::vector&lt;T&gt; &amp;<span class="keyword">&gt;</span>(x)[0];
 
     T alpha=1.;
     T beta=1.;
     <span class="keywordtype">int</span> incx=1;
     <span class="keywordtype">int</span> incy=1;
 
     <span class="keywordtype">int</span> lda=n_cols;
     <span class="keywordtype">int</span> m = n_cols;
     <span class="keywordtype">int</span> n = n_rows;
 
     T *d_A, *d_x, *d_y;
 
     cudaMalloc((<span class="keywordtype">void</span> **) &amp;d_A, n_rows * n_cols * <span class="keyword">sizeof</span>(T));
 
     cudaMalloc((<span class="keywordtype">void</span> **) &amp;d_x, n_cols * <span class="keyword">sizeof</span>(T));
     cudaMalloc((<span class="keywordtype">void</span> **) &amp;d_y, n_rows * <span class="keyword">sizeof</span>(T));
 
     cudaMemcpy(d_x, src, n_cols * <span class="keyword">sizeof</span>(T), cudaMemcpyHostToDevice);
 
     cudaMemcpy(d_A, A_entries, n_rows * n_cols * <span class="keyword">sizeof</span>(T), cudaMemcpyHostToDevice);
 
     <span class="keywordtype">double</span> cumulative_runtime = 0.;
     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;n_repetitions; i++)
     {
         cudaThreadSynchronize();
         CUDATimer timer;
 
         cudaMemcpy(d_y, dst, n_rows * <span class="keyword">sizeof</span>(T), cudaMemcpyHostToDevice);
 
         blasType::gemv (<span class="charliteral">&#39;t&#39;</span>, m, n, alpha,
                         d_A, lda,
                         d_x,  incx,
                         beta,
                         d_y,  incy);
 
         cudaThreadSynchronize();
         timer.stop();
         cumulative_runtime += timer.elapsed();
     }
 
     cudaMemcpy(dst, d_y, n_rows * <span class="keyword">sizeof</span>(T), cudaMemcpyDeviceToHost);
 
     cudaFree(d_y);
     cudaFree(d_x);
     cudaFree(d_A);
 
     <span class="keywordflow">return</span> cumulative_runtime;
 }
<span class="preprocessor"> #endif // CUDA_DRIVER_STEP_2_HH</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef FUJIMOTO_DRIVER_step2_H</span>
<span class="preprocessor"></span><span class="preprocessor"> #define FUJIMOTO_DRIVER_step2_H</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;vector&gt;</span>
<span class="preprocessor"> #include &lt;lac/blas++.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/MVMultDriverInterface.h&gt;</span>
<span class="preprocessor"> #include &lt;step-2/cuda_kernel_wrapper_step-2.cu.h&gt;</span>
 
 <span class="keyword">namespace </span>step2 {
</pre></div><p> <a class="anchor" id="plain-ClassFujimotoDriver"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T,<span class="keyword">typename</span> blasType=cublas&gt;
 <span class="keyword">class </span>FujimotoDriver : <span class="keyword">public</span> MVMultDriverInterface&lt;T&gt;, <span class="keyword">private</span> Kernels&lt;T&gt;
 {
 <span class="keyword">public</span>:
     <span class="keyword">typedef</span>
     <span class="keyword">typename</span> MVMultDriverInterface&lt;T&gt;::FullMatrixAccessor FullMatrixAccessor;
 
     FujimotoDriver(<span class="keyword">const</span> <span class="keywordtype">int</span> v) : fj_version(v) {}
 
     <span class="keyword">virtual</span>  ~FujimotoDriver () {}
 
     <span class="keyword">virtual</span> <span class="keywordtype">double</span> mvmult(std::vector&lt;T&gt;&amp; y,
                           <span class="keyword">const</span> FullMatrixAccessor&amp; A,
                           <span class="keyword">const</span> std::vector&lt;T&gt;&amp; x,
                           <span class="keywordtype">int</span> n_repetitions);
 
 <span class="keyword">protected</span>:
     <span class="keyword">const</span> <span class="keywordtype">int</span> fj_version;
 };
 
 } <span class="comment">// namespace step2 END</span>
 
<span class="preprocessor"> #include &lt;step-2/Fujimoto_driver_step-2.hh&gt;</span>
<span class="preprocessor"> #endif // FUJIMOTO_DRIVER_step2_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef FUJIMOTO_DRIVER_step2_HH</span>
<span class="preprocessor"></span><span class="preprocessor"> #define FUJIMOTO_DRIVER_step2_HH</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;step-2/cuda_kernel_wrapper_step-2.cu.h&gt;</span>
<span class="preprocessor"> #include &lt;base/CUDATimer.h&gt;</span>
</pre></div><p> <a class="anchor" id="plain-Functionmvmult"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> Number,<span class="keyword">typename</span> blasType&gt;
 <span class="keywordtype">double</span> step2::FujimotoDriver&lt;Number,blasType&gt;::mvmult(std::vector&lt;Number&gt; &amp; y,
                                                       <span class="keyword">const</span> FullMatrixAccessor&amp; A,
                                                       <span class="keyword">const</span> std::vector&lt;Number&gt; &amp; x,
                                                       <span class="keywordtype">int</span> n_repetitions)
 {
     <span class="keywordtype">int</span> n_rows = A.n_rows();
     <span class="keywordtype">int</span> n_cols = A.n_cols();
 
     Number * dst = &amp;y[0];
 
     <span class="keyword">const</span> Number * A_entries = A.val();
 
     <span class="keyword">const</span> Number * src = &amp;x[0];
 
 
     <span class="keywordtype">double</span> cumulative_elapsed_time = 0;
 
     this-&gt;mv_fujimoto(dst, A_entries, src,
                       n_rows, n_cols,
                       n_repetitions,
                       this-&gt;fj_version,
                       cumulative_elapsed_time);
 
     <span class="keywordflow">return</span> cumulative_elapsed_time;
 }
 
<span class="preprocessor"> #endif // FUJIMOTO_DRIVER_step2_HH</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
<span class="preprocessor"> #ifndef CUDA_KERNEL_STEP_2_CU_H</span>
<span class="preprocessor"> #define CUDA_KERNEL_STEP_2_CU_H</span>
</pre></div><p> <a class="anchor" id="plain-DeclarationofCUDAInterface"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">namespace </span>step2 {
</pre></div><p> <a class="anchor" id="plain-ClassKernels"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">struct </span>Kernels {
 
     <span class="keywordtype">void</span> mv_fujimoto(T *y, <span class="keyword">const</span> T *A, <span class="keyword">const</span> T *x,
                      <span class="keyword">const</span> <span class="keywordtype">int</span> m, <span class="keyword">const</span> <span class="keywordtype">int</span> n,
                      <span class="keyword">const</span> <span class="keywordtype">int</span> n_repetitions, <span class="keyword">const</span> <span class="keywordtype">int</span> fj_version, <span class="keywordtype">double</span>&amp; elapsed_time);
 };
 }
<span class="preprocessor"> #endif // CUDA_KERNEL_STEP_2_CU_H</span>
<span class="preprocessor"></span> 
 
 
 / *This file is part of SciPAL.
 
     SciPAL is free software: you can redistribute it and/or modify
     it under the terms of the GNU Lesser General Public License as published by
     the Free Software Foundation, either version 3 of the License, or
     (at your option) any later version.
 
     SciPAL is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     GNU Lesser General Public License <span class="keywordflow">for</span> more details.
 
     You should have received a copy of the GNU Lesser General Public License
     along with SciPAL.  If not, see &lt;http:<span class="comment">//www.gnu.org/licenses/&gt;.</span>
 
 Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * /
 
 
 
<span class="preprocessor"> #include &lt;step-2/cuda_kernel_wrapper_step-2.cu.h&gt;</span>
 
 
<span class="preprocessor"> #ifndef DONT_USE_CUDATIMER</span>
<span class="preprocessor"></span><span class="preprocessor"> #include &lt;base/CUDATimer.h&gt;</span>
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
<span class="preprocessor"> #include &lt;stdio.h&gt;</span>
</pre></div><p> <a class="anchor" id="plain-Kernels"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">namespace </span>step2 {
 
<span class="preprocessor"> #define bx blockIdx.x</span>
<span class="preprocessor"></span><span class="preprocessor"> #define tx threadIdx.x</span>
<span class="preprocessor"></span><span class="preprocessor"> #define ty threadIdx.y</span>
<span class="preprocessor"></span> 
 
 texture&lt;float4, 2, cudaReadModeElementType&gt; fTexRefA;
</pre></div><p> <a class="anchor" id="plain-Kernel_mv_fujimoto"></a> </p>
<div class="fragment"><pre class="fragment"> __global__
 <span class="keywordtype">void</span>
 _mv_fujimoto(<span class="keywordtype">float</span>* y, cudaArray* A, <span class="keywordtype">float</span>* x, <span class="keywordtype">int</span> m, <span class="keywordtype">int</span> n)
 {
     __shared__ <span class="keywordtype">float</span> xs[16][16];
 
     __shared__ <span class="keywordtype">float</span> Ps[16][16];
 
     float4 a;
 
     <span class="keywordtype">float</span> *Psptr = (<span class="keywordtype">float</span> *) Ps + (ty &lt;&lt; 4) + tx;
     <span class="keywordtype">int</span> ay = (bx &lt;&lt; 4) + ty;
     <span class="keywordtype">float</span> *xptr = x + (ty &lt;&lt; 4) + tx;
     <span class="keywordtype">float</span> *xsptr = (<span class="keywordtype">float</span> *) xs + (tx &lt;&lt; 2);
 
     *Psptr = 0.0f;
 
     <span class="keywordtype">int</span> i;
     <span class="keywordflow">for</span> (i = 0; i &lt; (n &amp; ~255); i += 256, xptr += 256)
     {
         xs[ty][tx] = *xptr;
         __syncthreads();
 
         <span class="keywordtype">int</span> ax = tx + (i &gt;&gt; 2);
 
         a = tex2D(fTexRefA, ax     , ay);
         *Psptr += a.x * *xsptr         + a.y * *(xsptr +   1) + a.z * *(xsptr +   2) + a.w * *(xsptr +   3);
 
         a = tex2D(fTexRefA, ax + 16, ay);
         *Psptr += a.x * *(xsptr +  64) + a.y * *(xsptr +  65) + a.z * *(xsptr +  66) + a.w * *(xsptr +  67);
 
         a = tex2D(fTexRefA, ax + 32, ay);
         *Psptr += a.x * *(xsptr + 128) + a.y * *(xsptr + 129) + a.z * *(xsptr + 130) + a.w * *(xsptr + 131);
 
         a = tex2D(fTexRefA, ax + 48, ay);
         *Psptr += a.x * *(xsptr + 192) + a.y * *(xsptr + 193) + a.z * *(xsptr + 194) + a.w * *(xsptr + 195);
 
         __syncthreads();
     }
 
     <span class="keywordflow">if</span> (i + (ty &lt;&lt; 4) + tx &lt; n) {
         xs[ty][tx] = *xptr;
     }
     __syncthreads();
 
     <span class="keywordtype">int</span> j;
     <span class="keywordflow">for</span> (j = 0; j &lt; ((n - i) &gt;&gt; 6); j++, xsptr += 61) {
         a = tex2D(fTexRefA, tx + (i &gt;&gt; 2) + (j &lt;&lt; 4), ay);
         *Psptr += a.x * *xsptr++ + a.y * *xsptr++ + a.z * *xsptr++ + a.w * *xsptr;
     }
     __syncthreads();
 
     <span class="keywordtype">int</span> remain = (n - i) &amp; 63;
 
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) &lt; remain) {
         a = tex2D(fTexRefA, tx + (i &gt;&gt; 2) + (j &lt;&lt; 4), ay);
         *Psptr += a.x * *xsptr++;
     }
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) + 1 &lt; remain) *Psptr += a.y * *xsptr++;
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) + 2 &lt; remain) *Psptr += a.z * *xsptr++;
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) + 3 &lt; remain) *Psptr += a.w * *xsptr;
     __syncthreads();
 
     <span class="keywordflow">if</span> (tx &lt; 8) *Psptr += *(Psptr + 8);
     <span class="keywordflow">if</span> (tx &lt; 4) *Psptr += *(Psptr + 4);
     <span class="keywordflow">if</span> (tx &lt; 2) *Psptr += *(Psptr + 2);
     <span class="keywordflow">if</span> (tx &lt; 1) *Psptr += *(Psptr + 1);
     __syncthreads();
 
     <span class="keywordflow">if</span> (ty == 0 &amp;&amp; (bx &lt;&lt; 4) + tx &lt; m) y[(bx &lt;&lt; 4) + tx] = Ps[tx][0];
 }
</pre></div><p> <a class="anchor" id="plain-Kernel_mv_fujimoto_T"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">struct </span>IsFloat;
 
 <span class="keyword">template</span>&lt;&gt;
 <span class="keyword">struct </span>IsFloat&lt;float&gt;
 {
     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">bool</span> value = <span class="keyword">true</span>;
 };
 
 <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">struct </span>IsFloat
 {
     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">bool</span> value = <span class="keyword">false</span>;
 };
 
 <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">struct </span>TexEl;
 
 <span class="keyword">template</span>&lt;&gt;
 <span class="keyword">struct </span>TexEl&lt;float&gt;
 {
     <span class="keyword">typedef</span> float4 value_type;
     <span class="keyword">typedef</span> float4 alt_value_type;
     <span class="keyword">typedef</span> float4 texel_type;
     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">int</span> tex_stride = 4;
 };
 
 <span class="keyword">template</span>&lt;&gt;
 <span class="keyword">struct </span>TexEl&lt;double&gt;
 {
     <span class="keyword">typedef</span> double4 value_type;
     <span class="keyword">typedef</span> double2 alt_value_type;
     <span class="keyword">typedef</span> int4 texel_type;
     <span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">int</span> tex_stride = 2;
 };
 
 texture&lt;TexEl&lt;double&gt;::texel_type, 2, cudaReadModeElementType&gt; dTexRefA;
 
 
 <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">struct </span>texAccessor {
 
     __device__
     <span class="keyword">typename</span> TexEl&lt;T&gt;::value_type
     operator() (<span class="keywordtype">int</span> ax, <span class="keywordtype">int</span> ay);
 
 };
 
 <span class="keyword">template</span>&lt;&gt;
 TexEl&lt;float&gt;::value_type texAccessor&lt;float&gt;::operator() (<span class="keywordtype">int</span> ax, <span class="keywordtype">int</span> ay)
 {
     <span class="keywordflow">return</span> tex2D(fTexRefA, ax, ay);
 }
 
 <span class="keyword">template</span>&lt;&gt;
 TexEl&lt;double&gt;::value_type texAccessor&lt;double&gt;::operator() (<span class="keywordtype">int</span> ax, <span class="keywordtype">int</span> ay)
 {
     TexEl&lt;double&gt;::texel_type tmp;
     TexEl&lt;double&gt;::value_type a;
 
     tmp = tex2D(dTexRefA, 2*ax, ay);
     a.x = __hiloint2double(tmp.y, tmp.x);
     a.y = __hiloint2double(tmp.w, tmp.z);
 
     tmp = tex2D(dTexRefA, 2*ax+1, ay);
     a.z = __hiloint2double(tmp.y, tmp.x);
     a.w = __hiloint2double(tmp.w, tmp.z);
 
<span class="preprocessor"> #ifndef nDEBUG</span>
<span class="preprocessor"></span>     printf(<span class="stringliteral">&quot;a : %f, %f, %f, %f\n&quot;</span>, a.x, a.y, a.z, a.w);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>     <span class="keywordflow">return</span> a;
 }
 
 <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 __global__
 <span class="keywordtype">void</span>
 _mv_fujimoto_T( T* y, cudaArray* A, T* x, <span class="keywordtype">int</span> m, <span class="keywordtype">int</span> n)
 {
     __shared__ T xs[16][16];
 
     __shared__ T Ps[16][16];
 
     <span class="keyword">typename</span> TexEl&lt;T&gt;::value_type a;
 
     T *Psptr = (T *) Ps + (ty &lt;&lt; 4) + tx;
 
     <span class="keywordtype">int</span> ay = (bx &lt;&lt; 4) + ty;
 
     T *xptr = x + (ty &lt;&lt; 4) + tx;
     T *xsptr = (T *) xs + (tx &lt;&lt; 2);
 
     *Psptr = 0.0f;
     <span class="keywordtype">int</span> i;
 
     texAccessor&lt;T&gt; tex_2D;
 
     <span class="keywordflow">for</span> (i = 0; i &lt; (n &amp; ~255); i += 256, xptr += 256)
     {
         xs[ty][tx] = *xptr;
         __syncthreads();
 
         <span class="keywordtype">int</span> ax = tx + (i &gt;&gt; 2);
 
         a = tex_2D(ax, ay);
         *Psptr += a.x * *xsptr         + a.y * *(xsptr +   1) + a.z * *(xsptr +   2) + a.w * *(xsptr +   3);
 
         a = tex_2D(ax+16, ay);
         *Psptr += a.x * *(xsptr +  64) + a.y * *(xsptr +  65) + a.z * *(xsptr +  66) + a.w * *(xsptr +  67);
 
         a = tex_2D(ax+32, ay);
         *Psptr += a.x * *(xsptr + 128) + a.y * *(xsptr + 129) + a.z * *(xsptr + 130) + a.w * *(xsptr + 131);
 
         a = tex_2D(ax+48, ay);
         *Psptr += a.x * *(xsptr + 192) + a.y * *(xsptr + 193) + a.z * *(xsptr + 194) + a.w * *(xsptr + 195);
 
         __syncthreads();
     }
 
     <span class="keywordflow">if</span> (i + (ty &lt;&lt; 4) + tx &lt; n) {
         xs[ty][tx] = *xptr;
     }
     __syncthreads();
 
     <span class="keywordtype">int</span> j;
     <span class="keywordflow">for</span> (j = 0; j &lt; ((n - i) &gt;&gt; 6); j++, xsptr += 61) {
         a = tex_2D(tx + (i &gt;&gt; 2) + (j &lt;&lt; 4), ay);
         *Psptr += a.x * *xsptr++ + a.y * *xsptr++    +     a.z * *xsptr++ + a.w * *xsptr;
     }
     __syncthreads();
 
     <span class="keywordtype">int</span> remain = (n - i) &amp; 63;
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) &lt; remain) {
         a = tex_2D(tx + (i &gt;&gt; 2) + (j &lt;&lt; 4), ay);
 
         *Psptr += a.x * *xsptr++;
     }
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) + 1 &lt; remain) *Psptr += a.y * *xsptr++;
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) + 2 &lt; remain) *Psptr += a.z * *xsptr++;
     <span class="keywordflow">if</span> ((tx &lt;&lt; 2) + 3 &lt; remain) *Psptr += a.w * *xsptr;
     __syncthreads();
 
 
     <span class="keywordflow">if</span> (tx &lt; 8) *Psptr += *(Psptr + 8);
     <span class="keywordflow">if</span> (tx &lt; 4) *Psptr += *(Psptr + 4);
     <span class="keywordflow">if</span> (tx &lt; 2) *Psptr += *(Psptr + 2);
     <span class="keywordflow">if</span> (tx &lt; 1) *Psptr += *(Psptr + 1);
 
     __syncthreads();
     <span class="keywordflow">if</span> (ty == 0 &amp;&amp; (bx &lt;&lt; 4) + tx &lt; m) y[(bx &lt;&lt; 4) + tx] = Ps[tx][0];
 }
</pre></div><p> <a class="anchor" id="plain-Kernel_mv_fujimoto_T2"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 __global__
 <span class="keywordtype">void</span>
 _mv_fujimoto_T2( T* y, cudaArray* A, T* x, <span class="keywordtype">int</span> m, <span class="keywordtype">int</span> n)
 {
     __shared__ T xs[16][16];
 
     __shared__ T Ps[16][16];
 
     <span class="keyword">typename</span> TexEl&lt;T&gt;::value_type a;
 
     T *Psptr = (T *) Ps + (16*ty) + tx;
 
     <span class="keywordtype">int</span> ay = (16*bx) + ty;
 
     T *xptr = x + (16*ty) + tx;
     T *xsptr = (T *) xs + (4*tx);
 
     *Psptr = 0.0f;
     <span class="keywordtype">int</span> i;
 
     texAccessor&lt;T&gt; tex_2D;
 
 
     <span class="keywordflow">for</span> (i = 0; i &lt; (n &amp; ~255); i += 256, xptr += 256)
     {
         xs[ty][tx] = *xptr;
         __syncthreads();
 
         <span class="keywordtype">int</span> ax = tx + (i/4);
 
         a = tex_2D(ax, ay);
         *Psptr += a.x * *xsptr         + a.y * *(xsptr +   1) + a.z * *(xsptr +   2) + a.w * *(xsptr +   3);
 
         a = tex_2D(ax+16, ay);
         *Psptr += a.x * *(xsptr +  64) + a.y * *(xsptr +  65) + a.z * *(xsptr +  66) + a.w * *(xsptr +  67);
 
         a = tex_2D(ax+32, ay);
         *Psptr += a.x * *(xsptr + 128) + a.y * *(xsptr + 129) + a.z * *(xsptr + 130) + a.w * *(xsptr + 131);
 
         a = tex_2D(ax+48, ay);
         *Psptr += a.x * *(xsptr + 192) + a.y * *(xsptr + 193) + a.z * *(xsptr + 194) + a.w * *(xsptr + 195);
 
         __syncthreads();
     }
 
     <span class="keywordflow">if</span> (i + (16*ty) + tx &lt; n) {
         xs[ty][tx] = *xptr;
     }
     __syncthreads();
 
     <span class="keywordtype">int</span> j;
     <span class="keywordflow">for</span> (j = 0; j &lt; ((n - i)/64); j++, xsptr += 61) {
         a = tex_2D(tx + (i/4) + (16*j), ay);
         *Psptr += a.x * *xsptr++ + a.y * *xsptr++    +     a.z * *xsptr++ + a.w * *xsptr;
     }
     __syncthreads();
 
     <span class="keywordtype">int</span> remain = (n - i) &amp; 63;
     <span class="keywordflow">if</span> ((4*tx) &lt; remain) {
         a = tex_2D(tx + (i/4) + (16*j), ay);
 
         *Psptr += a.x * *xsptr++;
     }
     <span class="keywordflow">if</span> ((4*tx) + 1 &lt; remain) *Psptr += a.y * *xsptr++;
     <span class="keywordflow">if</span> ((4*tx) + 2 &lt; remain) *Psptr += a.z * *xsptr++;
     <span class="keywordflow">if</span> ((4*tx) + 3 &lt; remain) *Psptr += a.w * *xsptr;
     __syncthreads();
 
 
     <span class="keywordflow">if</span> (tx &lt; 8) *Psptr += *(Psptr + 8);
     <span class="keywordflow">if</span> (tx &lt; 4) *Psptr += *(Psptr + 4);
     <span class="keywordflow">if</span> (tx &lt; 2) *Psptr += *(Psptr + 2);
     <span class="keywordflow">if</span> (tx &lt; 1) *Psptr += *(Psptr + 1);
 
     __syncthreads();
     <span class="keywordflow">if</span> (ty == 0 &amp;&amp; (16*bx) + tx &lt; m) y[(16*bx) + tx] = Ps[tx][0];
 }
</pre></div><p> <a class="anchor" id="plain-Kernel_mv_fujimoto_T3"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keyword">struct </span>texAccessorOpt {
 
     __device__
     <span class="keyword">typename</span> TexEl&lt;T&gt;::alt_value_type
     operator() (<span class="keywordtype">int</span> ax, <span class="keywordtype">int</span> ay);
 
 };
 
 <span class="keyword">template</span>&lt;&gt;
 TexEl&lt;float&gt;::alt_value_type texAccessorOpt&lt;float&gt;::operator() (<span class="keywordtype">int</span> ax, <span class="keywordtype">int</span> ay)
 {
     <span class="keywordflow">return</span> tex2D(fTexRefA, ax, ay);
 }
 
 <span class="keyword">template</span>&lt;&gt;
 TexEl&lt;double&gt;::alt_value_type texAccessorOpt&lt;double&gt;::operator() (<span class="keywordtype">int</span> ax, <span class="keywordtype">int</span> ay)
 {
     TexEl&lt;double&gt;::texel_type tmp;
     TexEl&lt;double&gt;::alt_value_type a;
 
     tmp = tex2D(dTexRefA, ax, ay);
     a.x = __hiloint2double(tmp.y, tmp.x);
     a.y = __hiloint2double(tmp.w, tmp.z);
 
<span class="preprocessor"> #ifdef DEBUG</span>
<span class="preprocessor"></span>     printf(<span class="stringliteral">&quot;a : %f, %f\n&quot;</span>, a.x, a.y);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>     <span class="keywordflow">return</span> a;
 }
 
 <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 __global__
 <span class="keywordtype">void</span>
 _mv_fujimoto_T3( T* y, cudaArray* A, T* x, <span class="keywordtype">int</span> m, <span class="keywordtype">int</span> n)
 {
     __shared__ T xs[16][16];
 
     __shared__ T Ps[16][16];
 
 
     T *Psptr = (T *) Ps + (16*ty) + tx;
 
     <span class="keywordtype">int</span> ay = (16*bx) + ty;
 
     T *xptr = x + (16*ty) + tx;
 
 
     *Psptr = 0.0f;
     <span class="keywordtype">int</span> i;
 
     <span class="keywordflow">if</span>(IsFloat&lt;T&gt;::value==<span class="keyword">true</span>)
     {
         T *xsptr = (T *) xs + (4*tx);
         <span class="keyword">typename</span> TexEl&lt;T&gt;::value_type a;
         texAccessor&lt;T&gt; tex_2D;
         <span class="keywordflow">for</span> (i = 0; i &lt; (n &amp; ~255); i += 256, xptr += 256)
         {
             xs[ty][tx] = *xptr;
             __syncthreads();
 
             <span class="keywordtype">int</span> ax = tx + (i/4);
 
             a = tex_2D(ax, ay);
              printf(<span class="stringliteral">&quot;a : %f, %f, %f, %f\n&quot;</span>, a.x, a.y, a.z, a.w);
             *Psptr += a.x * *xsptr         + a.y * *(xsptr +   1) + a.z * *(xsptr +   2) + a.w * *(xsptr +   3);
 
             a = tex_2D(ax+16, ay);
             *Psptr += a.x * *(xsptr +  64) + a.y * *(xsptr +  65) + a.z * *(xsptr +  66) + a.w * *(xsptr +  67);
 
             a = tex_2D(ax+32, ay);
             *Psptr += a.x * *(xsptr + 128) + a.y * *(xsptr + 129) + a.z * *(xsptr + 130) + a.w * *(xsptr + 131);
 
             a = tex_2D(ax+48, ay);
             *Psptr += a.x * *(xsptr + 192) + a.y * *(xsptr + 193) + a.z * *(xsptr + 194) + a.w * *(xsptr + 195);
 
             __syncthreads();
         }
 
         <span class="keywordflow">if</span> (i + (16*ty) + tx &lt; n) {
             xs[ty][tx] = *xptr;
         }
         __syncthreads();
 
 
         <span class="keywordtype">int</span> j;
         <span class="keywordflow">for</span> (j = 0; j &lt; ((n - i)/64); j++, xsptr += 61) {
             a = tex_2D(tx + (i/4) + (16*j), ay);
             *Psptr += a.x * *xsptr++ + a.y * *xsptr++ + a.z * *xsptr++ + a.w * *xsptr;
         }
         __syncthreads();
 
 
         <span class="keywordtype">int</span> remain = (n - i) &amp; 63;
         <span class="keywordflow">if</span> ((4*tx) &lt; remain) {
             a = tex_2D(tx + (i/4) + (16*j), ay);
 
             *Psptr += a.x * *xsptr++;
         }
         <span class="keywordflow">if</span> ((4*tx) + 1 &lt; remain) *Psptr += a.y * *xsptr++;
         <span class="keywordflow">if</span> ((4*tx) + 2 &lt; remain) *Psptr += a.z * *xsptr++;
         <span class="keywordflow">if</span> ((4*tx) + 3 &lt; remain) *Psptr += a.w * *xsptr;
         __syncthreads();
     }
     <span class="keywordflow">else</span> {
         T *xsptr = (T *) xs + (2*tx);
 
         <span class="keyword">typename</span> TexEl&lt;T&gt;::alt_value_type a;
 
         texAccessorOpt&lt;T&gt; tex_2D;
 
         <span class="keywordflow">for</span> (i = 0; i &lt; (n &amp; ~255); i += 256, xptr += 256)
         {
             xs[ty][tx] = *xptr;
 
             __syncthreads();
 
             <span class="keywordtype">int</span> ax = tx + (i/2);
 
 
             a = tex_2D(ax, ay);
             *Psptr += a.x * *xsptr         + a.y * *(xsptr +   1);
 
             a = tex_2D(ax+16, ay);
             *Psptr += a.x * *(xsptr +  32) + a.y * *(xsptr +  33);
 
             a = tex_2D(ax+32, ay);
             *Psptr += a.x * *(xsptr + 64) + a.y * *(xsptr + 65);
 
             a = tex_2D(ax+48, ay);
             *Psptr += a.x * *(xsptr + 96) + a.y * *(xsptr + 97);
 
             a = tex_2D(ax+64, ay);
             *Psptr += a.x * *(xsptr + 128) + a.y * *(xsptr + 129);
 
             a = tex_2D(ax+80, ay);
             *Psptr += a.x * *(xsptr + 160) + a.y * *(xsptr + 161);
 
             a = tex_2D(ax+96, ay);
             *Psptr += a.x * *(xsptr + 192) + a.y * *(xsptr + 193);
 
             a = tex_2D(ax+112, ay);
             *Psptr += a.x * *(xsptr + 224) + a.y * *(xsptr + 225);
 
             __syncthreads();
         }
 
         <span class="keywordflow">if</span> (i + (16*ty) + tx &lt; n) xs[ty][tx] = *xptr;
 
         __syncthreads();
 
 
         <span class="keywordtype">int</span> j;
 
         <span class="keywordflow">for</span> (j = 0; j &lt; ((n - i)/32); j++, xsptr += 31)
         {
             a = tex_2D(tx + (i/2) + (16*j), ay);
             *Psptr += a.x * *xsptr++ + a.y * *xsptr;
         }
         __syncthreads();
 
 
         <span class="keywordtype">int</span> remain = (n - i) &amp; 31;
 
         <span class="keywordflow">if</span> ((2*tx) &lt; remain) {
             a = tex_2D(tx + (i/2) + (16*j), ay);
 
             *Psptr += a.x * *xsptr++;
         }
 
         <span class="keywordflow">if</span> ( (2*tx) + 1 &lt; remain)
         {
             *Psptr += a.y * *xsptr;
         }
 
         __syncthreads();
     }
 
     <span class="keywordflow">if</span> (tx &lt; 8) *Psptr += *(Psptr + 8);
     <span class="keywordflow">if</span> (tx &lt; 4) *Psptr += *(Psptr + 4);
     <span class="keywordflow">if</span> (tx &lt; 2) *Psptr += *(Psptr + 2);
     <span class="keywordflow">if</span> (tx &lt; 1) *Psptr += *(Psptr + 1);
 
     __syncthreads();
     <span class="keywordflow">if</span> (ty == 0 &amp;&amp; (16*bx) + tx &lt; m) y[(16*bx) + tx] = Ps[tx][0];
 }
</pre></div><p> <a class="anchor" id="plain-Functionmv_fujimoto"></a> </p>
<div class="fragment"><pre class="fragment"> <span class="keywordtype">void</span> __do_FJ_orig(<span class="keywordtype">float</span>* d_y, cudaArray* d_A, <span class="keywordtype">float</span>* d_x, <span class="keywordtype">int</span> m, <span class="keywordtype">int</span> n, dim3 grid, dim3 threads)
 {
     _mv_fujimoto&lt;&lt;&lt; grid, threads &gt;&gt;&gt;(d_y, d_A, d_x, m, n);
 }
 
 <span class="keywordtype">void</span> __do_FJ_orig(<span class="keywordtype">double</span>* , cudaArray* , <span class="keywordtype">double</span>* , <span class="keywordtype">int</span> , <span class="keywordtype">int</span> , dim3 , dim3 )
 {
     printf(<span class="stringliteral">&quot;For double precision the original version of Fujimoto is not available!\n&quot;</span>);
 }
 
 <span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;
 <span class="keywordtype">void</span> Kernels&lt;T&gt;::mv_fujimoto(T *y, <span class="keyword">const</span> T *A, <span class="keyword">const</span> T *x, <span class="keyword">const</span> <span class="keywordtype">int</span> m, <span class="keyword">const</span> <span class="keywordtype">int</span> n,
                              <span class="keyword">const</span> <span class="keywordtype">int</span> n_repetitions,
                              <span class="keyword">const</span> <span class="keywordtype">int</span> fj_version,
                              <span class="keywordtype">double</span>&amp;  elapsed_time)
 {
 
     <span class="keywordtype">int</span> blkNum = (m + 15)/16; <span class="comment">// (m &gt;&gt; 4) + ((m &amp; 15) ? 1 : 0);</span>
     <span class="keywordtype">int</span> height = blkNum*16; <span class="comment">// blkNum &lt;&lt; 4;</span>
 
     <span class="keywordtype">int</span> width = 256*((n+255)/256); <span class="comment">// (n &amp; 255) ? (((n &gt;&gt; 8) + 1) &lt;&lt; 8) : n;</span>
 
     dim3 threads(16, 16);
     dim3 grid(blkNum, 1);
 
     cudaArray *d_A;
     T *d_x, *d_y;
 
     cudaChannelFormatDesc
             channelDesc = cudaCreateChannelDesc&lt;typename TexEl&lt;T&gt;::texel_type/ *float4* /&gt;();
 
     cudaMallocArray(&amp;d_A, &amp;channelDesc, width/TexEl&lt;T&gt;::tex_stride, height);
 
     <span class="keywordtype">size_t</span> size_of_T = <span class="keyword">sizeof</span>(T);
 
     cudaMemcpy2DToArray(d_A, 0, 0, A,
                         n * size_of_T,
                         n * size_of_T,
                         m,
                         cudaMemcpyHostToDevice);
 
 
     <span class="keywordflow">if</span> (IsFloat&lt;T&gt;::value)
         cudaBindTextureToArray(fTexRefA, d_A);
     <span class="keywordflow">else</span>
         cudaBindTextureToArray(dTexRefA, d_A);
 
     cudaMalloc((<span class="keywordtype">void</span> **) &amp;d_x, n * size_of_T );
     cudaMalloc((<span class="keywordtype">void</span> **) &amp;d_y, m * size_of_T );
 
     cudaMemcpy(d_x, x, n * size_of_T, cudaMemcpyHostToDevice);
 
<span class="preprocessor"> #ifndef DONT_USE_CUDATIMER</span>
<span class="preprocessor"></span>     CUDATimer timer;
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span>     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;n_repetitions; i++)
     {
         cudaMemcpy(d_y, y, m * size_of_T, cudaMemcpyHostToDevice);
         <span class="keywordflow">switch</span> (fj_version) {
         <span class="keywordflow">case</span> 0:
             __do_FJ_orig(d_y, d_A, d_x, m, n, grid, threads);
             <span class="keywordflow">break</span>;
         <span class="keywordflow">case</span> 1:
             _mv_fujimoto_T&lt;&lt;&lt; grid, threads &gt;&gt;&gt;(d_y, d_A, d_x, m, n);
             <span class="keywordflow">break</span>;
         <span class="keywordflow">case</span> 2:
             _mv_fujimoto_T2&lt;&lt;&lt; grid, threads &gt;&gt;&gt;(d_y, d_A, d_x, m, n);
             <span class="keywordflow">break</span>;
         <span class="keywordflow">case</span> 3:
             _mv_fujimoto_T3&lt;&lt;&lt; grid, threads &gt;&gt;&gt;(d_y, d_A, d_x, m, n);
             <span class="keywordflow">break</span>;
         <span class="keywordflow">default</span>:
             <span class="keywordflow">break</span>;
         }
     }
     cudaThreadSynchronize();
<span class="preprocessor"> #ifndef DONT_USE_CUDATIMER</span>
<span class="preprocessor"></span>     timer.stop();
     elapsed_time = timer.elapsed() ;
<span class="preprocessor"> #else</span>
<span class="preprocessor"></span>     elapsed_time = 3.1415926;
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span><span class="preprocessor"> #ifdef DEBUG</span>
<span class="preprocessor"></span><span class="preprocessor"> #ifndef DONT_USE_CUDATIMER</span>
<span class="preprocessor"></span>     timer.print_elapsed(<span class="stringliteral">&quot;Time spent in Fujimotos MV product:&quot;</span>);
<span class="preprocessor"> #endif</span>
<span class="preprocessor"></span><span class="preprocessor"> #endif</span>
<span class="preprocessor"></span> 
     cudaMemcpy(y, d_y, m * size_of_T, cudaMemcpyDeviceToHost);
 
     cudaFree(d_y);
     cudaFree(d_x);
 
     <span class="keywordflow">if</span>(IsFloat&lt;T&gt;::value)
         cudaUnbindTexture( fTexRefA);
     <span class="keywordflow">else</span>
         cudaUnbindTexture( dTexRefA);
     cudaFreeArray(d_A);
 }
 
 <span class="keyword">template</span> <span class="keyword">class </span>Kernels&lt;float&gt;;
 <span class="keyword">template</span> <span class="keyword">class </span>Kernels&lt;double&gt;;
 
 } <span class="comment">// namespace step2 END</span>
</pre></div> </div></div><!-- contents -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Files</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<hr size="1"><address style="align: right;"><small>
<img src="logo200.png" alt="blanc++"> documentation generated on Sun Jul 27 2014 17:41:51 by <a href="http://www.doxygen.org/index.html">
doxygen
</a> 1.7.6.1</small></address>
</body>
</html>
