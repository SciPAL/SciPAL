 * <a name="CommProg"></a>
 * <h1> The commented program</h1>
 * 
 * 
 * @code
 *     SciPAL is free software: you can redistribute it and/or modify
 *     it under the terms of the GNU Lesser General Public License as published by
 *     the Free Software Foundation, either version 3 of the License, or
 *     (at your option) any later version.
 * 
 *     SciPAL is distributed in the hope that it will be useful,
 *     but WITHOUT ANY WARRANTY; without even the implied warranty of
 *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *     GNU Lesser General Public License for more details.
 * 
 *     You should have received a copy of the GNU Lesser General Public License
 *     along with SciPAL.  If not, see <http://www.gnu.org/licenses/>.
 * 
 * Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * * /
 * 
 * 
 * @endcode
 * 
 * This is standard C++.
 * 
 * @code
 * #include <iostream>
 * #include <vector>
 * 
 * @endcode
 * 
 * Driver class for GPU part of th program.
 * 
 * @code
 * #include <cuda_driver_step-42.h>
 * #include <cuda_driver_step-42.hh>
 * 
 * @endcode
 * 
 * The parameter class for your simulation.
 * 
 * @code
 * #include <SimParams.h>
 * 
 * 
 * @endcode
 * 
 * deal.II includes
 * 
 * @code
 * #include <deal.II/lac/vector.h>
 * 
 * 
 * namespace step42 {
 * 
 * @endcode
 * 
 * 
 * <a name="ClassGPUInfo"></a> 
 * <h3>Class: GPUInfo</h3>
 * 
 * 
 * This an auxiliary structure which collects data related to the GPUs
 * available in the computer on which this program gets executed.
 * For details about the cuda<something> functions have a look at
 * the CUDA reference manual.
 * 
 * @code
 * struct GPUInfo {
 * 
 *     int n_CUDA_devices;
 * 
 *     int current_device_id;
 * 
 *     cudaDeviceProp prop;
 * 
 * 
 *     GPUInfo(int DevNo)
 *         :
 *           current_device_id(DevNo)
 *     {
 * 
 *     }
 * 
 * @endcode
 * 
 * 
 * <a name="Functionget"></a> 
 * <h4>Function: get</h4>
 * 
 * 
 * this function must be called to retrieve the
 * GPU-related information.
 * 
 * @code
 *     void get()
 *     {
 *         static const int KB = 1024;
 *         static const int MB = KB*KB;
 * 
 * @endcode
 * 
 * Retrieve information about the currently selected GPU.
 * 
 * @code
 *         std::cout << "current device ID : " << this->current_device_id << std::endl;
 * 
 *         cudaGetDeviceProperties(&prop, this->current_device_id);
 * 
 *         printf("Currently used GPU: %s \n",prop.name);
 *         printf("Compute Capability: %d.%d \n",prop.major,prop.minor);
 *         printf("ClockRate: %uMHz \n",prop.clockRate/1000);
 *         printf("Warpsize: %d \n",prop.warpSize);
 *         printf("Number of Multiprocessors: %d \n",prop.multiProcessorCount);
 * 
 *         printf("Shared Memory: %luKB\n",prop.sharedMemPerBlock/KB);
 *         printf("Constant Memory: %luKB \n",prop.totalConstMem/KB);
 *         printf("Global Memory: %luMB \n",prop.totalGlobalMem/MB);
 *         printf("the device %s concurrently copy memory between host and device while executing a kernel\n",
 *                (prop.deviceOverlap? "can": "cannot"));
 *     }
 * 
 * @endcode
 * 
 * To keep the compiler from automatically generating
 * a copy constructor and an assignment operator we provide
 * dummy implementations and declare them as private.
 * In case one of them is needed the compiler will complain at compile-time
 * and one can think about whether they are really needed, i.e. one has to
 * review one's software design.
 * 
 * @code
 * private:
 *     GPUInfo (const GPUInfo & / *other* /) {}
 * 
 *     GPUInfo & operator = (const GPUInfo & / *other* /) { return *this; }
 * 
 * };
 * 
 * 
 * @endcode
 * 
 * 
 * <a name="ClassMyFancySimulation"></a> 
 * <h3>Class: MyFancySimulation</h3>
 * 
 * 
 * To make this test facility extendible, we implement
 * a class for a simple user interface. Its primary tasks are
 * - management of run-time parameters by a simple text-based parameter file
 * - setting device parameters according to the user's parameters
 * - preprocessing and output of results
 * 
 * @code
 * class MyFancySimulation {
 * 
 * public:
 * 
 *     MyFancySimulation(int argc, char *argv[], GPUInfo &g);
 * 
 *     void run();
 * 
 * private:
 *     GPUInfo & gpuinfo;
 * 
 * protected:
 *     SimParams params;
 * };
 * 
 * }
 * 
 * 
 * @endcode
 * 
 * 
 * <a name="ConstructorMyFancySimulation"></a> 
 * <h4>Constructor: MyFancySimulation</h4>
 * 
 * 
 * The constructor is responsible for reading parameters
 * and initializing the device, i.e. the selected graphics card.
 * @param argc : The number of command line arguments. This is always $\ge 1$, as by default the zeroth argument is the name of program itself.
 * @param argv : Pointer to the array of command line arguments.
 * @param g : Reference to the object containing the GPU info from the system.
 * 
 * @code
 * step42::MyFancySimulation::MyFancySimulation(int argc,
 *                                                    char *argv[],
 *                                                    step42::GPUInfo &g)
 *     : gpuinfo(g)
 * {
 * @endcode
 * 
 * Before setting up the simulation we
 * figure out how many GPUs are available
 * 
 * @code
 *     cudaGetDeviceCount(&gpuinfo.n_CUDA_devices);
 *     std::cout
 *             << "N available CUDA devices : "
 *             << gpuinfo.n_CUDA_devices << std::endl;
 * 
 * @endcode
 * 
 * Declare and read parameters from a file. Basically, the parameter
 * file must have the same name as the binary. The extension has
 * to be ".prm". What has been read will be dumped into a log file.
 * 
 * @code
 *     dealii::ParameterHandler prm_handler;
 * 
 *    SimParams::declare(prm_handler);
 * 
 * @endcode
 * 
 * Get the current working directory ...
 * 
 * @code
 *     QDir cwd = QDir::current();
 * 
 * @endcode
 * 
 * i.e. where the program has been started.
 * 
 * @code
 *     QDir launch_dir = cwd;
 * 
 * @endcode
 * 
 * By default, the parameter file has the same name as the binary
 * and is supposed to be in a subdirectory prm of that directory,
 * where the program has been started.
 * 
 * @code
 *     std::string prm_filename;
 *     if (argc == 1)
 *     {
 *         prm_filename  = argv[0];
 *         prm_filename += ".prm";
 * 
 *         cwd.setPath("./prm");
 *     }
 *     else
 *     {
 * @endcode
 * 
 * Whatever gets passed as first command line argument is considered as path
 * to a parameter file.
 * 
 * @code
 *         std::cout << "Given parameter file : " << argv[1] << std::endl;
 * 
 * @endcode
 * 
 * We convert the sequence of characters into something more meaningful.
 * 
 * @code
 *         QFileInfo tmp(argv[1]);
 * 
 * @endcode
 * 
 * Before we proceed, let us figure out whether the given parameter file exists.
 * Note: If the file is a symlink that points to a non existing file,
 * false is returned as well.
 * 
 * @code
 *         if(!tmp.exists())
 *         {
 *             std::cerr << "The following parameter file does not exist:\n"
 *                       << argv[1] << std::endl;
 * 
 *             qFatal("Cannot proceed without proper path to paramter file");
 *         }
 * 
 * @endcode
 * 
 * Next, we subdivide the given filename into its path and filename
 * so that the corresponding subdirectories can be created.
 * 
 * @code
 *         QString prm_path = tmp.absolutePath();
 *         cwd.setPath(prm_path);
 *         cwd.makeAbsolute();
 *         prm_filename = tmp.fileName().toStdString();
 * 
 *         std::cout << "Parameter file path : "
 *                   << tmp.absolutePath().toStdString().c_str()
 *                   << std::endl;
 *     }
 * 
 *     std::cout << "Parameter file : " << prm_filename  << std::endl;
 * 
 * @endcode
 * 
 * Before the parameter file can be read, we have to make sure that
 * its directory exists. In case of the default parameter file
 * the directory will be created.
 * 
 * @code
 *     if (!cwd.exists() )
 *         launch_dir.mkpath( cwd.absolutePath() );
 * 
 *     QDir::setCurrent(cwd.absolutePath());
 * 
 *     prm_handler.read_input (prm_filename);
 * 
 *     QDir::setCurrent(launch_dir.absolutePath());
 * 
 *     this->params.get(prm_handler);
 * 
 * @endcode
 * 
 * Create toplevel run directory
 * 
 * @code
 *     cwd.setPath(this->params.run_dir.absolutePath());
 * 
 * @endcode
 * 
 * The following lets a directory make its own path.
 * 
 * @code
 *     if (!cwd.exists())
 *         cwd.mkpath( "." );
 * 
 * @endcode
 * 
 * Now, change to the run dir
 * 
 * @code
 *     QDir::setCurrent(cwd.absolutePath());
 * 
 *     cwd.setPath("./log");
 *     cwd.makeAbsolute();
 *     if (!cwd.exists())
 *         cwd.mkpath(".");
 * 
 * @endcode
 * 
 * Create the log directory and write what has been actually read
 * into log file. Basically, this is just another parameter file
 * and can thus be used again as input to another run after stripping the .log suffix.
 * 
 * @code
 *     QDir::setCurrent(cwd.absolutePath());
 * 
 *     prm_filename += ".log";
 *     std::ofstream log_out_text(("./" + QString(prm_filename.c_str()).split("/").last()).toStdString().c_str());
 *     prm_handler.print_parameters (log_out_text,
 *                                   dealii::ParameterHandler::Text);
 * 
 * @endcode
 * 
 * At this point the toplevel run dir must exist.
 * Thus, we can change to it without any further sanity test.
 * 
 * @code
 *     QDir::setCurrent(this->params.run_dir.absolutePath());
 * }
 * 
 * 
 * 
 * @endcode
 * 
 * 
 * <a name="Functionrun"></a> 
 * <h4>Function: run</h4>
 * 
 * 
 * Actual call to run function.
 * 
 * @code
 * void step42::MyFancySimulation::run()
 * {
 * 
 * @endcode
 * 
 * instantiate an object of the driver class
 * 
 * @code
 *     step42::CUDADriver testcase;
 * 
 * @endcode
 * 
 * ... and run the computation on the GPU (or other dedicated parallel hardware).
 * 
 * @code
 *     testcase.gemm_tests();
 * 
 *     testcase.gemv_tests();
 * 
 *     testcase.complex_tests();
 * 
 *     testcase.feature_demonstration();
 * 
 *     std::cout << "Done." << std::endl;
 * }
 * 
 * 
 * 
 * @endcode
 * 
 * 
 * <a name="Functionmain"></a> 
 * <h3>Function: main</h3>
 * 
 * 
 * As usual, the main function is pretty boring.
 * 
 * @code
 * int main(int argc, char *argv[])
 * {
 *     using namespace step42;
 * 
 * @endcode
 * 
 * At the beginning we figure out
 * how many CUDA devices are available.
 * 
 * @code
 *     int n_CUDA_devices;
 * 
 *     cudaGetDeviceCount(&n_CUDA_devices);
 *     std::cout
 *             << "N available CUDA devices : "
 *             <<  n_CUDA_devices
 *             << std::endl;
 * 
 * @endcode
 * 
 * This command is used to set the GPU on which
 * we want to run our computations.
 * For a list of GPUs execute nvidia-smi.
 * 
 * @code
 *     int DevNo = 0;
 *     cudaSetDevice(DevNo);
 *     GPUInfo gpu_info(DevNo);
 * 
 * @endcode
 * 
 * Before we can instantiate the simulation we have to get the GPU info.
 * 
 * @code
 *     gpu_info.get();
 * 
 *     MyFancySimulation machma(argc, argv, gpu_info);
 * 
 *     machma.run();
 * 
 * }
 * 
 * 
 * 
 * / *This file is part of SciPAL.
 * 
 *     SciPAL is free software: you can redistribute it and/or modify
 *     it under the terms of the GNU Lesser General Public License as published by
 *     the Free Software Foundation, either version 3 of the License, or
 *     (at your option) any later version.
 * 
 *     SciPAL is distributed in the hope that it will be useful,
 *     but WITHOUT ANY WARRANTY; without even the implied warranty of
 *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *     GNU Lesser General Public License for more details.
 * 
 *     You should have received a copy of the GNU Lesser General Public License
 *     along with SciPAL.  If not, see <http://www.gnu.org/licenses/>.
 * 
 * Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * * /
 * 
 * 
 * #ifndef CUDADriver_STEP_42_H
 * #define CUDADriver_STEP_42_H
 * 
 * #include <lac/release/blas_wrapper.hh>
 * #include <lac/release/cublas_wrapper.hh>
 * #include <base/CudaComplex.h>
 * 
 * @endcode
 * 
 * We encapsulate each project
 * into a dedicated namespace
 * in order to be able to re-use
 * parts of a test program in others.
 * 
 * @code
 * namespace step42 {
 * 
 * @endcode
 * 
 * 
 * <a name="ClassCUDADriver"></a> 
 * <h3>Class: CUDADriver</h3>
 * 
 * 
 * This class manages the communication between host and device.
 * In particular the issue of memory transfers from and to the device.
 * The dummy implementation given here is supposed to give an
 * impression how this management could be done.
 * For worked out examples have a look at the other steps from
 * previous lab courses.
 * The documentation of the member functions is kept together
 * with their definitions.
 * 
 * @code
 * class CUDADriver {
 * 
 *     typedef double Number;
 *     typedef SciPAL::CudaComplex<Number> cplxNumber;
 * 
 *     typedef cublas BW;
 * 
 * public:
 * 
 *     CUDADriver();
 * 
 *     ~CUDADriver() { BW::Shutdown(); }
 * 
 *     void gemm_tests();
 * 
 *     void gemv_tests();
 * 
 *     void complex_tests();
 * 
 *     void feature_demonstration();
 * 
 * private:
 * 
 * 
 * };
 * 
 * } // namespace step42 END
 * 
 * #endif // CUDADriver_STEP_42_H
 * 
 * 
 * 
 * / *This file is part of SciPAL.
 * 
 *     SciPAL is free software: you can redistribute it and/or modify
 *     it under the terms of the GNU Lesser General Public License as published by
 *     the Free Software Foundation, either version 3 of the License, or
 *     (at your option) any later version.
 * 
 *     SciPAL is distributed in the hope that it will be useful,
 *     but WITHOUT ANY WARRANTY; without even the implied warranty of
 *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *     GNU Lesser General Public License for more details.
 * 
 *     You should have received a copy of the GNU Lesser General Public License
 *     along with SciPAL.  If not, see <http://www.gnu.org/licenses/>.
 * 
 * Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * * /
 * 
 * 
 * #ifndef CUDA_DRIVER_STEP_42_HH
 * #define CUDA_DRIVER_STEP_42_HH
 * 
 * 
 * @endcode
 * 
 * The declaration of the interface to the CUDA-backend
 * is contained in the following header.
 * 
 * @code
 * #include <cuda_driver_step-42.h>
 * #include <cuda_kernel_wrapper_step-42.cu.h>
 * 
 * 
 * 
 * #include <lac/development/cublas_Matrix.h>
 * 
 * 
 * #include <lac/development/cublas_Vector.h>
 * #include <lac/blas++.h>
 * #include <base/CudaComplex.h>
 * 
 * @endcode
 * 
 * We have to include
 * 
 * @code
 * #include <cuda_runtime_api.h>
 * 
 * 
 * @endcode
 * 
 * 
 * <a name="ConstructorCUDADriver"></a> 
 * <h4>Constructor: CUDADriver</h4>
 * 
 * 
 * The constructor of the driver class allocates memory
 * on the GPU and copies data from host to device.
 * Furthermore, it keeps a pointer to the original host data for the
 * case that it has to be modified by the GPU results.
 * @param v_h : Pointer to a linear array in host-side memory that is to be copied to the GPU.
 * @param n : Number of entries of @p v_h.
 * 
 * @code
 * step42::CUDADriver::CUDADriver() {
 * 
 *     BW::Init();
 * }
 * 
 * 
 * 
 * 
 * @endcode
 * 
 * 
 * <a name="Functiongemm_tests"></a> 
 * <h4>Function: gemm_tests</h4>
 * 
 * 
 * This function tests the various special cases contained
 * in BLAS' gemm function.
 * 
 * @code
 * void step42::CUDADriver::gemm_tests()
 * {
 * 
 * @endcode
 * 
 * some dummy vectors
 * 
 * @code
 *     const unsigned int n_rows = 4;
 *     const unsigned int n_cols = 3;
 *     const unsigned int n_elements = n_rows * n_cols;
 * 
 *     std::vector<Number>
 *             a(n_elements, 1.),
 *             b(n_elements, 2.),
 *             c(n_rows * n_rows, 1.23);
 * 
 *     for (unsigned int i = 0; i < b.size(); i++ )
 *         b[i] = i+1;
 * 
 * 
 *     SciPAL::Matrix<Number, BW>
 *             A(n_rows, n_cols, a),
 *             B(n_cols, n_rows, b),
 *             C(n_rows, n_rows, c);
 * 
 *      Number alpha = 1.1;
 *      Number beta = 2.;
 * 
 *      std::cout << "A : " << std::endl;
 *      A.print();
 * 
 *      std::cout << "B : " << std::endl;
 *      B.print();
 * 
 *      std::cout << "C : " << std::endl;
 *      C.print();
 * 
 * 
 * 
 *      std::cout << " ============ C = " << alpha << " * A ======" << std::endl;
 *      C = alpha * A; // * B + beta * C;
 *        std::cout << "C : " << std::endl;
 *      C.print();
 * 
 *      std::cout << " ============ C = A * B ======" << std::endl;
 *      C = A * B;   std::cout << "C : " << std::endl; C.print();
 * 
 *      std::cout << " ============ C = B * A ======" << std::endl;
 *      C = B * A;   std::cout << "C : " << std::endl; C.print();
 * 
 *      std::cout << " ============ C = alpha * A * B ======" << std::endl;
 *      C = alpha * A * B; std::cout << "C : " << std::endl; C.print();
 * 
 * 
 * @endcode
 * 
 * sMMaM test
 * 
 * @code
 *      std::cout << " ============ C = " << alpha << " * A * B + "<<"C======" << std::endl;
 *      c.clear();
 *      c.resize(n_rows * n_rows, 1.);
 *      SciPAL::Matrix<Number, BW>
 *              D(n_rows, n_rows, c);
 * 
 * 
 * 
 *      C = D;
 *      std::cout << "C : " << std::endl; C.print();
 *      C = alpha * A * B + // beta *
 *              C; std::cout << "C : " << std::endl; C.print();
 * 
 * 
 * @endcode
 * 
 * gemm test
 * 
 * @code
 *      std::cout << " ============ C = " << alpha << " * A * B + "  << beta  << " * C======" << std::endl;
 *      C = D;
 *      std::cout << "C : " << std::endl; C.print();
 * 
 *      C = alpha * A * B + beta * C;
 *      std::cout << "C : " << std::endl; C.print();
 * }
 * 
 * 
 * @endcode
 * 
 * 
 * <a name="Functiongemv_tests"></a> 
 * <h4>Function: gemv_tests</h4>
 * 
 * 
 * This function tests the various special cases contained
 * in BLAS' gemv function.
 * 
 * 
 * Currently, it is rather a test for the vector arithmetic.
 * test vector expressions
 * 
 * @code
 * void step42::CUDADriver::gemv_tests()
 * {
 * #ifndef nUSE_ARRAY_EXPRESSIONS
 *      const unsigned int n_rows = 4;
 *      const unsigned int n_cols = 4;
 *      const unsigned int n_elements = n_rows * n_cols;
 * 
 *      Number alpha = 1.1;
 *      Number beta = 2.;
 * 
 *      std::vector<Number>
 *                 a(n_elements, 1.),
 *                 b(n_elements, 2.);
 * 
 * 
 *      for (unsigned int i = 0; i < a.size(); i++ )
 *          a[i] = i+1;
 * 
 *      SciPAL::Vector<Number, BW> vA, vB(n_elements), vC;
 *        vA = a;
 * @endcode
 * 
 * This sets all elements of vB to 2.3, note: vector needs to be initialized.
 * 
 * @code
 *        vB = SciPAL::Literal<Number>(2.3);
 *        vC = a;
 * 
 * 
 *        std::cout << "vA : " << std::endl;
 *        vA.print();
 * 
 *        std::cout << "vB : " << std::endl;
 *        vB.print();
 * 
 *        std::cout << " ============ vC = " << alpha << " * vA ======" << std::endl;
 *        vC = alpha * vA;
 *          std::cout << "vC : " << std::endl;
 *        vC.print();
 * 
 *        std::cout << " ============ vC = " << alpha << " * vA + vB ======" << std::endl;
 *        vC = alpha * vA + vB;
 *          std::cout << "vC : " << std::endl;
 *        vC.print();
 * 
 *        std::cout << " ============ vA = sin(vC) ======" << std::endl;
 *        const unsigned int n_sin_elements = n_elements;
 *        std::vector<Number> d(n_sin_elements);
 *        for(uint i = 0; i < d.size(); i++)
 *            d[i] = i* 2.* M_PI / d.size();
 * 
 *        SciPAL::Vector<Number, BW> vD; vD = d; //(n_sin_elements, 1, d);
 *       vD = sin(vD); // For this to work the device-side apply() function has to be explicitly specialized.
 *          std::cout << "sin(vD) : " << std::endl;
 *        vD.print();
 * @endcode
 * 
 * vC = alpha * sin(vA) + vB;
 * 

 * 
 * 

 * 
 * After the element-wise sine of a vector we do the same for a matrix.
 * 
 * @code
 *        SciPAL::Matrix<Number, BW>
 *                A(n_rows, n_cols, d);
 *        A = sin(A);
 *        A.print();
 * 
 * 
 *        std::cout << " ============ linear combination test ======" << std::endl;
 *        vC = 2.0 * vA;
 *        std::cout << "vC = 2.0 * vA" << std::endl;
 *        vC.print();
 * 
 * 
 *        vC = vA + vB;
 *        std::cout << "vC = vA + vB" << std::endl;
 *        vC.print();
 * 
 * 
 *        vC = vA + 2.0 * vB;
 *        std::cout << "vC = vA + 2.0 * vB" << std::endl;
 *        vC.print();
 * 
 *        vC = 2.0 * vA + 3.0 * vB;
 *        std::cout << "vC = 2.0 * vA + 3.0 * vB" << std::endl;
 *        vC.print();
 * 
 * @endcode
 * 
 * vC = 2.0 * vA + 3.0 * vB + 4.0 * vD;
 * std::cout << "vC = 2.0 * vA + 3.0 * vB + 4.0 * vD" << std::endl;
 * vC.print();
 * 

 * 
 * combined expr test
 * 
 * @code
 *        vC =sin(2.0 * vA + 3.0 * vB);
 *        std::cout << "vC = sin(2.0 * vA + 3.0 * vB)" << std::endl;
 *        vC.print();
 * 
 * @endcode
 * 
 * test pointwise sqrt
 * 
 * @code
 *        vC = sqrt(vC);
 *        std::cout << "sqrt(sin(2.0 * vA + 3.0 * vB))" << std::endl;
 *        vC.print();
 * 
 * @endcode
 * 
 * test pointwise *
 * 
 * @code
 *        vC = vA && vB;
 *        std::cout << "vC = vA .* vB" << std::endl;
 *        vC.print();
 * 
 * @endcode
 * 
 * test pointwise /
 * 
 * @code
 *        vC = vA || vB;
 *        std::cout << "vC = vA ./ vB" << std::endl;
 *        vC.print();
 * 
 * @endcode
 * 
 * combined expr test
 * 
 * @code
 *        vC = (vA + vB) || (vA - vB);
 *        std::cout << "vC = (vA + vB) || (vA - vB)" << std::endl;
 *        vC.print();
 * 
 * @endcode
 * 
 * combined expr test
 * vC =abs(cos(2.0 * vA + 3.0 * vB));
 * std::cout << "vC = abs(cos(2.0 * vA + 3.0 * vB)" << std::endl;
 * vC.print();
 * 

 * 
 * 
 * @code
 * #endif
 * }
 * 
 * void step42::CUDADriver::complex_tests()
 * {
 *     std::cout<<"Entering tests for complex number array exptessions."<<std::endl;
 * #ifndef nUSE_ARRAY_EXPRESSIONS
 *      const unsigned int n_rows = 4;
 *      const unsigned int n_cols = 4;
 *      const unsigned int n_elements = n_rows * n_cols;
 * 
 *      SciPAL::CudaComplex<Number> alpha(1.1);
 *      SciPAL::CudaComplex<Number> beta (2.);
 * 
 *      std::vector<std::complex<Number> >
 *                 a(n_elements, 1.),
 *                 b(n_elements, std::complex<Number>(2., 2.0));
 * 
 * 
 *      for (unsigned int i = 0; i < a.size(); i++ )
 *          a[i] = std::complex<Number>(i+1, (i+1)/2.); //generate some inputs
 * 
 *        SciPAL::Vector<SciPAL::CudaComplex<Number>, BW> vA, vB, vC;
 *        vA = a;
 *        vB = b;
 *        vC = a;
 * @endcode
 * 
 * vA(n_elements, 1, a),
 * vB(n_elements, 1, b),
 * vC(n_elements, 1, a);
 * 

 * 
 * 
 * @code
 *        std::cout << "vA : " << std::endl;
 *        vA.print();
 * 
 *        std::cout << "vB : " << std::endl;
 *        vB.print();
 * 
 *        std::cout << " ============ vC = " << alpha.real() << " * vA ======" << std::endl;
 *        vC = alpha * vA;
 *          std::cout << "vC : " << std::endl;
 *        vC.print();
 * 
 *        std::cout << " ============ vC = " << alpha.real() << " * vA + vB ======" << std::endl;
 *        vC = alpha * vA + vB;
 *          std::cout << "vC : " << std::endl;
 *        vC.print();
 * 
 *        std::cout << " ============ vA = sin(vC) ======" << std::endl;
 *        const unsigned int n_sin_elements = n_elements;
 *        std::vector<std::complex<Number> > d(n_sin_elements);
 *        for(uint i = 0; i < d.size(); i++)
 *            d[i] = std::complex<Number>(i* 2.* M_PI / d.size(), i* 4.* M_PI / d.size()) ;
 * 
 *        SciPAL::Vector<SciPAL::CudaComplex<Number>, BW> vD; vD = d; //(n_sin_elements, 1, d);
 *       vD = sin(vD); // For this to work the device-side apply() function has to be explicitly specialized.
 *          std::cout << "sin(vD) : " << std::endl;
 *        vD.print();
 * @endcode
 * 
 * vC = alpha * sin(vA) + vB;
 * 

 * 
 * 
 * @code
 *        std::cout << " ============ Matrix A = sin(A) ======" << std::endl;
 * @endcode
 * 
 * After the element-wise sine of a vector we do the same for a matrix.
 * 
 * @code
 *        SciPAL::Matrix<SciPAL::CudaComplex<Number>, BW>
 *                A(n_rows, n_cols, d);
 *        A = sin(A);
 *        A.print();
 * 
 *        std::cout << " ============ Matrix B = sqrt(A) ======" << std::endl;
 * @endcode
 * 
 * After the element-wise sine of a vector we do the same for a matrix.
 * 
 * @code
 *        SciPAL::Matrix<SciPAL::CudaComplex<Number>, BW>
 *                B(A);
 *        B = sqrt(A);
 *        B.print();
 * 
 *        std::cout << " ============ Matrix A = .exp(B) ======" << std::endl;
 * @endcode
 * 
 * After the element-wise sine of a vector we do the same for a matrix.
 * SciPAL::Matrix<SciPAL::CudaComplex<Number>, BW>
 * A(B);
 * 
 * @code
 *        A = exp(B);
 *        A.print();
 * 
 *        std::cout << " ============ Matrix A = B*C ======" << std::endl;
 * @endcode
 * 
 * After the element-wise sine of a vector we do the same for a matrix.
 * 
 * @code
 *        SciPAL::Matrix<SciPAL::CudaComplex<Number>, BW>
 *                C(A);
 *        A = B*C;
 *        A.print();
 * 
 * 
 *        std::cout << " ============ linear combination test ======" << std::endl;
 * 
 * @endcode
 * 
 * This does not work : vC = 2.0 * vA; because of mismatching type.
 * Thus we hav to use numbers wrapped in CudaComplexes
 * 
 * @code
 *        vC = beta * vA; ;
 *        std::cout << "vC = 2.0 * vA" << std::endl;
 *        vC.print();
 * 
 * 
 *        vC = vA + vB;
 *        std::cout << "vC = vA + vB" << std::endl;
 *        vC.print();
 * 
 * 
 *        vC = vA + beta * vB;
 *        std::cout << "vC = vA + 2.0 * vB" << std::endl;
 *        vC.print();
 * 
 *        vC = cplxNumber(2.0) * vA + cplxNumber(3.0) * vB;
 *        std::cout << "vC = 2.0 * vA + 3.0 * vB" << std::endl;
 *        vC.print();
 * 
 * @endcode
 * 
 * combined expr test
 * 
 * @code
 *        vC =sin(cplxNumber(2.0) * vA + cplxNumber(3.0) * vB);
 *        std::cout << "vC = sin(2.0 * vA + 3.0 * vB)" << std::endl;
 *        vC.print();
 * 
 * @endcode
 * 
 * test pointwise sqrt
 * 
 * @code
 *        vC = sqrt(vC);
 *        std::cout << "sqrt(sin(2.0 * vA + 3.0 * vB))" << std::endl;
 *        vC.print();
 * 
 * @endcode
 * 
 * test pointwise *
 * 
 * @code
 *        vC = vA && vB;
 *        std::cout << "vC = vA .* vB" << std::endl;
 *        vC.print();
 * 
 * @endcode
 * 
 * test pointwise /
 * 
 * @code
 *        vC = vA || vB;
 *        std::cout << "vC = vA ./ vB" << std::endl;
 *        vC.print();
 * 
 * @endcode
 * 
 * combined expr test
 * 
 * @code
 *        vC = (vA + vB) || (vA - vB);
 *        std::cout << "vC = (vA + vB) || (vA - vB)" << std::endl;
 *        vC.print();
 * 
 * @endcode
 * 
 * combined expr test
 * vC =abs(cos(2.0 * vA + 3.0 * vB));
 * std::cout << "vC = abs(cos(2.0 * vA + 3.0 * vB)" << std::endl;
 * vC.print();
 * 

 * 
 * 
 * @code
 * #endif
 * }
 * 
 * 
 * void step42::CUDADriver::feature_demonstration()
 * {
 *     Number * bla = new Number[3];
 *     Number * bla2 = new Number[3];
 *     Number * bla3 = new Number[3];
 *     std::vector<Number*> h_testV(5);
 *     h_testV[0] = bla; std::cout<<"ptr1 " << bla << std::endl;
 *     h_testV[1] = bla2;std::cout<<"ptr2 " << bla2 << std::endl;
 *     h_testV[2] = bla3;std::cout<<"ptr3 " << bla3 << std::endl;
 * 
 *     SciPAL::Vector<Number*, cublas> d_testV(5);
 * 
 *  d_testV = h_testV;
 *  d_testV.print();
 * 
 * 
 * 
 * 
 * }
 * 
 * #endif // CUDA_DRIVER_STEP_42_HH
 * 
 * 
 * 
 * / *This file is part of SciPAL.
 * 
 *     SciPAL is free software: you can redistribute it and/or modify
 *     it under the terms of the GNU Lesser General Public License as published by
 *     the Free Software Foundation, either version 3 of the License, or
 *     (at your option) any later version.
 * 
 *     SciPAL is distributed in the hope that it will be useful,
 *     but WITHOUT ANY WARRANTY; without even the implied warranty of
 *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *     GNU Lesser General Public License for more details.
 * 
 *     You should have received a copy of the GNU Lesser General Public License
 *     along with SciPAL.  If not, see <http://www.gnu.org/licenses/>.
 * 
 * Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * * /
 * 
 * 
 * 
 * 
 * 
 * / *This file is part of SciPAL.
 * 
 *     SciPAL is free software: you can redistribute it and/or modify
 *     it under the terms of the GNU Lesser General Public License as published by
 *     the Free Software Foundation, either version 3 of the License, or
 *     (at your option) any later version.
 * 
 *     SciPAL is distributed in the hope that it will be useful,
 *     but WITHOUT ANY WARRANTY; without even the implied warranty of
 *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *     GNU Lesser General Public License for more details.
 * 
 *     You should have received a copy of the GNU Lesser General Public License
 *     along with SciPAL.  If not, see <http://www.gnu.org/licenses/>.
 * 
 * Copyright  S. C. Kramer , J. Hagemann  2010 - 2014
 * * /
 * 
 * 
 * 
 * 
 * 
 * @endcode
